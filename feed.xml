<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/" rel="alternate" type="text/html" /><updated>2022-06-06T09:16:32+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/feed.xml</id><title type="html">wjohn1483.github.io</title><subtitle></subtitle><author><name>Your Name</name></author><entry><title type="html">Python logging介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/06/04/python-logging-introduction/" rel="alternate" type="text/html" title="Python logging介紹" /><published>2022-06-04T00:00:00+00:00</published><updated>2022-06-04T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/06/04/python-logging-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/06/04/python-logging-introduction/"><![CDATA[<p>這篇文章簡單介紹一下python logging這個package的使用方法。</p>

<!--more-->

<p>在python裡面想要去debug你的程式除了使用<code class="language-plaintext highlighter-rouge">print()</code>直接把變數印出來以外，可以使用原生的<code class="language-plaintext highlighter-rouge">logging</code> package來去把log給印出來。</p>

<h2 id="log的分類">Log的分類</h2>

<p>在開始介紹logging怎麼使用之前，我們可以先來認識一下log有分成不同的等級，在<a href="https://docs.python.org/3/howto/logging.html#when-to-use-logging">python的文件</a>中有介紹什麼時候該使用哪種方法來顯示訊息，像是<code class="language-plaintext highlighter-rouge">print()</code>主要是用來顯示usage等一般用途，而<code class="language-plaintext highlighter-rouge">logging.warning()</code>是表示發現到有問題，但並不影響執行，詳細的介紹建議閱讀上面的文件，底下簡單介紹一下log的分級。</p>

<ul>
  <li>
    <p>DEBUG：顯示詳細的訊息，主要是在追查問題的時候使用</p>
  </li>
  <li>
    <p>INFO：顯示確認的訊息，表示程式有正確地在執行</p>
  </li>
  <li>
    <p>WARNING：表示有些預料外的事情發生或預告可能的問題像是硬碟空間快不夠了，但程式仍可以繼續執行</p>
  </li>
  <li>
    <p>ERROR：程式執行的過程當中碰到了一些問題，可能有些function不能被執行了</p>
  </li>
  <li>
    <p>CRITICAL：程式碰到了更嚴重的問題，已經無法繼續執行</p>
  </li>
</ul>

<h2 id="簡單使用logging">簡單使用logging</h2>

<p>在<code class="language-plaintext highlighter-rouge">logging</code>裡面有根據上述不同等級的log有對應的function可以呼叫，可以看底下的例子</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logging</span><span class="p">.</span><span class="n">debug</span><span class="p">(</span><span class="s">"Debug message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Info message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="s">"Warning message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="s">"Error message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">critical</span><span class="p">(</span><span class="s">"Critical message"</span><span class="p">)</span>
</code></pre></div></div>

<p>在實際執行上面的程式碼以後我們可以得到下面的結果</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WARNING:root:Warning message
ERROR:root:Error message
CRITICAL:root:Critical message
</code></pre></div></div>

<p>在使用<code class="language-plaintext highlighter-rouge">logging</code>的function時，<code class="language-plaintext highlighter-rouge">logging</code>會去創建一個名叫<code class="language-plaintext highlighter-rouge">root</code>的logger，並把訊息透過這個logger來紀錄，而其預設的格式是<code class="language-plaintext highlighter-rouge">severity:logger name:message</code>，而且只會顯示WARNING以上的訊息，如果想要設定顯示哪種log的等級的話，可以在最前面呼叫<code class="language-plaintext highlighter-rouge">basicConcig()</code>來設定</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logging</span><span class="p">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">debug</span><span class="p">(</span><span class="s">"Debug message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Info message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="s">"Warning message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="s">"Error message"</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">critical</span><span class="p">(</span><span class="s">"Critical message"</span><span class="p">)</span>
</code></pre></div></div>

<p>此時得到的結果會是</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DEBUG:root:Debug message
INFO:root:Info message
WARNING:root:Warning message
ERROR:root:Error message
CRITICAL:root:Critical message
</code></pre></div></div>

<p>這樣的作法在當程式碼裡面有引入多個module的時候也適用</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main.py
</span><span class="kn">import</span> <span class="nn">logging</span>

<span class="kn">from</span> <span class="nn">lib</span> <span class="kn">import</span> <span class="n">func</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"info from main"</span><span class="p">)</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"error from main"</span><span class="p">)</span>
    <span class="n">func</span><span class="p">()</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lib.py
</span><span class="kn">import</span> <span class="nn">logging</span>


<span class="k">def</span> <span class="nf">func</span><span class="p">():</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"info from lib"</span><span class="p">)</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"error from lib"</span><span class="p">)</span>
</code></pre></div></div>

<p>在上面我們寫了兩個python script，分別為<strong>main.py</strong>和<strong>lib.py</strong>，其中<strong>main.py</strong>會去呼叫定義在<strong>lib.py</strong>裡面的<code class="language-plaintext highlighter-rouge">func()</code>，這時如果去執行<strong>main.py</strong>的話會得到下面的結果</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:root:info from main
ERROR:root:error from main
INFO:root:info from lib
ERROR:root:error from lib
</code></pre></div></div>

<p>在<strong>lib.py</strong>裡面設定的訊息也一樣會被顯示出來，然而美中不足的是，如果我們沒有特意在log裡面留下跟檔案有關的訊息的話，就很難從log裡面看出這個是從哪裡產生出來的log了，底下會介紹python文件當中比較建議，為每個檔案建立logger的方法。</p>

<h2 id="使用複數logger">使用複數logger</h2>

<p>在上面我們碰到了無法辨別log是從哪個module產生出來的問題，而解決這個問題的<a href="https://docs.python.org/3/howto/logging.html#advanced-logging-tutorial">建議做法</a>是對每一個module都建立專屬於他們的logger，也就是使用<code class="language-plaintext highlighter-rouge">logging.getLogger()</code>來建立logger以後，再用logger來紀錄我們的訊息。</p>

<p>這邊我們把上面例子中的<code class="language-plaintext highlighter-rouge">logging</code>都替換成<code class="language-plaintext highlighter-rouge">logger</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main.py
</span><span class="kn">import</span> <span class="nn">logging</span>

<span class="kn">from</span> <span class="nn">lib</span> <span class="kn">import</span> <span class="n">func</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"info from main"</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"error from main"</span><span class="p">)</span>
    <span class="n">func</span><span class="p">()</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lib.py
</span><span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">func</span><span class="p">():</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"info from lib"</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"error from lib"</span><span class="p">)</span>
</code></pre></div></div>

<p>這邊我們將<code class="language-plaintext highlighter-rouge">__name__</code>傳入<code class="language-plaintext highlighter-rouge">logging.getLogger()</code>當中，這時logging就會幫我們建立一個以<code class="language-plaintext highlighter-rouge">__name__</code>為名稱的logger，而<code class="language-plaintext highlighter-rouge">__name__</code>會在python裡面被代換成檔案名稱，這時再執行<strong>main.py</strong>就能得到以下的結果</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:__main__:info from main
ERROR:__main__:error from main
INFO:lib:info from lib
ERROR:lib:error from lib
</code></pre></div></div>

<p>如此便能方便地知道這個log是從哪個module產生的了。</p>

<h2 id="logger的階層">Logger的階層</h2>

<p>在上面的例子裡面我們建立了兩個logger，分別是<code class="language-plaintext highlighter-rouge">__main__</code>和<code class="language-plaintext highlighter-rouge">lib</code>，這兩個logger不會各自將訊息直接印出來，而是將訊息傳到他們上層的logger，讓上層logger中的handler來決定log要怎麼被處理，在這個例子裡面它們會將log傳給<code class="language-plaintext highlighter-rouge">root</code>這個logger，再去看<code class="language-plaintext highlighter-rouge">root</code>裡面的handler的設定來去做處理，詳細的處理流程可以參考<a href="https://docs.python.org/3/howto/logging.html#logging-flow">文件</a></p>

<p><img src="https://docs.python.org/3/_images/logging_flow.png" alt="Logging Flow" /></p>

<p>雖然在程式碼裡面看起來我們沒有為root logger設定任何handler，但其實在我們呼叫<code class="language-plaintext highlighter-rouge">logging.basicConfig()</code>的時候它就會<a href="https://docs.python.org/dev/library/logging.html#logging.basicConfig">自動幫我們建立好</a>，如果想要自行設定的話也可以使用<code class="language-plaintext highlighter-rouge">logging.getLogger()</code>，在其中不給任何的參數來拿到root logger，接著再透過<code class="language-plaintext highlighter-rouge">logger.addHandler()</code>來去新增handler。</p>

<h2 id="logging-format">Logging Format</h2>

<p>如果說我們想要自定義顯示出來的log的格式的話，可以在<code class="language-plaintext highlighter-rouge">logging.basicConfig()</code>的地方設定root logger中handler印出log的格式，因為底下的logger會把log往上傳給root logger，所以只需要在root logger中設定好，所有印出來的log都會是一樣的格式。</p>

<p>假如我們在<strong>main.py</strong>裡面多加個參數</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">logging</span>

<span class="kn">from</span> <span class="nn">lib</span> <span class="kn">import</span> <span class="n">func</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"info from main"</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"error from main"</span><span class="p">)</span>
    <span class="n">func</span><span class="p">()</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">log_format</span><span class="o">=</span><span class="s">"%(asctime)s %(filename)s:%(lineno)d - %(message)s"</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">log_format</span><span class="p">)</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div></div>

<p>而<strong>lib.py</strong>維持不變，這時印出來的訊息就會變成</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-06-04 23:02:58,775 main.py:8 - info from main
2022-06-04 23:02:58,775 main.py:9 - error from main
2022-06-04 23:02:58,775 lib.py:6 - info from lib
2022-06-04 23:02:58,775 lib.py:7 - error from lib
</code></pre></div></div>

<p>更多logging支援的attribute，可以看其<a href="https://docs.python.org/3/library/logging.html#logrecord-attributes">官方文件</a>。</p>]]></content><author><name>Your Name</name></author><category term="Tool" /><category term="Python" /><summary type="html"><![CDATA[這篇文章簡單介紹一下python logging這個package的使用方法。]]></summary></entry><entry><title type="html">MLflow介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/29/mlflow-introduction/" rel="alternate" type="text/html" title="MLflow介紹" /><published>2022-05-29T00:00:00+00:00</published><updated>2022-05-29T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/29/mlflow-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/29/mlflow-introduction/"><![CDATA[<p>隨著機器學習的興起，有越來越多人嘗試引入MLOps在系統當中，這篇文章簡單介紹一下MLflow的使用心得。</p>

<!--more-->

<h2 id="mlops">MLOps</h2>

<p>在開始介紹MLflow之前先簡單介紹一下MLOps想要做的事情，MLOps可以說跟DevOps一樣是一種精神，主要是希望能讓Machine Learning跟Operations能夠合作的更融洽，這邊Machine Learning的部分包含了對資料清理、建立並訓練模型、驗證模型成效等等的事情，而Operations指的是把模型部署到系統裡面進行預測。</p>

<p><img src="https://cloud.google.com/architecture/images/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-2-manual-ml.svg" alt="MLOps Manual Process" /></p>

<p><em><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#devops_versus_mlops">MLOps: Continuous delivery and automation pipelines in machine learning</a></em></p>

<p>上圖是一個簡單的pipeline，左半邊ML的部分是一般machine learning的流程，包含了資料處理和建立模型的過程，而最終產生的模型會放進model registry裡面，Operations再從model registry裡面把模型拿出來做serving。</p>

<p>這個pipeline簡單有效，但如果未來有新的資料進來或是模型的成效開始下降等可能會需要重新訓練的模型的情況發生的話，Operations就會需要再請ML的人幫忙訓練模型，為此另一個比較穩定的pipeline可以是如下圖。</p>

<p><img src="https://cloud.google.com/architecture/images/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-3-ml-automation-ct.svg" alt="MLOps Pipeline Automation" /></p>

<p><em><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#devops_versus_mlops">MLOps: Continuous delivery and automation pipelines in machine learning</a></em></p>

<p>在這個pipeline裡面，ML所交付的不再是一個模型，而是產生出這個模型的pipeline，包含了資料驗證、清理、建立模型、驗證模型等，而Operations會將這個pipeline部署到系統裡面自行去產生模型出來，如果說有新的資料或是有需要重新訓練模型的情況發生，Operations就能直接重跑這個pipeline來得到新的模型。</p>

<p>然而要建立這種pipeline會需要花費蠻多工夫的，而MLflow可以幫助我們降低一些建立這種pipeline的困難。</p>

<h2 id="mlflow">MLflow</h2>

<p><a href="https://mlflow.org/">MLflow</a>是一個開源的平台，主要是應用在machine learning lifecycle當中，MLflow包含了四個部分</p>

<ul>
  <li>
    <p>Tracking：用以記錄在訓練模型是所使用的參數和訓練過程中的一些metrics</p>
  </li>
  <li>
    <p>Projects：讓使用者可以建立一套pipeline來讓其他人可以輕易地重現出模型</p>
  </li>
  <li>
    <p>Models：把模型包裝起來，在裡面會紀錄讓模型運行所需要的環境和模型本身，讓其他人方便直接使用模型</p>
  </li>
  <li>
    <p>Registry：存放模型並支援版本控制</p>
  </li>
</ul>

<p>底下的文章將會簡述一下Tracking和Projects的部分。</p>

<h3 id="mlflow-tracking">MLflow Tracking</h3>

<p>我們先快速看一下底下的程式碼</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">mlflow</span> <span class="kn">import</span> <span class="n">log_metric</span><span class="p">,</span> <span class="n">log_param</span><span class="p">,</span> <span class="n">log_artifact</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="c1"># Log a parameter (key-value pair)
</span>    <span class="n">log_param</span><span class="p">(</span><span class="s">"param1"</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
    <span class="n">log_param</span><span class="p">(</span><span class="s">"param2"</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="c1"># Log a metric; metrics can be updated throughout the run
</span>    <span class="n">log_metric</span><span class="p">(</span><span class="s">"foo"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">log_metric</span><span class="p">(</span><span class="s">"foo"</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">log_metric</span><span class="p">(</span><span class="s">"foo"</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="c1"># Log an artifact (output file)
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"output1.txt"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"first file!"</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"output2.txt"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">"second file!"</span><span class="p">)</span>
    <span class="n">log_artifact</span><span class="p">(</span><span class="s">"output1.txt"</span><span class="p">)</span>
    <span class="n">log_artifact</span><span class="p">(</span><span class="s">"output2.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>在上面的程式碼中我們可以看到mlflow提供了三種不同log的function，<code class="language-plaintext highlighter-rouge">log_param</code>用來記錄這次訓練模型時所使用的hyperparameters像是learning rate、batch size等等，而<code class="language-plaintext highlighter-rouge">log_metric</code>用來記錄訓練模型中會變動的資料，像是loss、accuracy等，最後<code class="language-plaintext highlighter-rouge">log_artifact</code>會把該路徑的檔案放進artifact中，主要是把這次訓練完成以後想要留存的檔案儲存下來，像是模型本身、前處理/後處理用到的字典檔等。</p>

<p>有了這些function以後，我們就能在編寫程式的時候把這些function安插進來，之後就能在command line上面下<code class="language-plaintext highlighter-rouge">mlflow server</code>的指令來打開mlflow的UI來檢視訓練的成果，然而每次手動寫這些function有點麻煩，mlflow有另外提供了auto tracking的功能，只需要在程式碼裡面加個幾行，mlflow就會幫你自動紀錄這些參數和結果了。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""Trains and evaluate a simple MLP
on the Reuters newswire topic classification task.
"""</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">reuters</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>

<span class="c1"># The following import and function call are the only additions to code required
# to automatically log metrics and parameters to MLflow.
</span><span class="kn">import</span> <span class="nn">mlflow.keras</span>

<span class="n">mlflow</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">autolog</span><span class="p">()</span>

<span class="n">max_words</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Loading data..."</span><span class="p">)</span>
</code></pre></div></div>

<p><em><a href="https://github.com/mlflow/mlflow/blob/master/examples/keras/train.py">mlflow/examples/keras/train.py</a></em></p>

<p>在上面是一個用keras訓練模型的範例，在裡面我們只需要加入<code class="language-plaintext highlighter-rouge">import mlflow.keras</code>、<code class="language-plaintext highlighter-rouge">mlflow.keras.autolog()</code>這兩行就能讓mlflow幫我們紀錄參數了。</p>

<p><img src="./mlflow_keras.png" alt="MLflow Keras" /></p>

<h3 id="mlflow-projects">MLflow Projects</h3>

<p>假如我們想要分享我們訓練模型所做的所有步驟，我們可以寫一個<code class="language-plaintext highlighter-rouge">MLproject</code>的檔案，來讓其他人可以簡單下一個指令<code class="language-plaintext highlighter-rouge">mlflow run .</code>就能重現模型訓練的結果。</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">mnist-autolog-example</span>

<span class="na">conda_env</span><span class="pi">:</span> <span class="s">conda.yaml</span>

<span class="na">entry_points</span><span class="pi">:</span>
  <span class="na">main</span><span class="pi">:</span>
    <span class="na">parameters</span><span class="pi">:</span>
      <span class="na">max_epochs</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type</span><span class="pi">:</span> <span class="nv">int</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="nv">5</span><span class="pi">}</span>
      <span class="na">gpus</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type</span><span class="pi">:</span> <span class="nv">int</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="nv">0</span><span class="pi">}</span>
      <span class="na">strategy</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type str</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="s2">"</span><span class="s">None"</span><span class="pi">}</span>
      <span class="na">batch_size</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type</span><span class="pi">:</span> <span class="nv">int</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="nv">64</span><span class="pi">}</span>
      <span class="na">num_workers</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type</span><span class="pi">:</span> <span class="nv">int</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="nv">3</span><span class="pi">}</span>
      <span class="na">learning_rate</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type</span><span class="pi">:</span> <span class="nv">float</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="nv">0.001</span><span class="pi">}</span>
      <span class="na">patience</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type int</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="nv">3</span><span class="pi">}</span>
      <span class="na">mode</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type str</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="s1">'</span><span class="s">min'</span><span class="pi">}</span>
      <span class="na">verbose</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type bool</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="nv">True</span><span class="pi">}</span>
      <span class="na">monitor</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">type str</span><span class="pi">,</span> <span class="nv">default</span><span class="pi">:</span> <span class="s1">'</span><span class="s">val_loss'</span><span class="pi">}</span>

    <span class="na">command</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">python mnist_autolog_example.py \</span>
            <span class="s">--max_epochs {max_epochs} \</span>
            <span class="s">--gpus {gpus} \</span>
            <span class="s">--strategy {strategy} \</span>
            <span class="s">--batch_size {batch_size} \</span>
            <span class="s">--num_workers {num_workers} \</span>
            <span class="s">--lr {learning_rate} \</span>
            <span class="s">--es_patience {patience} \</span>
            <span class="s">--es_mode {mode} \</span>
            <span class="s">--es_verbose {verbose} \</span>
            <span class="s">--es_monitor {monitor}</span>
</code></pre></div></div>

<p><em><a href="https://github.com/mlflow/mlflow/blob/master/examples/pytorch/MNIST/MLproject">mlflow/examples/pytorch/MNIST/MLproject</a></em></p>

<p>MLflow在讀取這個檔案的時候會先在conda裡面建立一個virtual environment，並按照<code class="language-plaintext highlighter-rouge">conda.yaml</code>的設定來去安裝package們，接下來會去執行entry_points裡面<code class="language-plaintext highlighter-rouge">main</code>的部分，如果說想要使用不同的參數試試看的話，可以使用<code class="language-plaintext highlighter-rouge">mlflow run . -P PARAM=VALUE</code>的方式來去替換掉預設值。</p>

<p>如果在整個pipeline中還有其他資料處理或模型驗證的步驟，可以參考<a href="https://github.com/mlflow/mlflow/tree/master/examples/multistep_workflow">multistep_workflow</a>的範例。</p>

<h2 id="結論">結論</h2>

<p>要把整個pipeline包裝成可重複執行的程式碼還是需要蠻多工夫的，好在MLflow可以幫我們省去一些，而且其auto tracking的功能也很適合在做實驗的過程當中來使用。</p>

<p>另外在實作的過程當中值得一提的是，如果想要在auto tracking當中另外手動存入其他artifact，需要把<code class="language-plaintext highlighter-rouge">log_artifact</code>這個function放在同一個run裡面</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">mlflow</span><span class="p">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">autolog</span><span class="p">()</span>
    <span class="c1"># Training
</span>    <span class="n">mlflow</span><span class="p">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="s">"PATH_TO_ARTIFACT"</span><span class="p">)</span>
</code></pre></div></div>

<p>而在pipeline處理的過程中，假如說我們有個entry point是處理資料、另一個entry point是訓練模型，我們應該會希望每次pipeline跑起來便去檢查資料是否已經處理好了，如果已經處理好就直接跑訓練模型的部分就好，我目前還沒有在MLflow看到比較好的看有沒有執行過某個entry point的方法，可能還是需要像前面<a href="https://github.com/mlflow/mlflow/tree/master/examples/multistep_workflow">multistep_workflow</a>的範例那樣，自己寫個<code class="language-plaintext highlighter-rouge">main.py</code>來去檢查。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li>
    <p><a href="https://medium.com/ai-blog-tw/%E7%B5%A6ml-engineer%E7%9A%84mlops%E7%B0%A1%E8%BF%B0-%E6%8C%81%E7%BA%8C%E9%96%8B%E7%99%BC%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92service%E7%9A%84%E9%AB%98%E6%95%88%E7%90%86%E5%BF%B5-8bd552876299">給ML Engineer的MLOps簡述: 持續開發機器學習Service的高效理念</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#devops_versus_mlops">MLOps: Continuous delivery and automation pipelines in machine learning</a></p>
  </li>
</ul>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[隨著機器學習的興起，有越來越多人嘗試引入MLOps在系統當中，這篇文章簡單介紹一下MLflow的使用心得。]]></summary></entry><entry><title type="html">Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/14/Learning-Hierarchy-Aware-Knowledge-Graph-Embeddings-for-Link-Prediction/" rel="alternate" type="text/html" title="Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction" /><published>2022-05-14T00:00:00+00:00</published><updated>2022-05-14T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/14/Learning-Hierarchy-Aware-Knowledge-Graph-Embeddings-for-Link-Prediction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/14/Learning-Hierarchy-Aware-Knowledge-Graph-Embeddings-for-Link-Prediction/"><![CDATA[<p>簡單記錄一下看完這篇paper的筆記。</p>

<!--more-->

<p><a href="https://arxiv.org/abs/1911.09419">這篇paper</a>是AAAI 2020中被發表的paper，相較於其他knowledge graph的paper，這篇paper把所有的entity都放進極座標當中，希望讓模型學習到越內層的entity是階層中比較高的，越外層的eneity是階層中比較低的。</p>

<h2 id="hierarchy-aware-knowledge-graph-embedding-hake">Hierarchy-Aware Knowledge Graph Embedding (HAKE)</h2>

<p><img src="./model_illustration.png" alt="Model Illustration" /></p>

<h3 id="annotation">Annotation</h3>

<p>在輸入給模型的資料當中，主要會是各個entity之間的relation，寫作<code class="language-plaintext highlighter-rouge">(head, relation, tail)</code>，指得是說<code class="language-plaintext highlighter-rouge">head</code>和<code class="language-plaintext highlighter-rouge">tail</code>之間有<code class="language-plaintext highlighter-rouge">relation</code>，而<code class="language-plaintext highlighter-rouge">head</code>是比較上層的，以上面圖片中的例子來說，可能的資料會是</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">(Device,</span><span class="w"> </span><span class="err">has_function,</span><span class="w"> </span><span class="err">Source)</span><span class="w">
</span><span class="err">(Device,</span><span class="w"> </span><span class="err">has_function,</span><span class="w"> </span><span class="err">Support)</span><span class="w">
</span><span class="err">(Source,</span><span class="w"> </span><span class="err">has_object,</span><span class="w"> </span><span class="err">Lamp)</span><span class="w">
</span><span class="err">(Source,</span><span class="w"> </span><span class="err">has_object,</span><span class="w"> </span><span class="err">Light)</span><span class="w">
</span><span class="err">...</span><span class="w">
</span></code></pre></div></div>

<p>在paper裡面我們會給每一個<code class="language-plaintext highlighter-rouge">head</code>、<code class="language-plaintext highlighter-rouge">relation</code>和<code class="language-plaintext highlighter-rouge">tail</code>各一個embedding，分別寫作$\mathbf{h}$、$\mathbf{r}$和$\mathbf{t}$，其中因為作者想要將embedding存在在極座標當中，所以每一個embedding都會存在有modulus和phase的這兩個部分，以head的embedding為例，他們分別會被寫作$\mathbf{h}_m$、$\mathbf{h}_p$。</p>

<h3 id="modulus-distance">Modulus Distance</h3>

<p>在計算兩個embedding相似性的時候，會把modulus和phase這兩個部分拆開來看，我們會希望$\mathbf{h}_m$在經過relation的轉換以後，越像$\mathbf{t}_m$越好，亦即</p>

\[\mathbf{h}_m \circ \mathbf{r}_m = \mathbf{t}_m\]

<p>而距離的部分就是看實際上跟預期的落差有多少</p>

\[d_{r,m}(\mathbf{h}_m, \mathbf{t}_m)=\left\| \mathbf{h}_m\circ\mathbf{r}_m-\mathbf{t}_m\right\|_2\]

<p>其中值得一提的是，雖然embedding本身可以有負值，但$\mathbf{r}_m$的部分會限制裡面所有的值都必須要大於零，原因是因為我們想要階層比較高的entity在接近原點的位置，由於$[\mathbf{r}_m]_i&gt;0$的特性，模型漸漸地就會將階層低的embedding往外推了。</p>

<h3 id="phase-distance">Phase Distance</h3>

<p>在phase的部分跟modulus差不多，我們希望$\mathbf{h}_p$在經過relation的轉換以後，越像$\mathbf{t}_p$越好</p>

\[(\mathbf{h}_p+\mathbf{r}_p)\mod 2\pi=\mathbf{t}_p,\ where\ \mathbf{h}_p,\mathbf{r}_p,\mathbf{t}_p\in[0,2\pi)^k\]

<p>距離上也是看兩者相差多少</p>

\[d_{r,p}(\mathbf{h}_p, \mathbf{t}_p)=\left\| \sin((\mathbf{h}_p+\mathbf{r}_p-\mathbf{t}_p)/2)\right\|_1\]

<h3 id="loss-function">Loss Function</h3>

<p>上面分別定義了modulus distance和phase distance，兩個entity實際的距離便可定義成</p>

\[d_r(\mathbf{h},\mathbf{t})=d_{r,m}(\mathbf{h}_m,\mathbf{t}_m)+\lambda d_{r,p}(\mathbf{h}_p,\mathbf{t}_p)\]

<p>其中的$\lambda$是由model自行學出的參數（$\lambda\in\mathbb{R}$），而loss function便是用self-adversarial的loss，希望positive sample的距離要小於$\gamma$，negative sample的距離要大於$\gamma$</p>

\[L=-\log\sigma(\gamma-d_r(\mathbf{h},\mathbf{t}))-\sum\limits^{n}\limits_{i=1}p(h'_i,r,t'_i)\log\sigma(d_r(\mathbf{h}'_i,\mathbf{t}'_i)-\gamma)\]

\[p(h'_j,r,y'_j\vert\left\{(h_i,r_i,t_i)\right\})=\frac{\exp\alpha f_r(\mathbf{h}'_j,\mathbf{t}'_j)}{\sum_i\exp\alpha f_r(\mathbf{h}'_i,\mathbf{t}'_i)},\ where\ \alpha\ is\ temperature\]

\[f_r(\mathbf{h},\mathbf{t})=-d_r(\mathbf{h},\mathbf{t})=-d_{r,m}(\mathbf{h},\mathbf{t})-\lambda d_{r,p}(\mathbf{h},\mathbf{t})\]

<h2 id="experiments">Experiments</h2>

<p>作者把這個HAKE模型使用在底下三個dataset上，它們的一些數據放在底下的表格中。</p>

<p><img src="./datasets.png" alt="Datasets" /></p>

<p><img src="./results.png" alt="Results" /></p>

<p>上面是與其他模型在這三個dataset上的比較，可以看到HAKE的表現不俗。</p>]]></content><author><name>Your Name</name></author><category term="Paper" /><category term="Graph-Model" /><summary type="html"><![CDATA[簡單記錄一下看完這篇paper的筆記。]]></summary></entry><entry><title type="html">Superset介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/02/superset-introduction/" rel="alternate" type="text/html" title="Superset介紹" /><published>2022-05-02T00:00:00+00:00</published><updated>2022-05-02T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/02/superset-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/05/02/superset-introduction/"><![CDATA[<p>這篇文章簡單記錄一下如何安裝superset並從Google Sheets和CSV當中匯入資料做成dashboard。</p>

<!--more-->

<h2 id="superset簡介">Superset簡介</h2>

<p>Superset是個最早由Airbnb開發，後來開源到Apache的businese intelligence工具，讓使用者可以方便地視覺化資料庫裡面的資料，而這邊的資料庫除了常見的PostgreSQL、Hive以外，還支援從Google Sheets和使用者上傳的CSV來當作資料的源頭。</p>

<h2 id="安裝superset">安裝Superset</h2>

<p>這邊放上我安裝時使用的指令，其他的安裝方法或詳細的介紹可以參考<a href="https://superset.apache.org/docs/installation/installing-superset-from-scratch">官方的安裝文件</a>。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> gcc gcc-c++ libffi-devel python-devel python-pip python-wheel openssl-devel cyrus-sasl-devel openldap-devel bzip2-devel xz-devel
pip3 <span class="nb">install</span> <span class="nt">--upgrade</span> pip
pip3 <span class="nb">install </span>apache-superset <span class="nv">MarkupSafe</span><span class="o">==</span>2.0.1
<span class="c"># Recompile python if is shows python cannot import bz2</span>

<span class="nb">export </span><span class="nv">FLASK_APP</span><span class="o">=</span>superset
superset db upgrade

<span class="c"># Create default roles and permissions</span>
superset init

<span class="c"># Create an admin user in your metadata database (use `admin` as username to be able to load the examples)</span>
superset fab create-admin

<span class="c"># Load some data to play with</span>
superset load_examples

<span class="c"># To start a development web server on port 8088, use -p to bind to another port</span>
superset run <span class="nt">-p</span> 8088 <span class="nt">--with-threads</span> <span class="nt">--reload</span> <span class="nt">--debugger</span>
</code></pre></div></div>

<p>在上面的指令中，我們有建立了一個admin帳號，其帳號密碼都是<code class="language-plaintext highlighter-rouge">admin</code>，並在最後一行的指令啟動了superset，這時理論上連到<code class="language-plaintext highlighter-rouge">localhost:8088</code>就能看到superset的UI了。</p>

<h2 id="製作dashboard流程">製作Dashboard流程</h2>

<p>在superset裡面要製作最後的dashboard前有幾個步驟需要先執行：</p>

<ol>
  <li>
    <p>建立Database：與database建立連線，讓superset能從database裡面撈取資料出來。</p>
  </li>
  <li>
    <p>建立Dataset：從database裡面引入table，在database裡面可能有千千萬萬個table，這邊我們需要告訴superset我們有興趣的table是哪些，只把有興趣的table schema引入到superset裡面。</p>
  </li>
  <li>
    <p>製作chart：引入了table以後，就能寫SQL或是用預先定義好的metric（$SUM(\star)$、$COUNT(\star)$）來視覺化table的資訊。</p>
  </li>
  <li>
    <p>製作dashboard：把前一個步驟製作的chart的呈現在一個dashboard中，方便一次瀏覽多個table視覺化的結果。</p>
  </li>
</ol>

<h2 id="建立database">建立Database</h2>

<p>底下介紹如何使用連結Google Sheets和PostgreSQL這兩個database，如果想要連結其他database的話，可以參考<a href="https://superset.apache.org/docs/databases/installing-database-drivers">官方文件</a>。由於superset主要是由python所編寫的，為了要能跟database做連線，我們需要安裝相關database的python API，在文件裡面有建議要安裝哪些套件。</p>

<h3 id="google-sheets">Google Sheets</h3>

<h4 id="安裝driver">安裝driver</h4>

<p>因為在 前面是透過<code class="language-plaintext highlighter-rouge">pip3 install</code>來安裝superset的，所以在這邊也只需要簡單的安裝pip package就能讓superset使用了，不過有可能會需要重新啟動superset來讓它吃到最新的API。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>shillelagh
</code></pre></div></div>

<h4 id="引入database">引入database</h4>

<p>在安裝好Google Sheets driver以後，在superset的UI上面點選<code class="language-plaintext highlighter-rouge">Data&gt;Databases</code>，在右邊可以看到新增Database的按鈕，點下去以後理論上就能看到<code class="language-plaintext highlighter-rouge">Google Sheets</code>的選項了。</p>

<p><img src="./supported_databases_google_sheets.png" alt="Supported Databases - Google Sheets" /></p>

<p>在下一個畫面當中只要填上相對應的名稱和網址就能順利建立了，需要注意的是Google Sheets的權限必須要設定成所有人都能觀看才能引入，如果想要讓私人的Google Sheets能被superset讀取的話，可以參考<a href="https://docs.preset.io/docs/google-sheets-private-connection">這篇文章</a>，另外Google Sheets裡面每一個不同的tab都需要手動新增進來，假如說我們想要引入這個sheets裡面的<code class="language-plaintext highlighter-rouge">Simple sheet</code>、<code class="language-plaintext highlighter-rouge">2 header sheet</code>和<code class="language-plaintext highlighter-rouge">birth_names</code>的話，就會需要填寫以下的設定。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name: simple sheet
URL: https://docs.google.com/spreadsheets/d/1_rN3lm0R_bU3NemO0s9pbFkY5LQPcuy1pscv8ZXPtg8/edit#gid<span class="o">=</span>0

Name: 2 header sheet
URL: https://docs.google.com/spreadsheets/d/1_rN3lm0R_bU3NemO0s9pbFkY5LQPcuy1pscv8ZXPtg8/edit#gid<span class="o">=</span>1077884006

Name: birth names
URL: https://docs.google.com/spreadsheets/d/1_rN3lm0R_bU3NemO0s9pbFkY5LQPcuy1pscv8ZXPtg8/edit#gid<span class="o">=</span>174770703
</code></pre></div></div>

<h3 id="postgresql">PostgreSQL</h3>

<h4 id="安裝postgresql">安裝PostgreSQL</h4>

<p>安裝PostgreSQL的方式在不同的OS上不太一樣，這邊貼上我安裝時使用的指令。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm
<span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> postgresql14-server
<span class="nb">sudo</span> /usr/pgsql-14/bin/postgresql-14-setup initdb
<span class="nb">sudo </span>systemctl <span class="nb">enable </span>postgresql-14
<span class="nb">sudo </span>systemctl start postgresql-14
</code></pre></div></div>

<p>安裝好PostgreSQL以後，我們需要在其中建立使用者帳號，可以參考底下的指令，記得將<code class="language-plaintext highlighter-rouge">USER_NAME</code>替換成自己的帳號名稱。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo</span> <span class="nt">-i</span> <span class="nt">-u</span> postgres
createuser USER_NAME
createdb USER_NAME
</code></pre></div></div>

<p>如果順利的話，理論上在自己帳號底下執行<code class="language-plaintext highlighter-rouge">psql</code>應該就能進入PostgreSQL的介面了，這時我們需要幫這個帳號設定一個密碼方便superset來登入。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># In psql command line</span>
alter user USER_NAME password <span class="s1">'PASSWORD'</span><span class="p">;</span>
</code></pre></div></div>

<h4 id="安裝driver-1">安裝driver</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>psycopg2-binary
</code></pre></div></div>

<h4 id="引入database-1">引入database</h4>

<p>安裝好driver以後，在按下新增database的按鈕時，應該就能看到PostgreSQL的選項了，這邊貼上預設的設定，理論上把<code class="language-plaintext highlighter-rouge">USER_NAME</code>、<code class="language-plaintext highlighter-rouge">PASSWORD</code>替換成自行設定的值後按下connect就可以了。</p>

<p><img class="image image--xl" src="./postgresql_database_settings.png" /></p>

<p>如果希望讓superset支援CSV上傳的功能，需要在<code class="language-plaintext highlighter-rouge">ADVANCED</code>的設定中的<code class="language-plaintext highlighter-rouge">Security</code>裡面勾選<code class="language-plaintext highlighter-rouge">Allow data upload</code>的選項，上傳的CSV會在PostgreSQL裡面建立一張新的table。</p>

<h2 id="建立dataset">建立Dataset</h2>

<p>在成功引入database以後，在<code class="language-plaintext highlighter-rouge">Data&gt;Datasets</code>裡面按下新增Dataset的按鈕，選擇好database就能看到前面引入的database裡面的table們了，點選<code class="language-plaintext highlighter-rouge">ADD</code>以後就能在chart裡面讀取這些table的資料。</p>

<p><img class="image image--xl" src="./add_dataset.png" /></p>

<h2 id="製作chart">製作Chart</h2>

<p>成功引入dataset以後，在create chart的部分就能找到先前引入的dataset了，接著就能根據想看的資訊來做出漂亮的圖表。</p>

<p><img src="./create_new_chart.png" alt="Create New Chart" /></p>

<p><img src="./chart_settings.png" alt="Chart Settings" /></p>

<h2 id="製作dashboard">製作Dashboard</h2>

<p>在把table的資訊視覺化成chart以後，如果想要將多個chart顯示在同一個畫面可以使用dashboard，在建立dashboard的畫面裡面可以用拖曳的方式來把想要顯示的chart放進來。</p>

<p><img src="./dashboard_settings.png" alt="Dashboard Settings" /></p>

<p>最後按下Save就大功告成了。</p>

<p><img src="./dashboard_demo.png" alt="Dashboard Demo" /></p>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[這篇文章簡單記錄一下如何安裝superset並從Google Sheets和CSV當中匯入資料做成dashboard。]]></summary></entry><entry><title type="html">Airflow介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/02/26/airflow-introduction/" rel="alternate" type="text/html" title="Airflow介紹" /><published>2022-02-26T00:00:00+00:00</published><updated>2022-02-26T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/02/26/airflow-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2022/02/26/airflow-introduction/"><![CDATA[<p>這篇文章紀錄一下嘗試使用Airflow的經歷。</p>

<!--more-->

<p>之前在聽一些技術分享的時候，有聽到別人使用Airflow來作為他們的排程系統，剛好在網路上也有看到別人<a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html">使用Airflow來追漫畫連載</a>，想說我也來做一個簡單的每天登入領獎勵的程式來學習Airflow怎麼使用，底下紀錄一下製作的過程。</p>

<h2 id="安裝airflow">安裝Airflow</h2>

<p><a href="https://airflow.apache.org/">Airflow</a>是由Airbnb開發的排程系統，主要是由python編寫，安裝起來也相當地方便，只需要執行底下的指令就行。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install</span> <span class="s2">"apache-airflow[crypto, slack]"</span>
</code></pre></div></div>

<h3 id="初始化database">初始化database</h3>

<p>在安裝完成以後，會需要先初始化airflow的database，這個database會用來儲存任務執行的設定和log。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># export AIRFLOW_HOME=/path/you/want</span>
airflow db init
</code></pre></div></div>

<p>預設的路徑會放在<code class="language-plaintext highlighter-rouge">~/airflow</code>，你也可以藉由<code class="language-plaintext highlighter-rouge">export AIRFLOW_HOME</code>來選擇自己喜歡的位置。</p>

<h3 id="開啟web-server">開啟web server</h3>

<p>接下來就可以準備啟動airflow了，我們可以使用底下的指令開啟web server，並設定port為8080。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow webserver <span class="nt">-p</span> 8080
</code></pre></div></div>

<p>這時就可以連去<code class="language-plaintext highlighter-rouge">localhost:8080</code>來看到airflow的使用者介面了，但進去的時候會發現要帳號密碼才能登入，我們可以透過下面的指令來創建一個權限為admin的帳戶，其帳號密碼都是<code class="language-plaintext highlighter-rouge">admin</code>。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow <span class="nb">users </span>create <span class="nt">--role</span> Admin <span class="nt">--username</span> admin <span class="nt">--email</span> admin <span class="nt">--firstname</span> admin <span class="nt">--lastname</span> admin <span class="nt">--password</span> admin
</code></pre></div></div>

<p>理論上在這個步驟做完以後就能順利地看到類似於底下的畫面了。</p>

<p><img src="./airflow_ui.png" alt="Airflow UI" /></p>

<h3 id="開啟scheduler">開啟scheduler</h3>

<p>雖說UI已經打得開了，但會發現上面的任務都沒辦法執行，原因是因為實際上排程這些任務的是scheduler，而web server就真的只是一個UI讓使用者方便使用，所以我們還需要執行底下的指令才能啟動。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow scheduler
</code></pre></div></div>

<p>scheduler和web server的關係可以參考<a href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/overview.html">airflow官方文件</a>裡面的架構圖。</p>

<p><img src="https://airflow.apache.org/docs/apache-airflow/stable/_images/arch-diag-basic.png" alt="Airflow Architecture" /></p>

<h2 id="建立屬於自己的任務">建立屬於自己的任務</h2>

<p>前面有提到airflow主要是由python來編寫的，當我們要加入一個新的任務時，我們也是寫一個python的script，並放入<code class="language-plaintext highlighter-rouge">${AIRFLOW_HOME}/dags/</code>（預設是<code class="language-plaintext highlighter-rouge">~/airflow/dags/</code>）這個路徑底下，airflow就會自動抓取你寫的script，在UI上面顯示出來。</p>

<h3 id="airflow-python-script">Airflow Python Script</h3>

<p>一個簡單的任務可以參考底下的程式碼。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">airflow.operators.python_operator</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.dummy_operator</span> <span class="kn">import</span> <span class="n">DummyOperator</span>


<span class="k">def</span> <span class="nf">login_func</span><span class="p">(</span><span class="n">account</span><span class="p">,</span> <span class="n">password</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Attempt to login with account = </span><span class="si">{</span><span class="n">account</span><span class="si">}</span><span class="s">, password = </span><span class="si">{</span><span class="n">password</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>


<span class="n">account</span> <span class="o">=</span> <span class="s">"user"</span>
<span class="n">password</span> <span class="o">=</span> <span class="s">"password"</span>
<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"owner"</span><span class="p">:</span> <span class="s">"THE_ONE"</span><span class="p">,</span>
    <span class="s">"start_date"</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s">"schedule_interval"</span><span class="p">:</span> <span class="s">"@daily"</span><span class="p">,</span>
    <span class="s">"retries"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s">"retry_delay"</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span><span class="s">"login_dag"</span><span class="p">,</span> <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    <span class="n">login</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s">"login"</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">login_func</span><span class="p">,</span>
        <span class="n">op_args</span><span class="o">=</span><span class="p">[</span><span class="n">account</span><span class="p">,</span> <span class="n">password</span><span class="p">],</span>
        <span class="n">provide_context</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">DummyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">"do_nothing"</span><span class="p">)</span>

    <span class="n">login</span> <span class="o">&gt;&gt;</span> <span class="n">end</span>
</code></pre></div></div>

<p>在上面的程式碼裡面，我們先定義了一個function，假裝是要登入某個服務，接著定義了function需要使用到的參數<code class="language-plaintext highlighter-rouge">account</code>和<code class="language-plaintext highlighter-rouge">password</code>，再來是這個任務的參數，最後是整個任務的流程。</p>

<p><a href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/operators.html">airflow提供了許許多多的operator</a>，可以根據自己的需要來去選擇哪一個operator比較適合這個任務，在定義好了operator的object以後，再透過<code class="language-plaintext highlighter-rouge">login &gt;&gt; end</code>這樣的方式來去把這些operator串在一起，這邊也支援分支，只要整個流程是一個Directed Acyclic Graph（DAG）就行。</p>

<p>值得一提的是，我在寫的時候如果把<code class="language-plaintext highlighter-rouge">with DAG(...):</code>這一段放進<code class="language-plaintext highlighter-rouge">if __name__ == "__main__"</code>的話，好像airflow就抓不到的樣子，在寫的時候需要注意一下。</p>

<h3 id="測試新加入的任務">測試新加入的任務</h3>

<p>在寫好上面的script以後，可以直接像以往寫python的方式那樣去執行看看，它並不會真的去執行，airflow會去看有沒有哪邊有語法上的錯誤。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 /path/to/your/script.py
</code></pre></div></div>

<p>如果想要實際測試看看，可以上去UI、點進job裡面，右上角有個三角形可以手動跑整個流程試試看。</p>

<p><img src="./airflow_job.png" alt="Airflow Job Page" /></p>

<p>如果跑起來有符合預期的話，就能toggle左上角的選項，啟動這個DAG，讓它根據設定的頻率來執行了。</p>

<p>值得一提的是，當開啟這個DAG以後，airflow會補跑<code class="language-plaintext highlighter-rouge">start_date</code>到今天的所有job，所以要先確定一下<code class="language-plaintext highlighter-rouge">start_date</code>有沒有設定對再開啟會比較好。</p>

<h3 id="開始的時間跟預期的不同">開始的時間跟預期的不同？</h3>

<p>在上面的script裡面，我們設定</p>

<pre><code class="language-python3">    "start_date": datetime(2022, 2, 8, 11, 0),
    "schedule_interval": "@daily",
</code></pre>

<p>期望它可以從2022/2/8的早上11點開始執行第一次，並以天為頻率來執行，但實際上會發現它第一次的執行時間會是2022/2/9的早上11點，原因是因為上面寫的是任務時間，跟實際上執行的時間不同，airflow會在<code class="language-plaintext highlighter-rouge">start_date+schedule_interval</code>的時間過完以後才開始處理<code class="language-plaintext highlighter-rouge">start_date+schedule_interval</code>的資料。</p>

<p>想法上有點類似於，我想將今天使用者的資料統整起來，並壓上今天的日期，但我實際執行統整這個動作的時間會是在明天，因為今天還沒有過完，如果今天就做統整，就會有部分的資料被漏掉。</p>

<h2 id="結論">結論</h2>

<p>Airflow是個安裝簡單、功能也很齊全的排程系統，上面敘述的部分只是airflow的九牛一毛而已，還有許許多多的功能沒有被覆蓋到，如果有興趣或是有複雜的功能想要實現，可以去看看<a href="https://airflow.apache.org/docs/apache-airflow/stable/index.html">airflow的官方文件</a>。</p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li><a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html">一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載</a></li>
</ol>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[這篇文章紀錄一下嘗試使用Airflow的經歷。]]></summary></entry><entry><title type="html">AutoKeras介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/12/23/autokeras-introduction/" rel="alternate" type="text/html" title="AutoKeras介紹" /><published>2021-12-23T00:00:00+00:00</published><updated>2021-12-23T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/12/23/autokeras-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/12/23/autokeras-introduction/"><![CDATA[<p>現在市面上有眾多AutoML的框架，而用深度學習並有Neural Architecture Search（NAS）功能的並不多，這邊紀錄一下使用AutoKeras的心得。</p>

<!--more-->

<h2 id="安裝autokeras">安裝AutoKeras</h2>

<p>安裝的方式很簡單，只需要<code class="language-plaintext highlighter-rouge">pip install</code>就行了，不過值得一提的是，在文章撰寫的當下，雖然<a href="https://autokeras.com/install/">AutoKeras的官網</a>上寫支援tensorflow 2.3.0以上的版本，但實際用tensorflow 2.7.0的時候會出現問題，建議還是先使用tensorflow 2.3.0。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span><span class="nv">tensorflow</span><span class="o">==</span>2.3.0 autokeras
</code></pre></div></div>

<h2 id="利用autokeras做text-classification">利用AutoKeras做text classification</h2>

<p>在<a href="https://autokeras.com/tutorial/overview/">AutoKeras的官網</a>上有很多tutorial來做不同的任務，像是text classification、image classification等等，這邊嘗試的是tutorial裡面的text classification，任務是sentiment analysis，給定一個評論，判斷這個評論是正面還是負面的。</p>

<h3 id="準備訓練用的資料">準備訓練用的資料</h3>

<p>底下的程式碼會去從網路上抓取dataset下來，並做成numpy，值得一提的是，文字的部分我們並沒有轉成index，而是單純的string，轉成index的部分會交由autokeras放在模型裡面。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_files</span>


<span class="k">print</span><span class="p">(</span><span class="s">"Preparing data..."</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">get_file</span><span class="p">(</span>
    <span class="n">fname</span><span class="o">=</span><span class="s">"aclImdb.tar.gz"</span><span class="p">,</span>
    <span class="n">origin</span><span class="o">=</span><span class="s">"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"</span><span class="p">,</span>
    <span class="n">extract</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># set path to dataset
</span><span class="n">IMDB_DATADIR</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="s">"aclImdb"</span><span class="p">)</span>

<span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"neg"</span><span class="p">]</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">load_files</span><span class="p">(</span>
    <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">IMDB_DATADIR</span><span class="p">,</span> <span class="s">"train"</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">classes</span>
<span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">load_files</span><span class="p">(</span>
    <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">IMDB_DATADIR</span><span class="p">,</span> <span class="s">"test"</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">classes</span>
<span class="p">)</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">target</span><span class="p">)</span>

<span class="c1"># Minimize training size for tutorial
</span><span class="n">sample_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="n">sample_size</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="n">sample_size</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Data samples..."</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (sample_size,)
</span><span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (sample_size,)
</span><span class="k">print</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">50</span><span class="p">])</span>  <span class="c1"># b'Zero Day leads you to think, even re-think why two'
</span><span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">])</span>  <span class="c1"># [1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0]
</span></code></pre></div></div>

<h3 id="訓練模型">訓練模型</h3>

<p>在這邊我們使用autokeras裡面的TextClassifier，設定<code class="language-plaintext highlighter-rouge">max_trials</code>為2，代表嘗試2種不同的模型架構，可以視情況把這個數字調大，而<code class="language-plaintext highlighter-rouge">overwrite</code>會將上次訓練的結果覆蓋掉，如果想接續上次訓練，可以改成<code class="language-plaintext highlighter-rouge">False</code>。</p>

<p>在<code class="language-plaintext highlighter-rouge">fit()</code>裡面有設定<code class="language-plaintext highlighter-rouge">epochs</code>，表示每一個模型架構會訓練多少個epoch。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">autokeras</span> <span class="k">as</span> <span class="n">ak</span>


<span class="k">print</span><span class="p">(</span><span class="s">"Building model..."</span><span class="p">)</span>
<span class="c1"># Initialize the text classifier.
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">ak</span><span class="p">.</span><span class="n">TextClassifier</span><span class="p">(</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_trials</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>  <span class="c1"># It only tries 2 models as a quick demo.
</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p>值得一提的是，<code class="language-plaintext highlighter-rouge">TextClassifier</code>可以設定模型的metrics要是什麼，預設是<code class="language-plaintext highlighter-rouge">val_loss</code>，可以依據任務的需求來做修改。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cls</span> <span class="o">=</span> <span class="n">ak</span><span class="p">.</span><span class="n">TextClassifier</span><span class="p">(</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">max_trials</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">objective</span><span class="o">=</span><span class="s">"accuracy"</span><span class="p">,</span>  <span class="c1"># Change to other metric that is suitable for your task
</span><span class="p">)</span>
</code></pre></div></div>

<p>另外，<code class="language-plaintext highlighter-rouge">TextClassifier</code>會自己去判斷label有多少個，並自己對label做index，只是在預測的時候並不會自動把index轉回原本label的樣子，建議這邊自己先用<code class="language-plaintext highlighter-rouge">sklearn.preprocessing.LabelEncoder</code>先對label做index，並在<code class="language-plaintext highlighter-rouge">fit()</code>的時候餵入轉好index的資料，之後在預測時，就可以使用<code class="language-plaintext highlighter-rouge">LabelEncoder</code>來轉回label原本的樣子。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>


<span class="c1"># Before training
</span><span class="n">labeler</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">labeler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
<span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">labeler</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s">"/path/to/labeler.pkl"</span><span class="p">,</span> <span class="s">"wb"</span><span class="p">),</span> <span class="n">pickle</span><span class="p">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

<span class="c1"># After training
</span><span class="n">labeler</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">"/path/to/labeler.pkl"</span><span class="p">,</span> <span class="s">"rb"</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">labeler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="儲存模型">儲存模型</h3>

<p>這邊會儲存表現最好的模型。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">export_model</span><span class="p">()</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">"./model"</span><span class="p">,</span> <span class="n">save_format</span><span class="o">=</span><span class="s">"tf"</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">"./model.h5"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="模型預測">模型預測</h3>

<p>autokeras輸出的模型跟一般keras訓練出來的模型相同，所以我們可以用keras的<code class="language-plaintext highlighter-rouge">load_model()</code>來讀取模型，不過會需要在後面加上<code class="language-plaintext highlighter-rouge">custom_objects</code>，把autokeras自定義的object帶進來。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s">"./model"</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">ak</span><span class="p">.</span><span class="n">CUSTOM_OBJECTS</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="結論">結論</h2>

<p>可以稍微瀏覽一下<a href="https://autokeras.com/tutorial/overview/">autokeras的tutorial</a>，如果碰到的任務種類有在裡面，可以嘗試看看，只不過會需要跑在可以連上外網的機器上，因為autokeras會去網路上抓一些pretrain的模型下來，另外也需要注意一下硬碟的使用量，因為autokeras會把每個trial訓練的模型儲存下來，很容易把硬碟吃滿，不然就是需要在<a href="https://autokeras.com/text_classifier/">ak.TextClassifier</a>裡面限制<code class="language-plaintext highlighter-rouge">max_model_size</code>的大小。</p>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[現在市面上有眾多AutoML的框架，而用深度學習並有Neural Architecture Search（NAS）功能的並不多，這邊紀錄一下使用AutoKeras的心得。]]></summary></entry><entry><title type="html">Unsupervised Speech Recognition</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/08/28/unsupervised-speech-recognition/" rel="alternate" type="text/html" title="Unsupervised Speech Recognition" /><published>2021-08-28T00:00:00+00:00</published><updated>2021-08-28T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/08/28/unsupervised-speech-recognition</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/08/28/unsupervised-speech-recognition/"><![CDATA[<p>簡單介紹一下Facebook AI Research前陣子出的、以非監督的方式來做語音辨識的<a href="https://ai.facebook.com/research/publications/unsupervised-speech-recognition">paper</a>。</p>

<!--more-->

<h2 id="model-framework">Model Framework</h2>

<p>在這篇<a href="https://ai.facebook.com/blog/wav2vec-unsupervised-speech-recognition-without-supervision/">官方的部落格文章</a>裡面有對整篇paper有個大致的介紹，也有一段影片講解這篇paper使用的方法。</p>

<p><img src="./wav2vec_u_framework.png" alt="wav2vec U Framework" /></p>

<p>上圖是這篇paper wav2vec U的整體架構，首先會先把整段語音透過wav2vec 2.0轉換成feature sequence，再來對這些feature做k-means，藉由k-means所獲得的cluster來對語音訊號做segmentation，最後將segment好的語音訊號的feature輸入至generator中轉換成phoneme sequence，搭配GAN的方式來去做訓練。</p>

<h2 id="wav2vec-20">wav2vec 2.0</h2>

<p><img src="./wav2vec_2_framework.png" alt="wav2vec 2.0 Framework" /></p>

<p>wav2vec 2.0的訓練方式跟BERT有些類似，首先會先將語音訊號透過CNN抽取出這段語音的特徵，接著對它做product quantization，在把quantization前的feature輸入進transformer以後，希望在被mask掉的位置所產生出來的feature要越像quantization後的feature越好，在訓練的時候也會拿其他時間點經過quantization後的feature來做contrasive training。</p>

<h3 id="product-quantization">Product Quantization</h3>

<p><img src="https://i.typlog.com/fabwrite/NM/ZL0fPpntjxi3pzrQirdw.png?x-oss-process=style/l" alt="Product Quantization" /></p>

<p><em><a href="http://www.fabwrite.com/productquantization">实例理解product quantization算法</a></em></p>

<p>假如說我們現在有5萬張圖片的feature，每個feature有1024維，我們將這1024維切成8份，每份有128維如上圖那樣，接著以維度為單位來做k-means，這邊令k=256，我們就可以將原先1024維的feature轉換成由8個cluster id所組成的向量，把1024維降成了8維。</p>

<h2 id="segment-representations">Segment Representations</h2>

<p>一段語音輸入進wav2vec 2.0以後，我們可以得到一串vector sequence，而作者們把所有訓練資料裡面的語音都丟進去wav2vec 2.0，將產生出來的一堆向量拿去做k-means，可以說是對每一小段語音訊號都給它一個編號。如果我們發現到說一段語音裡面相鄰兩個feature的編號相同，就可以將他們視為在同一個segment裡面，直到碰到不同編號。</p>

<p>作者們將同一個segment裡面的feature做平均來當作是這個segment的representation，值得一提的是，作者們並不是直接使用wav2vec 2.0產生出來的feature做平均，而是先對所有訓練資料經過wav2vec 2.0產生出的feature做PCA，用經過PCA轉換的feature再來做平均以後當作segment的representation。</p>

<h2 id="gan">GAN</h2>

<p><img src="./gan_framework.png" alt="GAN Framework" /></p>

<p>在得到了segment representation以後，接下來作者們將這些representation輸入進generator裡面，希望generator直接產生出phoneme distribution，這邊再搭配實際上文字的所轉換出來的phoneme 1-hot encoding，透過discriminator來讓generator產生出的phoneme distribution能越像真實的phoneme越好。另外在這邊作者們有將generator產生出來、argmax以後是相同的output再做一次平均，之後才輸入進discriminator中。</p>

<h2 id="experiment-results">Experiment Results</h2>

<p><img src="./librispeech_results.png" alt="Librispeech Results" /></p>

<p>在經過繁複的訓練流程以後，可以看到wav2vec U的表現不俗，搭配厲害的language model以後，error rate可以媲美數年前supervised learning的結果。</p>

<p><img src="./low_resource_languages_results.png" alt="Low Resource Languages Results" /></p>

<p>在low-resource上的表現甚至可以贏過supervised learning的結果。</p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li><a href="http://www.fabwrite.com/productquantization">实例理解product quantization算法</a></li>
</ol>]]></content><author><name>Your Name</name></author><category term="Paper" /><category term="Speech-Recognition" /><summary type="html"><![CDATA[簡單介紹一下Facebook AI Research前陣子出的、以非監督的方式來做語音辨識的paper。]]></summary></entry><entry><title type="html">Object Detection概論</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/25/object-detection/" rel="alternate" type="text/html" title="Object Detection概論" /><published>2021-07-25T00:00:00+00:00</published><updated>2021-07-25T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/25/object-detection</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/25/object-detection/"><![CDATA[<p>簡單整理一下目前有關object detection的一些研究。</p>

<!--more-->

<h2 id="暴力做object-detection">暴力做Object Detection</h2>

<p>隨著深度學習的興起，現在已經有各式各樣的model可以幫助我們做image classification，辨識出圖片裡面的是什麼東西。如果想要直接用這些model做物件偵測，一個簡單暴力的方式是，用不同大小的方框掃過整張圖片，把每一個方框的圖片都丟進去model裡面做物件分類來達到物件偵測的效果。</p>

<h2 id="region-with-cnnr-cnn">Region with CNN（R-CNN）</h2>

<p>在前面提到我們可以用不同的方框掃過整張圖片來做物件偵測，但這樣的效率明顯不高，而且很吃計算量，這邊要介紹的<a href="https://arxiv.org/pdf/1311.2524.pdf">R-CNN</a>便是透過Selective Search來選取可能有東西的區域，再拿去model裡面分類，其大致上的流程如下：</p>

<ol>
  <li>產生大約2000個可能有東西的區域（Region Proposals）</li>
  <li>透過預先訓練好的模型像是AlexNet、Inception等抽取圖片特徵</li>
  <li>將特徵透過SVM來去分辨裡面有沒有含有特定物體</li>
</ol>

<p><img src="./rcnn_architecture.png" alt="R-CNN Architecture" /></p>

<h3 id="selective-search">Selective Search</h3>

<p><a href="https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf">Selective search</a>是以<a href="http://cs.brown.edu/people/pfelzens/papers/seg-ijcv.pdf">Graph Based Segmentation</a>的結果為基礎，使用階層群聚演算法來得到要輸入進model的region proposal，Graph Based Segmentation在Open CV裡面有支援，使用的方式可以參考<a href="https://blog.gtwang.org/programming/opencv-graph-based-segmentation-tutorial/">這篇部落格</a>。</p>

<p>階層群聚演算法會從Graph Based Segmentation的結果裡面，每次挑選出兩個最相近的區塊做合併，而相似度的計算包含了顏色、紋理、大小等等的因素，綜合起來來判斷兩個區塊的相似度，詳細的介紹可以參考<a href="https://blog.gtwang.org/programming/selective-search-for-object-detection/">這篇部落格</a>，具體演算法的流程可以參考下圖。</p>

<p><img src="./selective_search_algorithm.png" alt="Selective Search Algorithm" /></p>

<h3 id="bounding-box-regression">Bounding-box Regression</h3>

<p>R-CNN除了使用selective search找到有可能的region proposal以外，有另外透過bounding-box regression來調整selective search框出來的bounding box。</p>

<p>對於每一個bounding box，我們可以透過\((x, y, w, h)\)​來表示，這四個數值分別代表這個bounding box中心點座標和長寬，而bounding-box regression是想要透過一個平移加縮放的mapping function \(f()\)​來把selective search得到的bounding box \((P_x, P_y, P_w, P_y)\)透過轉換以後可以越接近label好的bounding box \((G_x, G_y, G_w, G_h)\)​越好。</p>

\[f(P_x, P_y, P_w, P_y)=(\hat{G}_x, \hat{G}_y, \hat{G}_w, \hat{G}_h)\approx(G_x, G_y, G_w, G_h)\]

<p>透過將\(f()\)​弄成regression task，之後便可以透過gradient descent來訓練\(f()\)​，更詳細的說明可以參考<a href="https://blog.csdn.net/zijin0802034/article/details/77685438">這篇文章</a>。</p>

<h2 id="fast-r-cnn">Fast R-CNN</h2>

<p>在上面的R-CNN裡面，每一個region proposal都會被丟進預先訓練好的模型來抽取圖片特徵，然而很多時候region proposal之間會有重疊的部分，其實並不需要重新再算一遍，因此在<a href="https://arxiv.org/pdf/1504.08083.pdf">Fast R-CNN</a>裡面想要直接把region proposal對應到feature map中，來避免掉不必要的計算。</p>

<p><img src="./fast_rcnn_architecture.png" alt="Fast R-CNN Architecture" /></p>

<p>Fast R-CNN跟R-CNN一樣，會先需要先選好region proposal，在把圖片經過CNN得到feature map的時候，也會將選好的region proposal也投影到跟feature map一樣的大小，直接對該區塊內的feature map做max pooling後得到固定大小的feature，最後透過fully connected layers來得到region裡面物體的類別，以及對bounding box做回歸，這個方法被稱作Region of Interest Pooling（RoI Pooling）。</p>

<p><img src="https://deepsense.ai/wp-content/uploads/2017/02/roi_pooling-1.gif" alt="RoI Pooling" /></p>

<p><em><a href="https://deepsense.ai/region-of-interest-pooling-explained/">Region of interest pooling explained</a></em></p>

<h2 id="faster-r-cnn">Faster R-CNN</h2>

<p>在Fast R-CNN裡面還是會需要跑selective search來得到region proposal，而<a href="https://arxiv.org/pdf/1506.01497.pdf">Faster R-CNN</a>的想法是想要直接在CNN的feature map裡面透過Region Proposal Network來直接得到region proposal。</p>

<p>Region Proposal Network是一個CNN，它會先用個sliding window去掃過整張圖片，在每個window的中心點去套用\(k\)​​個預先定義好、不同大小的anchor box，將anchor box框出來的feature map輸入進CNN以後，predict出含有物體的機率，以及實際bounding box的座標。</p>

<p><img src="./region_proposal_network.png" alt="Region Proposal Network" /></p>

<p>其整體的架構畫出來大概長底下這樣，中間的區塊是Faster R-CNN提出來的RPN，而右邊的是原本Fast R-CNN既有的部分。</p>

<p><img src="./faster_rcnn_graph.png" alt="Faster R-CNN Graph" /></p>

<p><em><a href="https://blog.csdn.net/jiongnima/article/details/79094159">实例分割模型Mask R-CNN详解：从R-CNN，Fast R-CNN，Faster R-CNN再到Mask R-CNN</a></em></p>

<h2 id="mask-r-cnn">Mask R-CNN</h2>

<p><a href="https://arxiv.org/pdf/1703.06870.pdf">Mask R-CNN</a>在Faster R-CNN的基礎上，修改了RoI Pooling，調整成RoI Align，並多加入Mask prediction。</p>

<p><img src="./mask_rcnn_graph.png" alt="Mask R-CNN Graph" /></p>

<p><em><a href="https://blog.csdn.net/jiongnima/article/details/79094159">实例分割模型Mask R-CNN详解：从R-CNN，Fast R-CNN，Faster R-CNN再到Mask R-CNN</a></em></p>

<h3 id="roi-align">RoI Align</h3>

<p>在原本RoI Pooling的使用情境下，會需要在把region proposal投影到feature map的維度時把座標取整數，在計算max pooling的時候也需要對區塊的範圍取整數，雖然說在feature map上面取整數去除掉的零頭看起來不大，但feature map實際上是圖片經過了很多CNN，濃縮過的feature，去除掉的零頭在原本圖片上的影響其實是比想像中大的。</p>

<p>因此在Mask R-CNN裡面使用bilinear interpolation來避免掉取整數的問題，下圖中的藍色方框是CNN輸出的feature map，而黑色方框是RoI，藉由interpolation的方式來計算出要輸入至後面的feature。</p>

<p><img src="roi_align.png" alt="RoI Align" /></p>

<h3 id="mask-prediction">Mask Prediction</h3>

<p>在Mask R-CNN做的另一件事情是引入<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">Fully Convolutional Networks（FCN）</a>來做pixel-wise的mask，FCN主要是先使用CNN來對圖片做降維，之後再透過deconvolution CNN來把feature還原到圖片原本的大小，並predict出segmentation。</p>

<p><img src="./fcn_diagram.png" alt="FCN Diagram" /></p>

<h2 id="yolo">YOLO</h2>

<p>前面所提的R-CNN們都是region-based的方法，會需要先決定有可能的region proposal再往後進行下去，而<a href="https://pjreddie.com/media/files/papers/yolo.pdf">YOLO</a>是You Only Look Once的縮寫，一個region-free的方法，希望可以只跑一次CNN就同時產生出bounding box和物體的類別。</p>

<p><img src="yolo_model.png" alt="YOLO Model" /></p>

<p>首先，YOLO會先把圖片切成\(S \times S\)​個grid，並讓每一個grid都用neural network去預測\(B\)​個可能的bounding box、含有物件的信心程度以及物件的類別。在圖中上半部不同的黑框便是預測出來的bounding box，而不同的粗細表示信心程度的大小，而下半部是物件類別的預測結果。</p>

<p>在選出了有可能的bounding box和類別偵測的結果以後，會先用一個固定的threshold把信心程度太低的bounding box去除掉，然後使用Non-Maximum Supression（NMS）來計算出最後的輸出結果，NMS運作的方式可以參考<a href="https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E7%89%A9%E4%BB%B6%E5%81%B5%E6%B8%AC-non-maximum-suppression-nms-aa70c45adffa">這篇文章</a>，裡頭有詳細的圖解可以參考。</p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li><a href="https://blog.gtwang.org/programming/opencv-graph-based-segmentation-tutorial/">OpenCV 教學：實作 Graph Based Segmentation 圖形分割演算法</a></li>
  <li><a href="https://blog.gtwang.org/programming/selective-search-for-object-detection/">OpenCV 教學：實作 Selective Search 物體偵測候選區域演算法</a></li>
  <li><a href="https://blog.csdn.net/zijin0802034/article/details/77685438">边框回归(Bounding Box Regression)详解</a></li>
  <li><a href="https://ccshenyltw.medium.com/object-detection-r-cnn-fast-rcnn-faster-rcnn-mask-rcnn-retinanet-to-be-continued-71b67640445">Object Detection : R-CNN, Fast-RCNN, Faster RCNN</a></li>
  <li><a href="https://medium.com/cubo-ai/%E7%89%A9%E9%AB%94%E5%81%B5%E6%B8%AC-object-detection-740096ec4540">關於影像辨識，所有你應該知道的深度學習模型</a></li>
  <li><a href="https://blog.csdn.net/jiongnima/article/details/79094159">实例分割模型Mask R-CNN详解：从R-CNN，Fast R-CNN，Faster R-CNN再到Mask R-CNN</a></li>
  <li><a href="https://deepsense.ai/region-of-interest-pooling-explained/">Region of interest pooling explained</a></li>
  <li><a href="https://chih-sheng-huang821.medium.com/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E7%89%A9%E4%BB%B6%E5%81%B5%E6%B8%AC-you-only-look-once-yolo-4fb9cf49453c">深度學習-物件偵測:You Only Look Once (YOLO)</a></li>
  <li><a href="https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E7%89%A9%E4%BB%B6%E5%81%B5%E6%B8%AC-non-maximum-suppression-nms-aa70c45adffa">機器/深度學習: 物件偵測 Non-Maximum Suppression (NMS)</a></li>
</ol>]]></content><author><name>Your Name</name></author><category term="Computer-Vision" /><category term="Object-Detection" /><summary type="html"><![CDATA[簡單整理一下目前有關object detection的一些研究。]]></summary></entry><entry><title type="html">在遠端的job執行完成時發送通知</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/25/remote-job-finish-notification/" rel="alternate" type="text/html" title="在遠端的job執行完成時發送通知" /><published>2021-07-25T00:00:00+00:00</published><updated>2021-07-25T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/25/remote-job-finish-notification</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/25/remote-job-finish-notification/"><![CDATA[<p>這邊記錄一個方法來當server上的job跑完時，可以在MacBook上面跳出一個通知。</p>

<!--more-->

<h2 id="方法簡介">方法簡介</h2>

<p>使用的方法是透過在SSH連線至遠端server的時候，順便做port forwarding，把自己電腦的port 22接上遠端server，如此便可以讓遠端server透過SSH連線回電腦上使用command line跳出通知。</p>

<h2 id="在macbook上面允許ssh連線">在MacBook上面允許SSH連線</h2>

<p>首先，我們必須要讓MacBook可以接受SSH離線，只需要在<code class="language-plaintext highlighter-rouge">設定→共享</code>裡面打開SSH連線的設定就可以了，在<a href="https://support.apple.com/zh-tw/guide/mac-help/mchlp1066/mac">Apple官方的使用手冊</a>上有詳細的說明。</p>

<h2 id="forward-local-port">Forward Local Port</h2>

<p>在SSH連線到遠端server的時候，可以多加<code class="language-plaintext highlighter-rouge">-R</code>這個option，便可以把本機的port接到遠端server上。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh <span class="nt">-R</span> 2000:localhost:22 &lt;username&gt;@&lt;<span class="nb">hostname</span><span class="o">&gt;</span>
</code></pre></div></div>

<p>在上面的指令當中，便是將遠端server的port 2000跟本機的port 22做連結。</p>

<h2 id="從server連回本機">從Server連回本機</h2>

<p>在連上server以後，可以先試著將底下的<code class="language-plaintext highlighter-rouge">username</code>換成本機的使用者名稱測試看看能不能連回來。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh <span class="nt">-p</span> 2000 &lt;username&gt;@localhost
</code></pre></div></div>

<p>如果能順利連回來的話，接下來便是把public key放到本機裡面，以避免每次連線都要打密碼，詳細的流程看底下的步驟，主要是參考<a href="https://help.dreamhost.com/hc/en-us/articles/216499537-How-to-configure-passwordless-login-in-Mac-OS-X-and-Linux">這篇文章</a>。</p>

<ol>
  <li>
    <p>在server上使用底下的指令創造key</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ssh-keygen
</code></pre></div>    </div>
  </li>
  <li>
    <p>把創建出來，帶有<code class="language-plaintext highlighter-rouge">.pub</code>副檔名的檔案裡面所有的內容複製進本機的<strong>~/.ssh/authorized_keys</strong>這份檔案中，如果這個檔案原本不存在，可以直接用文字編輯器建立</p>
  </li>
  <li>
    <p>在server上透過key來連線至本機</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ssh <span class="nt">-i</span> &lt;path to private key&gt; <span class="nt">-p</span> &lt;port&gt; &lt;username&gt;@localhost
</code></pre></div>    </div>

    <p>預設private key的路徑會是<strong>~/.ssh/id_rsa</strong>。</p>
  </li>
</ol>

<h2 id="傳送notification">傳送Notification</h2>

<p>在能順利從server連回本機以後，就可以透過command line來傳送notification了，底下的指令是使用MacBook原生的指令來產生notification，其他argument可以參考<a href="https://code-maven.com/display-notification-from-the-mac-command-line">這篇文章</a>。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>osascript <span class="nt">-e</span> <span class="s1">'display notification "" with title "Job Finished!" subtitle ""'</span>
</code></pre></div></div>

<p>在通知跳出來以後，可以對著通知按右鍵對通知做設定。</p>

<h2 id="總結">總結</h2>

<p>上面使用了一個簡單的方式來讓server控制本機發送通知，可以將連線、發送通知寫成腳本，並在server完成job時呼叫這個腳本來提醒你job已經跑完了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>Your <span class="nb">command</span><span class="o">]</span> <span class="o">||</span> send_notification.sh
</code></pre></div></div>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li><a href="https://serverfault.com/questions/175798/ssh-back-to-the-local-machine-from-a-remote-ssh-session">SSH back to the local machine from a remote SSH session</a></li>
</ol>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[這邊記錄一個方法來當server上的job跑完時，可以在MacBook上面跳出一個通知。]]></summary></entry><entry><title type="html">深度學習於語音辨識</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/18/speech-recognition-with-deep-learning/" rel="alternate" type="text/html" title="深度學習於語音辨識" /><published>2021-07-18T00:00:00+00:00</published><updated>2021-07-18T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/18/speech-recognition-with-deep-learning</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2021/07/18/speech-recognition-with-deep-learning/"><![CDATA[<p>在<a href="https://wjohn1483.github.io/2021/06/14/introduction-to-speech-recognition/">先前的文章</a>裡頭，介紹了在深度學習蓬勃發展之前，語音辨識大概是如何達成的，而這篇文章會簡單介紹一下，在加入了深度學習以後，語音辨識的技術有了什麼樣的更動。</p>

<!--more-->

<p>過去在做語音辨識的時候，會需要不同的模型互相協作，而隨著深度學習的發展，有些語音辨識的方法已經可以將所有的模型整合成一個模型，大大簡化了語音辨識的複雜度。</p>

<h2 id="listen-attend-and-spelllas">Listen, Attend and Spell（LAS）</h2>

<p>第一個要提到的模型是LAS，是一個End-to-end的語音辨識模型，輸入語音訊號，輸出就是character。</p>

<p><img src="./LAS_model_architecture.png" alt="LAS Model Architecture" /></p>

<p>上圖為LAS模型的架構，其實就是一個sequence to sequence的model搭配attention，不過比較特別的是，在encoder也就是上圖中的Listener裡頭，使用的是pyramidal bidirectional LSTM，因為輸入的語音訊號的個數通常都遠大於輸出的字數，所以透過pyramidal的方式來減少decoder attend的數量；另一個特別的地方是，在decoder的也就是上圖中的Speller裡面，仍然會將RNN的輸出拉回來放進下一個時間點的輸入。</p>

<p>LAS的model雖然可以幫助我們做語音辨識，但這個模型需要將整個句子都聽完才可以開始辨識，如果輸入進來的語音訊號很長，或是想要對串流語音做語音辨識，就得要使用其他的方式，可以參考底下的方法。</p>

<h2 id="connectionist-temporal-classificationctc">Connectionist Temporal Classification（CTC）</h2>

<p>CTC是一種基於RNN loss function的方法，可以把比較長的輸入\(X\)轉換成比較短的輸出\(Z\)，跟語音辨識所需要的條件相同，而CTC的特點在於輸出的時候會多一個<code class="language-plaintext highlighter-rouge">blank</code>的符號，每一個時間點RNN的輸出除了可以是vocabulary裡面的字以外，還可以是<code class="language-plaintext highlighter-rouge">blank</code>，寫作<code class="language-plaintext highlighter-rouge">-</code>。</p>

<p><img src="./CTC_model_architecture.png" alt="CTC Model Architecture" /></p>

<p>假如說我們拿一段語音訊號\(X=[x_1, x_2, ..., x_T]\)輸入到LSTM裡面，每個時間點LSTM都會輸出一個長度為\(L+1\)的向量\(y_t=[y_t^{-}, y_t^1, ..., y_t^L]\)，其中\(L\)表示vocabulary的大小，雖然我們知道這整段語音訊號\(X\)所對應到的文字是\(Z=[z_1, z_2, ..., z_U]\)，但因為LSTM整個輸出的長度跟輸入長度相同，都是\(T\)，而文字的長度是\(U\)，兩者對不起來，沒辦法直接一對一對應做gradient descent，所以CTC在這裡使用了<code class="language-plaintext highlighter-rouge">blank</code>並將\(Z\)裡面的文字重複來把\(Z\)的長度擴充到跟\(T\)一樣，並搭配一個mapping function \(B()\)來把所有<code class="language-plaintext highlighter-rouge">blank</code>和相鄰的重複輸出去除掉，保留不相鄰的輸出。</p>

<p>舉例來說，假設今天放進LSTM的\(X\)長度為4，而對應的\(Z\)為\([讚, 啦]\)，我們可以透過加入<code class="language-plaintext highlighter-rouge">-</code>或重複\(Z\)裡面的字來讓長度變為4，之後再讓\(B()\)幫我們把修改過的輸出\(Z^*\)的輸出對回\(Z\)，亦即</p>

\[B([-, 讚, 啦, 啦])=[讚, 啦] \\
B([讚, 讚, 啦, 啦])=[讚, 啦] \\
B([-, 讚, 啦, -])=[讚, 啦]\]

<p>其中每一個\(B()\)的輸入\([-, 讚, 啦, 啦]\)、\([讚, 讚, 啦, 啦]\)等都可以是LSTM用來學習的目標，而我們會透過<a href="https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm">Forward-backward Algorithm</a>來將所有可能的組合都囊括進來。</p>

<p>我們將LSTM每一個時間點的輸出\(y_t\)攤開來，並取出所有在\(Z\)裡面文字的機率，再在每個label之間都插入<code class="language-plaintext highlighter-rouge">blank</code>的符號，如上圖中的上半部。在這邊，我們限定每個時間點的轉移只能往右邊或右上角走，不能往右下或左邊走，如此便可以透過Forward Algorithm將最後一個時間點的機率總和來當作觀察到輸出\(Z\)的機率\(P(Z\vert X)\)，其中每一個可能的\(Z^*\)的機率可以被表示為</p>

\[P(Z^*\vert X)=\coprod\limits_{t=1}\limits^{T}y_t^{Z^*_t}\]

<p>而\(P(Z\vert X)\)可以被表示為</p>

\[P(Z\vert X)=\sum\limits_{Z^* \in B^{-1}(Z)}P(Z^*\vert X)\]

<p>最後就可以透過底下的loss function做訓練了</p>

\[\mathcal{L}_{CTC}=-\sum\limits_{\forall(X,Z^*)\in\theta}\ln P(Z^*\vert X)\]

<p>訓練完CTC以後，就可以直接將聲音訊號餵進去，選擇每一個時間點最大的文字搭配\(B()\)當作是語音辨識的輸出，也可以使用beam search來增進performance。</p>

<h2 id="rnn-transducerrnn-t">RNN Transducer（RNN-T）</h2>

<p>在上述CTC的部分裡面，我們透過在label裡面加入<code class="language-plaintext highlighter-rouge">blank</code>來讓串流語音辨識成為可能，然而在CTC裡面，每一個時間點的輸出跟下一個時間點的輸出是互相獨立的，這會使得後面時間的要輸出的時候因為不確定前面輸出過了沒造成結巴的現象，而RNN-T所做的改動便是將上一個時間點的輸出拉回來當作是下一個時間點的輸入，並改變predict文字的方式。</p>

<p>在前面CTC的部分裡，每一個時間點LSTM會吃一個向量進來，輸出一個文字，但在RNN-T裡面，每一個時間點LSTM會重複吃一同個向量，直到predict出<code class="language-plaintext highlighter-rouge">NULL</code>以後才會吃下一個輸入。</p>

<pre><code class="language-mermaid">graph BT;
    LSTM1[LSTM]
    LSTM2[LSTM]
    LSTM3[LSTM]
    LSTM4[LSTM]
    LSTM5[LSTM]
    LSTM6[LSTM]
    i1[i1]
    i2[i2]
    i3[i3]
    o1[c]
    o2[a]
    o3[NULL]
    o4[t]
    o5[NULL]
    o6[NULL]
    i1--&gt;LSTM1
    LSTM1--&gt;o1
    i1--&gt;LSTM2
    LSTM2--&gt;o2
    i1--&gt;LSTM3
    LSTM3--&gt;o3
    i2--&gt;LSTM4
    LSTM4--&gt;o4
    i2--&gt;LSTM5
    LSTM5--&gt;o5
    i3--&gt;LSTM6
    LSTM6--&gt;o6
</code></pre>

<p>所以當輸入的語音embedding長度為\(T\)時，我們就會在對應的答案裡面加入\(T\)個<code class="language-plaintext highlighter-rouge">NULL</code>，至於要如何將\(T\)個<code class="language-plaintext highlighter-rouge">NULL</code>放進去就跟CTC的方式相同。</p>

<p>RNN-T除了predict方式的不同，還有在輸出的最後放一個language model，並把language model的輸出與下一個時間點的輸入一用餵進LSTM當中，可以看<a href="https://youtu.be/CGuLuBaLIeI?t=1870">影片中的架構</a>來獲得比較清楚的了解。</p>

<p>總的來說，RNN-T的架構如下圖，由三個部分所構成成：</p>

<ul>
  <li>Encoder：可以想成是acoustic model，也就是上面架構圖中的LSTM，計算語音訊號的特徵。</li>
  <li>Prediction Network：可以想成是language model，在<a href="https://youtu.be/CGuLuBaLIeI?t=1870">影片中的架構</a>裡面最上層的部分。</li>
  <li>Joint Network：綜合Encoder和Prediction Network的輸出決定最後的文字是什麼，在<a href="https://youtu.be/CGuLuBaLIeI?t=1870">影片中的架構</a>中是黃色的框框。</li>
</ul>

<p><img src="https://www.researchgate.net/publication/335044103/figure/fig3/AS:789632253952000@1565274408664/Recurrent-neural-network-RNN-transducer-structure-38.png" alt="RNN-T Overview" /></p>

<h2 id="neural-transducer">Neural Transducer</h2>

<p>Neural Transducer和RNN-T的作法類似，與RNN-T不同的地方在於，輸入從單一個acoustic feature變成多個acoustic feature，並在其中加入attention的機制。</p>

<p><img src="./neural_transducer_architecture.png" alt="Neural Transducer Architecture" /></p>

<p>在neural transducer裡，輸入進來的acoustic feature們會用固定大小\(W\)的window切開，分成多個block，每次模型會根據當前輸入的block中的acoustic feature來做predict，直到model predict出<code class="language-plaintext highlighter-rouge">NULL</code>以後才會輸入下一個block。</p>

<h2 id="monotonic-chunkwise-attentionmocha">Monotonic Chunkwise Attention（MoChA）</h2>

<p>MoChA又對neural transducer做了一些變形，在neural transducer裡使用固定大小的\(W\)來對acoustic feature分塊，而MoChA想讓model來自己決定block要怎麼切。</p>

<p><img src="./mocha_attention.png" alt="MoChA Attention" /></p>

<p>在上圖(a)是一般的soft attention，在輸出\(y\)的時候會對所有的input算attention。</p>

<p>圖(b)是monotonic attention，由model來決定要attend多少input，\(\otimes\)是有被選中的input，而\(\bullet\)是決定要停止的地方，下一個時間點會從上一個時間點停止的地方開始往後預測該要在哪個input停下來。</p>

<p>圖(c)是MoChA，與圖(b)的作法類似，但在這邊會設定一個window size \(W\)，在停下來的地方往前框\(W\)個feature來當作模型的輸入，在圖中的例子是設定\(W=3\)。</p>

<h2 id="總結">總結</h2>

<p>在這篇文章裡面介紹了一些End-to-end的方式來訓練語音辨識的模型，它們的辨識錯誤率跟先前的HMM-DNN hybrid模型相近，如果資料量夠大的話，end-to-end的模型還可以把錯誤率再調降，可以根據擁有的資料量來決定要使用哪一種方式來製作你的語音辨識模型。</p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li><a href="https://www.youtube.com/watch?v=CGuLuBaLIeI">[DLHLP 2020] Speech Recognition (3/7) - CTC, RNN-T and more</a></li>
  <li><a href="https://arxiv.org/pdf/1508.01211.pdf">Listen, Attend and Spell</a></li>
  <li><a href="https://www.researchgate.net/figure/Recurrent-neural-network-RNN-transducer-structure-38_fig3_335044103">Figure 4 - available via license: Creative Commons Attribution 4.0 International</a></li>
  <li><a href="https://arxiv.org/pdf/1511.04868.pdf">A Neural Transducer</a></li>
  <li><a href="https://arxiv.org/pdf/1712.05382.pdf">Monotonic Chunkwise Attention</a></li>
</ol>]]></content><author><name>Your Name</name></author><category term="Speech-Recognition" /><summary type="html"><![CDATA[在先前的文章裡頭，介紹了在深度學習蓬勃發展之前，語音辨識大概是如何達成的，而這篇文章會簡單介紹一下，在加入了深度學習以後，語音辨識的技術有了什麼樣的更動。]]></summary></entry></feed>
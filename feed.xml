<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/" rel="alternate" type="text/html" /><updated>2025-03-12T02:30:21+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/feed.xml</id><title type="html">wjohn1483.github.io</title><subtitle></subtitle><author><name>Your Name</name></author><entry><title type="html">Gradio Introduction</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2025/02/22/gradio-introduction/" rel="alternate" type="text/html" title="Gradio Introduction" /><published>2025-02-22T00:00:00+00:00</published><updated>2025-02-22T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2025/02/22/gradio-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2025/02/22/gradio-introduction/"><![CDATA[<p>在做出了令人驚艷的模型或是功能以後，為了可以讓更多人使用，需要一個UI的介面來讓大家來操作，這邊簡單介紹一個可以快速透過python做出網頁UI的套件Gradio。</p>

<!--more-->

<h2 id="gradio">Gradio</h2>

<p><a href="https://www.gradio.app/">Gradio</a>是一個python的套件，讓使用者可以透過python來快速地創造出一個網頁來展示你所製作的模型或者是其他功能，在huggingface上面有許許多多的模型就是使用Gradio來展示給大家。</p>

<p>安裝的方式很簡單，可以直接透過pip來安裝</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">--upgrade</span> gradio
</code></pre></div></div>

<h2 id="簡單的範例">簡單的範例</h2>

<p>在安裝完成以後就可以著手來製作第一個簡單的網頁了，這邊可以來看一下<a href="https://www.gradio.app/guides/quickstart#building-your-first-demo">官方文件</a>裡面的第一個範例程式碼</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># app.py
</span><span class="kn">import</span> <span class="n">gradio</span> <span class="k">as</span> <span class="n">gr</span>

<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">intensity</span><span class="p">):</span>
    <span class="k">return</span> <span class="sh">"</span><span class="s">Hello, </span><span class="sh">"</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">"</span><span class="s">!</span><span class="sh">"</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">intensity</span><span class="p">)</span>

<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Interface</span><span class="p">(</span>
    <span class="n">fn</span><span class="o">=</span><span class="n">greet</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">slider</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">demo</span><span class="p">.</span><span class="nf">launch</span><span class="p">()</span>
</code></pre></div></div>

<p>透過<code class="language-plaintext highlighter-rouge">python app.py</code>或是<code class="language-plaintext highlighter-rouge">gradio app.py</code>的方式來執行這個程式碼，兩者的差異在於<code class="language-plaintext highlighter-rouge">gradio app.py</code>會反應程式碼的改動，當你在開發的時候可以透過這個方式來開發，但開發完成以後建議使用<code class="language-plaintext highlighter-rouge">python app.py</code>的方式來host會比較好。</p>

<p>跑出來的結果會長得像下面的樣子，如果點上面官方文件的連結，可以直接在網站裡面與它互動看看</p>

<p><img src="first_demo.png" alt="First demo" /></p>

<p>在這邊我們透過字串的方式宣告了一個Interface的輸入和輸出，而且定義了一個python function <code class="language-plaintext highlighter-rouge">greet()</code>來去做邏輯的處理，需要注意<code class="language-plaintext highlighter-rouge">greet()</code>的argument的個數必須與inputs的個數相同，而<code class="language-plaintext highlighter-rouge">greet()</code>回傳的argument個數也必須與outputs的個數相同，在按下submit以後，<code class="language-plaintext highlighter-rouge">greet()</code>這個function會被執行，並將結果回傳到outputs當中，這時修改過後的文字就會出現在上方圖片右手邊的文字框裡面。</p>

<p>如果想要調整server的port，可以在<code class="language-plaintext highlighter-rouge">launch()</code>裡面加入相關的參數來設定。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">demo</span><span class="p">.</span><span class="nf">launch</span><span class="p">(</span><span class="n">server_name</span><span class="o">=</span><span class="sh">"</span><span class="s">0.0.0.0</span><span class="sh">"</span><span class="p">,</span> <span class="n">server_port</span><span class="o">=</span><span class="mi">8080</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="更細緻的操控">更細緻的操控</h3>

<p>在上面的例子裡面，我們使用了<code class="language-plaintext highlighter-rouge">Interface()</code>來幫助我們創建了一個簡單的UI出來，並指定了一個python function來處理對應的邏輯，如果你想要自行決定文字框和按鈕的排版、python function被觸發的條件，我們可以透過<code class="language-plaintext highlighter-rouge">Blocks()</code>來達成</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">gradio</span> <span class="k">as</span> <span class="n">gr</span>

<span class="k">def</span> <span class="nf">greet</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">intensity</span><span class="p">):</span>
    <span class="k">return</span> <span class="sh">"</span><span class="s">Hello, </span><span class="sh">"</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">"</span><span class="s">!</span><span class="sh">"</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">intensity</span><span class="p">)</span>

<span class="k">with</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Blocks</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Hello Gradio</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">demo</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Row</span><span class="p">():</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Name</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">intensity</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Slider</span><span class="p">(</span><span class="n">minimum</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">maximum</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Intensity</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">submit_button</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Button</span><span class="p">(</span><span class="sh">"</span><span class="s">Submit</span><span class="sh">"</span><span class="p">,</span> <span class="n">variant</span><span class="o">=</span><span class="sh">"</span><span class="s">primary</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Output</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">submit_button</span><span class="p">.</span><span class="nf">click</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">greet</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">intensity</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">])</span>
    <span class="n">name</span><span class="p">.</span><span class="nf">change</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">greet</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">intensity</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">])</span>
    <span class="n">intensity</span><span class="p">.</span><span class="nf">change</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">greet</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">intensity</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">])</span>

<span class="n">demo</span><span class="p">.</span><span class="nf">launch</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="first_demo_modified.png" alt="First demo modified" /></p>

<p>在上面的程式碼裡面，我們將<code class="language-plaintext highlighter-rouge">Interface()</code>替換成了<code class="language-plaintext highlighter-rouge">Blocks()</code>，並設定了網頁的名稱是<code class="language-plaintext highlighter-rouge">Hello Gradio</code>，同時引入了<code class="language-plaintext highlighter-rouge">Row()</code>，把在with clause底下的所有元件放在同一列裡面，而先前用字串指定的輸入輸出我們改成了gradio的物件來做更多的設定，最後對於每一個物件設定其觸發條件，<code class="language-plaintext highlighter-rouge">click()</code>為當按鈕被按下去的時候觸發，而<code class="language-plaintext highlighter-rouge">change()</code>為當元件的內容有被改變的時候就觸發，<code class="language-plaintext highlighter-rouge">Textbox()</code>還有像是<code class="language-plaintext highlighter-rouge">submit()</code>的觸發條件，當在文字框內按下enter就觸發等等，gradio有什麼元件以及各個元件有什麼可以設定及其觸發條件，可以參考<a href="https://www.gradio.app/docs/gradio/introduction">這邊的文件</a>。</p>

<h2 id="api的範例">API的範例</h2>

<p>除了使用網頁上面的UI來使用自己寫好的功能，Gradio還有提供API的方式來開放讓大家使用，我們可以透過<a href="https://www.gradio.app/guides/getting-started-with-the-python-client">python client</a>來呼叫前面寫好的<code class="language-plaintext highlighter-rouge">greet()</code> function</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">gradio_client</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="n">client</span> <span class="o">=</span> <span class="nc">Client</span><span class="p">(</span><span class="sh">"</span><span class="s">http://localhost:7860/</span><span class="sh">"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">World</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">intensity</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">api_name</span><span class="o">=</span><span class="sh">"</span><span class="s">/greet</span><span class="sh">"</span>
<span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>

<p>這邊我們使用一個URL來初始化<code class="language-plaintext highlighter-rouge">Client()</code>這個物件，接著將function需要的輸入放進去，而API的名字會對應前面在設定觸發條件時，給定的python function，可以透過網頁UI最下方<code class="language-plaintext highlighter-rouge">Use via API</code>的按鈕來查看有哪些API可以被調用。</p>

<p>除了透過python client來使用以外，Gradio還可以<a href="https://www.gradio.app/guides/querying-gradio-apps-with-curl#authentication">使用一般的curl指令</a>來呼叫</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">EVENT_ID</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-X</span> POST http://localhost:7860/gradio_api/call/greet <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> <span class="nt">-d</span> <span class="s1">'{
  "data": ["World", 3]
}'</span> | <span class="nb">awk</span> <span class="nt">-F</span><span class="s1">'"'</span> <span class="s1">'{ print $4}'</span><span class="si">)</span>
curl <span class="nt">-N</span> http://localhost:7860/gradio_api/call/greet/<span class="k">${</span><span class="nv">EVENT_ID</span><span class="k">}</span>
</code></pre></div></div>

<p>這邊比較特別的地方是，使用curl並不像python client，直接呼叫就可以得到結果，而是會先用POST把資料餵進去以後拿到一個<code class="language-plaintext highlighter-rouge">event_id</code>，接著再用這個<code class="language-plaintext highlighter-rouge">event_id</code>透過GET的方式去取得跑出來的結果。</p>

<h2 id="動態的範例">動態的範例</h2>

<p>在前面的範例裡面，我們都是設定好固定的UI來讓使用者來使用，如果說想要讓UI隨著使用的的輸入而動態變化的話也是可以做到的，我們可以透過<code class="language-plaintext highlighter-rouge">@gr.render()</code>的方式來達成</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">gradio</span> <span class="k">as</span> <span class="n">gr</span>

<span class="k">def</span> <span class="nf">add_field</span><span class="p">(</span><span class="n">fields</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">fields</span> <span class="o">+</span> <span class="p">[{</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">:</span> <span class="n">value</span><span class="p">}],</span> <span class="sh">""</span><span class="p">,</span> <span class="sh">""</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Blocks</span><span class="p">()</span> <span class="k">as</span> <span class="n">web</span><span class="p">:</span>
        <span class="n">fields_state</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">State</span><span class="p">([])</span>
        <span class="k">with</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Row</span><span class="p">():</span>
            <span class="n">field_name_text</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">New field name</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">field_value_text</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Textbox</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">New field value</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">add_field_btn</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Button</span><span class="p">(</span><span class="sh">"</span><span class="s">Add</span><span class="sh">"</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">add_field_btn</span><span class="p">.</span><span class="nf">click</span><span class="p">(</span><span class="n">add_field</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">fields_state</span><span class="p">,</span> <span class="n">field_name_text</span><span class="p">,</span> <span class="n">field_value_text</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">fields_state</span><span class="p">,</span> <span class="n">field_name_text</span><span class="p">,</span> <span class="n">field_value_text</span><span class="p">])</span>

        <span class="nd">@gr.render</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">fields_state</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">render_fields</span><span class="p">(</span><span class="n">fields</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Row</span><span class="p">():</span>
                    <span class="n">name</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Textbox</span><span class="p">(</span><span class="n">field</span><span class="p">[</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Name</span><span class="sh">"</span><span class="p">)</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Textbox</span><span class="p">(</span><span class="n">field</span><span class="p">[</span><span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Value</span><span class="sh">"</span><span class="p">)</span>
                    <span class="n">update_btn</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Button</span><span class="p">(</span><span class="sh">"</span><span class="s">Update</span><span class="sh">"</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">delete_btn</span> <span class="o">=</span> <span class="n">gr</span><span class="p">.</span><span class="nc">Button</span><span class="p">(</span><span class="sh">"</span><span class="s">Delete</span><span class="sh">"</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">variant</span><span class="o">=</span><span class="sh">"</span><span class="s">stop</span><span class="sh">"</span><span class="p">)</span>
                    <span class="k">def</span> <span class="nf">delete_field</span><span class="p">(</span><span class="n">field</span><span class="o">=</span><span class="n">field</span><span class="p">):</span>
                        <span class="n">fields</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">field</span><span class="p">)</span>
                        <span class="k">return</span> <span class="n">fields</span>
                    <span class="k">def</span> <span class="nf">update_field</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
                        <span class="n">new_fields</span> <span class="o">=</span> <span class="nf">delete_field</span><span class="p">()</span>
                        <span class="k">return</span> <span class="n">new_fields</span> <span class="o">+</span> <span class="p">[{</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">:</span> <span class="n">value</span><span class="p">}]</span>
                    <span class="n">update_btn</span><span class="p">.</span><span class="nf">click</span><span class="p">(</span><span class="n">update_field</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">fields_state</span><span class="p">)</span>
                    <span class="n">delete_btn</span><span class="p">.</span><span class="nf">click</span><span class="p">(</span><span class="n">delete_field</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">fields_state</span><span class="p">)</span>

    <span class="n">web</span><span class="p">.</span><span class="nf">launch</span><span class="p">()</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="dynamic_demo.png" alt="Dynamic demo" /></p>

<p>在<code class="language-plaintext highlighter-rouge">gr.Blocks()</code>的第一段裡面，我們宣告了一個<code class="language-plaintext highlighter-rouge">gr.State()</code>，裡面存放的是一個python list，同時做了兩個<code class="language-plaintext highlighter-rouge">Textbox()</code>，讓使用可以輸入<code class="language-plaintext highlighter-rouge">name</code>、<code class="language-plaintext highlighter-rouge">value</code>，並加入一個按鈕來去將使用者輸入的name、value pair放到state裡面。</p>

<p>接著我們透過<code class="language-plaintext highlighter-rouge">gr.render()</code>，並以前面的state當作輸入，根據state裡面儲存的list的資訊去產生對應的元件出來，於此同時我們也可以對新產生出來的元件去設定其觸發的條件，進而更新state裡面的資訊，如此便可以動態地新增、移除網頁上面的元件了。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li><a href="https://blog.csdn.net/cxyhjl/article/details/139712016">【Gradio】Building With Blocks 块中的状 态 + 动态应用程序与渲染装饰器-CSDN博客</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[在做出了令人驚艷的模型或是功能以後，為了可以讓更多人使用，需要一個UI的介面來讓大家來操作，這邊簡單介紹一個可以快速透過python做出網頁UI的套件Gradio。]]></summary></entry><entry><title type="html">Spark Introduction</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/08/07/spark-introduction/" rel="alternate" type="text/html" title="Spark Introduction" /><published>2024-08-07T00:00:00+00:00</published><updated>2024-08-07T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/08/07/spark-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/08/07/spark-introduction/"><![CDATA[<p>這篇文章記錄一下最近學習到對於spark執行上的理解。</p>

<!--more-->

<h2 id="spark的基本架構">Spark的基本架構</h2>

<p><img src="https://i0.wp.com/sparkbyexamples.com/wp-content/uploads/2023/03/Driver-2.jpg?w=731&amp;ssl=1" alt="Spark architecture" /></p>

<p><em><a href="https://sparkbyexamples.com/spark/what-is-spark-job/">What is Spark Job - Spark By {Examples}</a></em></p>

<p>Spark的基本架構長得如上圖，當我們提交一個spark application給cluster manager像是yarn以後，application首先會先被交由一個driver來執行，driver可以想成是在cluster內某一個instance上的process，而這個process會根據你寫的程式碼去要求cluster manager給予executor來去執行對應的任務。</p>

<p><img src="https://i0.wp.com/sparkbyexamples.com/wp-content/uploads/2023/03/spark-Stage-1.jpg?w=711&amp;ssl=1" alt="Spark stage" /></p>

<p><em><a href="https://sparkbyexamples.com/spark/what-is-spark-stage/">What is Spark Stage? Explained - Spark By {Examples}</a></em></p>

<p>一個application通常會根據你寫的程式碼又被細分成好幾個job和stage，一個job會被產生是當你對dataframe或是rdd採取一些特定的action像是<code class="language-plaintext highlighter-rouge">count()</code>、<code class="language-plaintext highlighter-rouge">collect()</code>、<code class="language-plaintext highlighter-rouge">write()</code>等，而每個job底下又可能有好幾個stage，端看你這個action需不需要shuffle、與其他instance傳輸資料，最後的每一個task就是實際上會丟到executor上執行的資料partition。</p>

<h2 id="如何計算spark-application需要多少資源">如何計算Spark Application需要多少資源</h2>

<p>這邊我們需要先區分一下instance和executor，instance是你這個cluster裡面實際的機器，而executor是spark用來執行task的process，所以在一個instance上面有可能會被分配到一個或多個executor，根據你機器的規格和executor對於core和memory的要求來決定。</p>

<p>而每一個task會交由一個core來執行，所以當一個executor有4個核心的時候，spark會以multi-thread的方式來平行化地執行4個task，如果task裡面有包含到python udf，那麼會在每一個核心上面長一個python執行器，由每個核心的python執行器來執行udf。</p>

<p>值得一提的是，spark好像只會看instance的核心數來分配executor，如果你的executor需要很多memory，需要小心造成OOM，舉例來說假設一個instance上面有16個core、64GB的記憶體，而我們設定<code class="language-plaintext highlighter-rouge">spark.executor.cores=2</code>、<code class="language-plaintext highlighter-rouge">spark.executor.memory=16g</code>，這時spark會覺得這個instance有機會可以放16/2=8個executor，但由於memory的關係其實最多只能放4個，如果8個都放上去就有可能造成問題，需要設定<code class="language-plaintext highlighter-rouge">spark.executor.instances</code>來限制executor的數量。</p>

<h2 id="為什麼python-udf會被執行多次">為什麼python udf會被執行多次</h2>

<p>PySpark執行python udf的方式是會先把拿到的資料partition再切成好幾個batch，把每個batch轉換成PyArrow的格式以後交由python執行器來執行，而現在pandas udf支援透過iterator的方式來存取，spark會把每一個batch的iterator丟進python執行器來跑udf，這時如果udf有一些比較吃重的初始化工作的時候，就可以寫在iterator前，之後就可以透過iterator來吃資料，不用再重新初始化一次。</p>

<p>如果我們透過Spark UI去看每一個task的log的時候，可能還是會發現udf裡面初始化的部分被執行了多次，這邊有幾種可能，一個可能是因為executor有多個核心、使用multi-thread執行，所以同一個executor上不同task的log被混在一起，另一個可能是spark沒有把結果保留下來，後面又重算了一次，原因可能是job和job之間做了其他事情，executor需要釋放記憶體去執行其他的任務，當後面的job又需要前面job計算的結果時導致重算，我們可以透過<code class="language-plaintext highlighter-rouge">cache()</code>、<code class="language-plaintext highlighter-rouge">persist()</code>來讓spark強制把結果儲存下來，避免重算的發生。</p>

<p>在一個<a href="https://stackoverflow.com/questions/58696198/spark-udf-executed-many-times">StackOverflow的討論串</a>上面有提供另一個方式是把udf設定成<code class="language-plaintext highlighter-rouge">Nondeterministic</code>，讓spark只執行一次這個udf，或許也可以試試看，但如果後面需要重算，這個做法還是會讓udf被執行多次。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@pandas_udf</span><span class="p">(...)</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="nf">asNondeterministic</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li>
    <p><a href="https://sparkbyexamples.com/spark/what-is-spark-job/">What is Spark Job - Spark By {Examples}</a></p>
  </li>
  <li>
    <p><a href="https://sparkbyexamples.com/spark/what-is-spark-stage/">What is Spark Stage? Explained - Spark By {Examples}</a></p>
  </li>
  <li>
    <p><a href="https://sparkbyexamples.com/spark/spark-tune-executor-number-cores-and-memory/">Tune Spark Executor Number, Cores, and Memory - Spark By {Examples}</a></p>
  </li>
</ul>]]></content><author><name>Your Name</name></author><category term="Spark" /><summary type="html"><![CDATA[這篇文章記錄一下最近學習到對於spark執行上的理解。]]></summary></entry><entry><title type="html">Diffusion Model介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/08/03/introduction-to-diffusion-model/" rel="alternate" type="text/html" title="Diffusion Model介紹" /><published>2024-08-03T00:00:00+00:00</published><updated>2024-08-03T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/08/03/introduction-to-diffusion-model</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/08/03/introduction-to-diffusion-model/"><![CDATA[<p>這篇文章來記錄一下學習diffusion model的筆記。</p>

<!--more-->

<p>在過去如果要讓機器產生圖片，通常會使用VAE或是GAN的方法來產生，而後來出現了diffusion model，產圖的效果很好，近期幾乎所有產圖的模型都是基於diffusion model來設計的。</p>

<h2 id="diffusion-model的運作原理">Diffusion Model的運作原理</h2>

<p>Diffusion model的想法可以想成是我們去訓練一個noise predictor，輸入一張圖片，去預測圖片當中有哪些部分是雜訊，接下來就是將原始圖片減去noise predictor預測出來的雜訊來獲得新的圖片</p>

<pre><code class="language-mermaid">graph LR;
    image1(Image)
    image2(New image)
    denoise[Noise predictor]
    noise(Noise)
    minus(Minus)
    image1--&gt;denoise
    denoise--&gt;noise
    image1--&gt;minus
    noise--&gt;minus
    minus--&gt;image2
</code></pre>

<p>我們可以從一張隨機分佈上面抽樣出來的圖片，反覆上面的動作來獲得一張清晰的圖片，有點類似米開朗基羅雕塑大衛像，雕像已經在石頭裡面了，只是把多餘的部分拿掉。</p>

<pre><code class="language-mermaid">graph LR;
    image1(Image T)
    denoise1[Denoise]
    image2(Image T-1)
    denoise2[Denoise]
    image3(Image T-2)
    denoise3[Denoise]
    image_final(Image 1)
    image1--&gt;denoise1
    denoise1--&gt;image2
    image2--&gt;denoise2
    denoise2--&gt;image3
    image3--&gt;denoise3
    denoise3--Many steps later--&gt;image_final
</code></pre>

<p>具體在訓練這個noise predictor的時候，我們會把當下是第幾步也放進noise predictor當中</p>

<pre><code class="language-mermaid">graph LR;
    image1(Image 1000)
    step1(1000)
    denoise1[Denoise]
    image2(Image 999)
    step2(999)
    denoise2[Denoise]
    image3(Image 998)
    image1--&gt;denoise1
    step1--&gt;denoise1
    denoise1--&gt;image2
    image2--&gt;denoise2
    step2--&gt;denoise2
    denoise2--&gt;image3
</code></pre>

<p>可以想像在剛開始從都是雜訊的圖片需要去除雜訊的時候，消除雜訊的力道需要比較大一些，而到後面圖片已經成形以後，消除雜訊的力道就可以不用這麼大了，因為需要把當下的步數給noise predictor當作輸入。</p>

<p>而訓練資料的取得方法也相對簡單，從網路上找到各式各樣的圖片以後，往圖片裡面加入noise就取得了一組paired data，被加入noise的圖片是noise predictor的輸入，而加進去的noise便是noise predictor的label。</p>

<h2 id="文字生成圖片">文字生成圖片</h2>

<p>在上面的部分我們是直接從都是雜訊的圖片裡面去產生一張清晰的圖片，如果想要產生出來的圖片能跟我們給予的文字敘述相符合，通常的做法像底下這樣</p>

<pre><code class="language-mermaid">graph LR;
    text(Text)
    encoder[Text encoder]
    diffusion[Text-to-Image diffusion]
    random(Random noise)
    decoder[Image decoder]
    image(Image)
    text--text representation--&gt;encoder
    encoder--&gt;diffusion
    random--&gt;diffusion
    diffusion--image latent representation--&gt;decoder
    decoder--&gt;image
</code></pre>

<p>首先會有一個Text encoder把使用者給予的文字轉換成vector，而這個vector會在text-to-image的diffusion model裡面在產生圖片的時候被使用到，最後是一個image decoder model，專門把diffusion model產生出來的tensor轉換成圖片，在前面diffusion model當中，我們可以直接產生圖片也可以讓後面的decoder產生，在目前的研究中看起來，分成兩步驟，讓decoder產生圖片的效果是比較好的。</p>

<h3 id="text-encoder">Text Encoder</h3>

<p>這邊text encoder的目標是把敘述轉換成vector，我們可以直接使用已經訓練好的語言模型像是BERT、GPT來幫助我們將文字轉換成向量。</p>

<h3 id="image-decoder">Image Decoder</h3>

<p>Image decoder做的事情是將diffusion model產生出來的向量或是小圖片轉換成大圖片，這邊我們可以去網路上搜尋各式各樣的圖片，透過訓練一個VAE來獲得這個image decoder，因為VAE可以不需要文字和圖片成對的資料，所以有機會可以用很多圖片來得到一個比較好的decoder。</p>

<h3 id="diffusion">Diffusion</h3>

<p>在diffusion的部分，大致上的做法跟上面雷同，比較不一樣的是因為我們想要根據使用者輸入的文字來產生圖片，所以在noise predictor的每一步都會把text encoder做出來的文字向量輸入給noise predictor。</p>

<p>如果diffusion model最後的輸出是latent representation，當我們在把成對的圖片和文字拿來訓練diffusion model的時候，我們可以使用VAE的encoder把圖片轉換成tensor，而上方diffusion model的中間產物也會從圖片變成tensor，亦即noise predictor在預測的就不是圖片上的noise，而是圖片的latent representation的noise。</p>

<h2 id="結論">結論</h2>

<p>這篇文章簡單介紹了一下diffusion model的概念以及text to image所會使用到的模組，但如果實際上去看stable diffusion的演算法會發現跟上面的說法有一些出入，詳細的數學可以參考<a href="https://www.youtube.com/watch?v=ifCDXFdeaaM&amp;list=PLJV_el3uVTsNi7PgekEUFsyVllAJXRsP-&amp;index=4">這邊的影片</a>。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsNi7PgekEUFsyVllAJXRsP-">Diffusion Model - YouTube</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="Computer-Vision" /><summary type="html"><![CDATA[這篇文章來記錄一下學習diffusion model的筆記。]]></summary></entry><entry><title type="html">架設Elasticsearch來搜尋log</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/05/24/elasticsearch/" rel="alternate" type="text/html" title="架設Elasticsearch來搜尋log" /><published>2024-05-24T00:00:00+00:00</published><updated>2024-05-24T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/05/24/elasticsearch</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/05/24/elasticsearch/"><![CDATA[<p>這篇文章記錄一下如何架設一個etlasticsearch的伺服器來儲存log，好方便使用者來做搜尋。</p>

<!--more-->

<p><a href="https://www.elastic.co/">Elasticsearch</a>是一個開源的搜尋系統，使用者可以將檔案或是文字透過RESTful API的方式上傳到elasticsearch上做index，接著一樣透過RESTful API的方式來根據使用者設定的條件來取得對應的文件，這篇文章會介紹一下如何透過docker架設一個elasticsearch伺服器，並搭配Kibana和Filebeat來監控路徑下的檔案並透過UI來操作。</p>

<h2 id="架設elasticsearch">架設Elasticsearch</h2>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html">架設Elasticsearch</a>的方式有很多種，一個比較簡單的方式是直接去抓docker image下來</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker network create elastic
docker pull docker.elastic.co/elasticsearch/elasticsearch:8.13.4
<span class="nb">sudo </span>sysctl <span class="nt">-w</span> vm.max_map_count<span class="o">=</span>262144
docker run <span class="nt">--name</span> es01 <span class="nt">--net</span> elastic <span class="nt">-p</span> 9200:9200 <span class="nt">-it</span> <span class="nt">-m</span> 1GB docker.elastic.co/elasticsearch/elasticsearch:8.13.4
</code></pre></div></div>

<p>上面的指令會創建一個叫<code class="language-plaintext highlighter-rouge">elastic</code>的網路，之後創建的container都會放在這個網路底下，而在執行<code class="language-plaintext highlighter-rouge">docker run</code>以後，最後會停在一個畫面，上會顯示使用者<code class="language-plaintext highlighter-rouge">elastic</code>的密碼，以及Kibana的enrollment token，我們需要將這個密碼存下來，在之後要使用UI或是打API時都會使用到。</p>

<p>如果想要測試elasticsearch有沒有順利地被建立起來，可以透過底下的指令試打看看</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">ELASTIC_PASSWORD</span><span class="o">=</span><span class="s2">"YOUR_PASSWORD_HERE"</span>
docker <span class="nb">cp </span>es01:/usr/share/elasticsearch/config/certs/http_ca.crt <span class="nb">.</span>
curl <span class="nt">--cacert</span> http_ca.crt <span class="nt">-u</span> elastic:<span class="k">${</span><span class="nv">ELASTIC_PASSWORD</span><span class="k">}</span> https://localhost:9200
</code></pre></div></div>

<p>要跟elasticsearch溝通除了需要帳號密碼以外，我們還需要一個http certificate，這邊可以直接從container裡面複製出來。</p>

<h2 id="架設kibana">架設Kibana</h2>

<p>Kibana是用來跟Elasticsearch互動的UI介面，一樣也可以透過docker來建立</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull docker.elastic.co/kibana/kibana:8.13.4
docker run <span class="nt">--name</span> kib01 <span class="nt">--net</span> elastic <span class="nt">-p</span> 5601:5601 docker.elastic.co/kibana/kibana:8.13.4
</code></pre></div></div>

<p>這時使用瀏覽器連線到<a href="http://localhost:5601">http://localhost:5601</a>應該就可以看到kibana的介面了，畫面上會顯示要你填入enrollment token，把上方elasticsearch顯示的enrollment token直接填入就可以讓兩者順利連線了。</p>

<h2 id="上傳document">上傳Document</h2>

<p>在建立好elasticsearch和kibana以後，接著就可以把我們想要從中搜尋的文件給上傳上去了，elasticsearch提供了很多方式可以上傳，這邊介紹如何透過python和filebeat來上傳。</p>

<h3 id="使用python上傳document">使用Python上傳Document</h3>

<p>首先我們需要先安裝elasticsearch的套件</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>elasticsearch
</code></pre></div></div>

<p>接著就可以透過python來連線到elasticsearch了</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">elasticsearch</span> <span class="kn">import</span> <span class="n">Elasticsearch</span>

<span class="n">es</span> <span class="o">=</span> <span class="nc">Elasticsearch</span><span class="p">(</span><span class="sh">"</span><span class="s">https://localhost:9200</span><span class="sh">"</span><span class="p">,</span>
                   <span class="n">basic_auth</span><span class="o">=</span><span class="p">(</span><span class="sh">"</span><span class="s">elastic</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">YOUR_PASSWORD_HERE</span><span class="sh">"</span><span class="p">),</span>
                   <span class="n">ca_certs</span><span class="o">=</span><span class="sh">"</span><span class="s">./http_ca.crt</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>這邊需要提供elasticsearch所架設的位置、帳號密碼和http certificate的路徑來建立連線。</p>

<p>下一步便是建立一個elasticsearch的index，好把我們想要搜尋的document放進這個index裡面</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">es</span><span class="p">.</span><span class="n">indices</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="sh">"</span><span class="s">YOUR_INDEX_NAME</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># es.indices.delete(index="YOUR_INDEX_NAME", ignore=[400, 404])
</span></code></pre></div></div>

<p>如果想要刪除，重新建立index的話，可以使用上面<code class="language-plaintext highlighter-rouge">delete</code>的function來把整個index刪掉。</p>

<p>最後就是將document上傳上去</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">es</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span>
    <span class="n">index</span><span class="o">=</span><span class="sh">"</span><span class="s">YOUR_INDEX_HERE</span><span class="sh">"</span><span class="p">,</span>
    <span class="nb">id</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">document_id</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">document</span><span class="o">=</span><span class="p">{</span>
        <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">document_name</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<p>這邊我們上傳了一個document，其id是<code class="language-plaintext highlighter-rouge">f"{document_id}"</code>，底下有一個field是<code class="language-plaintext highlighter-rouge">name</code>，其對應的value是<code class="language-plaintext highlighter-rouge">f"{document_name}"</code>，這裡可以根據你對document的理解和處理來新增多個field，但id只能有一個。</p>

<p>這時，在Kibana上面做仿側邊欄的<strong>Search→Content</strong>裡面應該就能看到你上傳上去的index和document了，如果想透過python來query的話，可以使用下面的方式透過document name來搜尋</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span> <span class="o">=</span> <span class="n">es</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="sh">"</span><span class="s">YOUR_INDEX_HERE</span><span class="sh">"</span><span class="p">,</span>
                     <span class="n">body</span><span class="o">=</span><span class="p">{</span>
                         <span class="sh">"</span><span class="s">query</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
                             <span class="sh">"</span><span class="s">match</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
                                 <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">document_name</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
                             <span class="p">}</span>
                         <span class="p">}</span>
                     <span class="p">})</span>
</code></pre></div></div>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-with-elasticsearch.html">Elasticsearch還有提供多種方式</a>來做搜尋，如果需要的話可以再自行研究。</p>

<h3 id="使用filebeat上傳document">使用Filebeat上傳Document</h3>

<p>上面使用python的方式是我們主動將document上傳到elasticsearch上，另一個方式是使用filebeat去監聽特定路徑下的檔案更動，如果有新的更動就將新的資料上傳到elastcissearch上，filebeat是<a href="https://www.elastic.co/logstash">Logstash</a>裡面比較輕量化的檔案監聽套件，如果需求比較複雜的話可以嘗試使用Logstash看看。</p>

<p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation-configuration.html">安裝filebeat的方式</a>有很多種方法，底下使用的是rpm的安裝方式</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-L</span> <span class="nt">-O</span> https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.13.4-x86_64.rpm
<span class="nb">sudo </span>rpm <span class="nt">-vi</span> filebeat-8.13.4-x86_64.rpm
</code></pre></div></div>

<p>安裝好以後，我們可以打開<code class="language-plaintext highlighter-rouge">/etc/filebeat/filebeat.yml</code>來設定filebeat，首先需要設定filebeat連接到elasticsearch，在<code class="language-plaintext highlighter-rouge">output.elasticsearch</code>的區塊改成底下的設定</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">output.elasticsearch</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">https://localhost:9200"</span><span class="pi">]</span>
  <span class="na">preset</span><span class="pi">:</span> <span class="s">balanced</span>
  <span class="na">prototol</span><span class="pi">:</span> <span class="s2">"</span><span class="s">https"</span>
  <span class="na">username</span><span class="pi">:</span> <span class="s2">"</span><span class="s">elastic"</span>
  <span class="na">password</span><span class="pi">:</span> <span class="s2">"</span><span class="s">${ES_PASS}"</span>
  <span class="na">ssl.certificate_authorities</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">/path/to/your/certificate"</span><span class="pi">]</span>
</code></pre></div></div>

<p>這邊的<code class="language-plaintext highlighter-rouge">${ES_PASS}</code>是存放在filebeat keystore的變數，如果直接把密碼寫在yml裡面會有洩漏的風險，<a href="https://www.elastic.co/guide/en/beats/filebeat/8.13/keystore.html">filebeat提供了keystore的功能</a>讓你把機密資訊存起來，使用的方式是先建立keystore</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>filebeat keystore create
</code></pre></div></div>

<p>接著就能透過底下的指令來設定變數</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>filebeat keystore add ES_PASS
</code></pre></div></div>

<p>再來我們就可以跳到<code class="language-plaintext highlighter-rouge">filebeat.inputs</code>的地方來設定要監聽的路徑，底下是一個簡單的模板</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">filebeat.inputs</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">filestream</span>
  <span class="na">id</span><span class="pi">:</span> <span class="s">your_input_id</span>
  <span class="na">enabled</span><span class="pi">:</span> <span class="kc">true</span>
  <span class="na">paths</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">/path/to/your/logs</span>
    <span class="c1"># e.g. - /var/log/*.log</span>
  <span class="c1"># json.keys_under_root: true</span>
  <span class="c1"># json.add_error_key: true</span>
  <span class="na">index</span><span class="pi">:</span> <span class="s2">"</span><span class="s">your_index"</span>
</code></pre></div></div>

<p>如果想要監聽其他路徑的檔案並放到不同的index裡面，只需要再另外加一個<code class="language-plaintext highlighter-rouge">type</code>的區塊就可以了，這邊我們需要設定這個input的id、要監聽的路徑以及想要放到elasticsearch的哪個index裡面。</p>

<p>設定好以後，執行底下的指令讓filebeat跑起來，就可以在Kibana上面看到filebeat上傳的index了，在左邊側邊欄裡面的<strong>Management→Stack Management→Index Management</strong>也可以看到相關的設定。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>filebeat <span class="nt">-e</span>
</code></pre></div></div>

<p>如果在上傳的時候發現問題，想讓filebeat重新上傳整個index，除了在kibana裡面砍掉index外，我們需要把底下的資料夾也砍掉，讓filebeat忘記過去曾經上傳過的東西以後，重啟filebeat的服務來整個重新上傳。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/var/lib/filebeat/registry
</code></pre></div></div>

<h4 id="parse-json-log">Parse json log</h4>

<p>Filebeat預設會是一行一行地讀取路徑底下的檔案，如果這個檔案是紀錄json的log，每一行是一個json object的話，我們可以在<code class="language-plaintext highlighter-rouge">filebeat.inputs</code>多加<code class="language-plaintext highlighter-rouge">json.keys_under_root</code>和<code class="language-plaintext highlighter-rouge">json.add_error_key</code>來讓filebeat幫我們去parse json的log。</p>

<p>這時如果去kibana上面看會發現到filebeat把整個json object放到<code class="language-plaintext highlighter-rouge">message</code>這個field裡面，沒有把json的key、value塞到對應的field</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">processors</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">decode_json_fields</span><span class="pi">:</span>
    <span class="na">fields</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">message"</span><span class="pi">]</span>
    <span class="na">process_array</span><span class="pi">:</span> <span class="kc">false</span>
    <span class="na">max_depth</span><span class="pi">:</span> <span class="m">2</span>
    <span class="na">target</span><span class="pi">:</span> <span class="s2">"</span><span class="s">"</span>
    <span class="na">overwrite_keys</span><span class="pi">:</span> <span class="kc">true</span>
    <span class="na">add_error_key</span><span class="pi">:</span> <span class="kc">false</span>
</code></pre></div></div>

<p>我們還需要在<code class="language-plaintext highlighter-rouge">/etc/filebeat/filebeat.yml</code>裡面<code class="language-plaintext highlighter-rouge">processors</code>的區塊多加<code class="language-plaintext highlighter-rouge">decode_json_fields</code>來明確地告訴filebeat我們想要解析<code class="language-plaintext highlighter-rouge">message</code>這個field，設定好並重啟filebeat的服務以後就可以在kibana上面看到json object裡面的key、value被塞進elasticsearch index裡document的field了。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li>
    <p><a href="https://ithelp.ithome.com.tw/users/20130639/ironman/3747">親愛的，我把ElasticSearch上雲了 :: 第 12 屆 iThome 鐵人賽</a></p>
  </li>
  <li>
    <p><a href="https://www.cnblogs.com/zsql/p/13137833.html"> 一篇文章搞懂filebeat（ELK）</a></p>
  </li>
</ul>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[這篇文章記錄一下如何架設一個etlasticsearch的伺服器來儲存log，好方便使用者來做搜尋。]]></summary></entry><entry><title type="html">如何安裝Comfy UI</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/04/17/comfy-ui/" rel="alternate" type="text/html" title="如何安裝Comfy UI" /><published>2024-04-17T00:00:00+00:00</published><updated>2024-04-17T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/04/17/comfy-ui</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/04/17/comfy-ui/"><![CDATA[<p>先前介紹了如何<a href="https://wjohn1483.github.io/2023/07/02/stable-diffusion/">在本機上面跑Stable Diffusion</a>，這篇文章來記錄一下如何安裝Comfy UI，來讓產圖變得更容易。</p>

<!--more-->

<h2 id="comfy-ui">Comfy UI</h2>

<p><a href="https://github.com/comfyanonymous/ComfyUI">Comfy UI</a>是個使用stable diffusion產圖，但把介面變成流程圖的方式來呈現，方便使用者可以一目了然地理解產圖的過程，還可以直接在上面調整prompt和參數。</p>

<h2 id="安裝流程">安裝流程</h2>

<h3 id="安裝comfy-ui">安裝Comfy UI</h3>

<p>首先先從<a href="https://github.com/comfyanonymous/ComfyUI">GitHub</a>上面把Comfy UI clone下來，接下來安裝python相關的套件</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div>

<h3 id="下載模型">下載模型</h3>

<p>在有了UI以後，我們還需要去下載其背後所使用到的stable diffusion的模型們，我們可以在<a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main">huggingface</a>上面下載到，至少會需要模型本身的safetensors，如果有更新的模型也可以下載最新的。將下載下來的safetensors檔案放在clone下來repository的<strong>models/checkpoints</strong>即可。</p>

<h3 id="執行comfy-ui">執行Comfy UI</h3>

<p>只要下底下的指令，理論上就可以順利地跑起來了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Use GPU</span>
python3 main.py

<span class="c"># Use CPU only</span>
python3 main.py <span class="nt">--cpu</span>
</code></pre></div></div>

<p>預設的port是8188，所以打開瀏覽器連上<code class="language-plaintext highlighter-rouge">http://localhost:8188</code>應該就能看到使用者介面了。</p>

<p><img src="./comfyui.png" alt="Comfy UI" /></p>

<p>上面的文字框可以填上你想要用來產生圖片的prompt，而下面的文字框是填上你不想要在圖片中看到的prompt，記得在左邊的Checkpoint區塊選擇你下載下來的模型，最後按下<code class="language-plaintext highlighter-rouge">Queue Prompt</code>就可以產圖了。</p>

<h3 id="上傳pipeline">上傳pipeline</h3>

<p>基本版的pipeline雖然挺好用的，但網路上有更多更厲害的pipeline，這邊舉<a href="https://github.com/SytanSD/Sytan-SDXL-ComfyUI/blob/main/Sytan's%20SDXL%201.0%20Workflow%20.json">Sytan-SDXL-ComfyUI</a>為例子，直接從GitHub上面把json下載下來Load到Comfy UI上面就可以使用了。</p>

<h2 id="comfyui-manager">ComfyUI-Manager</h2>

<p>隨著Comfy UI的盛行，有越來越多人寫了一些其他的套件來擴充現有Comfy UI的功能，我們可以透過ComfyUI-Manager來安裝其他實用的套件，安裝的方法很簡單，在前面clone下來的Comfy UI repository裡面下底下的指令就可以了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>custom_nodes
git clone https://github.com/ltdrdata/ComfyUI-Manager.git
<span class="c"># Restart Comfy UI</span>
</code></pre></div></div>

<p>重啟Comfy UI以後就可以看到右邊選單列表內多了<code class="language-plaintext highlighter-rouge">Manager</code>的按鈕可以點選，在裡面可以搜尋各式各樣的套件來安裝。</p>

<h3 id="comfyspace">Comfyspace</h3>

<p>在眾多的套件裡面，推薦可以先安裝<a href="https://github.com/11cafe/comfyui-workspace-manager">ComfySpace</a>，在Manager裡面搜尋<code class="language-plaintext highlighter-rouge">ComfyUI Workspace Manager</code>，接著重啟Comfy UI就可以了，其功用是幫你記錄和尋找Comfy UI的pipeline，如此就可以不用自己存pipeline的json，增加產圖的效率。</p>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[先前介紹了如何在本機上面跑Stable Diffusion，這篇文章來記錄一下如何安裝Comfy UI，來讓產圖變得更容易。]]></summary></entry><entry><title type="html">Bandit Algorithms Notes</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/02/22/bandit-algorithms-notes/" rel="alternate" type="text/html" title="Bandit Algorithms Notes" /><published>2024-02-22T00:00:00+00:00</published><updated>2024-02-22T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/02/22/bandit-algorithms-notes</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/02/22/bandit-algorithms-notes/"><![CDATA[<p>最近剛好有機會碰了一下一直聽過但都沒有實際碰過的Bandit Algorithms，這邊紀錄一下從網路上學習到的知識。</p>

<!--more-->

<p>Bandit算法一開始被設計出來是為了要解決在有限的資源下要如何創造最大的收益，網路文章中給的例子通常都是在一個滿是吃角子老虎機台的房間當中，如何用手中有限的籌碼獲得最大的報酬，也就是找到獲獎機率比較大的吃角子老虎機台，這時候使用者會面臨繼續玩原本預期收益最大的吃角子老虎機，或是去玩看看新的吃角子老虎機，也就是在exploitation和exploration兩者之間抉擇。</p>

<p>在原本的Multi-Armed Bandit裡面，我們只考慮不同吃角子老虎的機台，並沒有考慮使用者本身的偏好，像是某個使用者可能特別偏好某個有特殊外型的吃角子老虎機，對於該使用者而言那台吃角子老虎機的預期收益會比較大，如果有考慮到使用者本身資訊的bandit通常被稱為contextual bandit，反之被稱為context-free bandit。</p>

<p>在任何的一個bandit algorithm裡面，我們會對每一個arm，也就是每一個吃角子老虎機台打一個分數，並從這些機台裡面選一個分數最高的去使用，而不同的算法會有不同打分數的方式，比較著名的context-free bandit的算法有UCB、Thompson Sampling，比較著名的contextual bandit算法有LinUCB。</p>

<h2 id="epsilon-greedy">Epsilon Greedy</h2>

<p>在進到Bandit的算法之前，我們可以先用一個簡單的方法來平衡exploitation和exploration，我們可以每次在決定要玩哪台吃角子老虎機的時候先擲一個骰子，令其有$\epsilon$的機率會去選擇以前沒有玩過的吃角子老虎機試試看，反之就繼續玩目前玩過的所有吃角子老虎機裡面，預期收益最大的。</p>

<h2 id="upper-confidence-bound-ucb">Upper Confidence Bound (UCB)</h2>

<p>在使用epsilon greedy做exploration的時候，每一個arm被選中的機會是相等的，但實際上每一個arm曾經被看過的次數和互動過的次數都不同，在exploration的時候可以有更聰明一點的方法，而UCB的概念是對於每一個arm給予的分數是基於它有可能所帶來的最高報酬，其分數的公式如下</p>

\[\mu_i+\sqrt{\frac{2\ln (n)}{n_i}}\]

<p>$\mu_i$是每一個$arm_i$前n次嘗試獲得的平均報酬，$n$是總嘗試次數，$n_i$是$arm_i$被嘗試的次數。</p>

<p>左邊這項可以理解成過去這個$arm_i$所能夠帶給我們的平均報酬是多少，展現的是exploitation的部分，而右邊這項會讓比較少曝光的$arm_i$有比較高的分數，令其有機會被展示出來，展現的是exploration的部分。</p>

<h2 id="thompson-sampling">Thompson Sampling</h2>

<p>Thompson sampling的想法是，每次使用同一個arm所獲得的報酬可能會是浮動的，表示每一個arm的報酬可能是某種distribution，每次使用的時候就會從distribution裡面隨機抽樣出來當作是這次使用的報酬，而Thompson sampling覺得這個distribution應該是beta distribution，一個beta distribution會由兩個變數a、b來決定，也就是每個arm自帶的參數，因此在某個時間點選擇要使用哪一個arm的時候，就是每一個arm都從beta distribution裡面抽樣一個數字出來，看誰的數字最大就選擇哪個arm。</p>

<h2 id="linucb">LinUCB</h2>

<p>LinUCB相較於UCB，多了使用者的資訊在裡面，其公式長得大概像這樣</p>

\[LinUCB_a=E(r_a \vert x)+\alpha STD(r_a \vert x)=x^T*\theta_a+\alpha\sqrt{x^TA_a^{-1}x}\]

<p>在上面的$x$表示的是使用者的特徵向量，而$\theta_a$和$A_a$是某一個arm本身自帶的參數，跟UCB一樣，左邊這項表示對過去這個使用者對這個arm的喜好程度，而右邊這項表示使用者願意exploration的分數。</p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li>
    <p><a href="https://zhuanlan.zhihu.com/p/35753281">Contextual Bandit算法在推荐系统中的实现及应用</a></p>
  </li>
  <li>
    <p><a href="https://blog.tsingjyujing.com/ml/rl/mab-summary">Re：从零开始的Multi-armed Bandit</a></p>
  </li>
  <li>
    <p><a href="https://yangxudong.github.io/contextual-bandit/">在生产环境的推荐系统中部署Contextual bandit (LinUCB)算法的经验和陷阱</a></p>
  </li>
  <li>
    <p><a href="https://zhuanlan.zhihu.com/p/381585388">MAB系列1：Contextual-free Bandits</a></p>
  </li>
  <li>
    <p><a href="https://zhuanlan.zhihu.com/p/384427160">MAB系列2：Contextual Bandits: LinUCB</a></p>
  </li>
</ol>]]></content><author><name>Your Name</name></author><category term="Bandit" /><summary type="html"><![CDATA[最近剛好有機會碰了一下一直聽過但都沒有實際碰過的Bandit Algorithms，這邊紀錄一下從網路上學習到的知識。]]></summary></entry><entry><title type="html">nginx Reverse Proxy</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/01/20/nginx-reverse-proxy/" rel="alternate" type="text/html" title="nginx Reverse Proxy" /><published>2024-01-20T00:00:00+00:00</published><updated>2024-01-20T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/01/20/nginx-reverse-proxy</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/01/20/nginx-reverse-proxy/"><![CDATA[<p>最近想要把在同一台機器上面的不同服務都使用同一個port來去做serving，這邊記錄一下嘗試使用nginx來做reverse proxy的過程。</p>

<!--more-->

<p>在機器上因為不同的需求開了兩個不同的服務在不同的port，但想要讓這兩個服務都透過相同的port 80來給使用者來做使用，這時候我們可以使用nginx的反向代理功能來讓使用者使用相同的port 80，搭配不同的path來連到不同的服務。</p>

<h2 id="安裝nginx">安裝nginx</h2>

<p>底下是在CentOS上面安裝時使用的指令，不同的作業系統的安裝方法可以參考<a href="https://www.nginx.com/resources/wiki/start/topics/tutorials/install/">官網</a>上的介紹。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> nginx
</code></pre></div></div>

<h2 id="設定nginx">設定nginx</h2>

<p>關於nginx的設定都放在<code class="language-plaintext highlighter-rouge">/etc/nginx/nginx.conf</code>裡面，我們可以在http$\rightarrow$server的區塊裡面，新增不同的path來讓nginx來做反向代理。</p>

<div class="language-nginx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># For more information on configuration, see:</span>
<span class="c1">#   * Official English Documentation: http://nginx.org/en/docs/</span>
<span class="c1">#   * Official Russian Documentation: http://nginx.org/ru/docs/</span>

<span class="k">user</span> <span class="s">nginx</span><span class="p">;</span>
<span class="k">worker_processes</span> <span class="s">auto</span><span class="p">;</span>
<span class="k">error_log</span> <span class="n">/var/log/nginx/error.log</span><span class="p">;</span>
<span class="k">pid</span> <span class="n">/run/nginx.pid</span><span class="p">;</span>

<span class="c1"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span>
<span class="k">include</span> <span class="n">/usr/share/nginx/modules/*.conf</span>;

<span class="k">events</span> <span class="p">{</span>
    <span class="kn">worker_connections</span> <span class="mi">1024</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">http</span> <span class="p">{</span>
    <span class="kn">log_format</span>  <span class="s">main</span>  <span class="s">'</span><span class="nv">$remote_addr</span> <span class="s">-</span> <span class="nv">$remote_user</span> <span class="s">[</span><span class="nv">$time_local</span><span class="s">]</span> <span class="s">"</span><span class="nv">$request</span><span class="s">"</span> <span class="s">'</span>
                      <span class="s">'</span><span class="nv">$status</span> <span class="nv">$body_bytes_sent</span> <span class="s">"</span><span class="nv">$http_referer</span><span class="s">"</span> <span class="s">'</span>
                      <span class="s">'"</span><span class="nv">$http_user_agent</span><span class="s">"</span> <span class="s">"</span><span class="nv">$http_x_forwarded_for</span><span class="s">"'</span><span class="p">;</span>

    <span class="kn">access_log</span>  <span class="n">/var/log/nginx/access.log</span>  <span class="s">main</span><span class="p">;</span>

    <span class="kn">sendfile</span>            <span class="no">on</span><span class="p">;</span>
    <span class="kn">tcp_nopush</span>          <span class="no">on</span><span class="p">;</span>
    <span class="kn">tcp_nodelay</span>         <span class="no">on</span><span class="p">;</span>
    <span class="kn">keepalive_timeout</span>   <span class="mi">65</span><span class="p">;</span>
    <span class="kn">types_hash_max_size</span> <span class="mi">4096</span><span class="p">;</span>

    <span class="kn">gzip_static</span> <span class="no">off</span><span class="p">;</span>

    <span class="kn">include</span>             <span class="n">/etc/nginx/mime.types</span><span class="p">;</span>
    <span class="kn">default_type</span>        <span class="nc">application/octet-stream</span><span class="p">;</span>

    <span class="c1"># Load modular configuration files from the /etc/nginx/conf.d directory.</span>
    <span class="c1"># See http://nginx.org/en/docs/ngx_core_module.html#include</span>
    <span class="c1"># for more information.</span>
    <span class="kn">include</span> <span class="n">/etc/nginx/conf.d/*.conf</span><span class="p">;</span>

    <span class="kn">server</span> <span class="p">{</span>
        <span class="kn">listen</span>       <span class="mi">80</span><span class="p">;</span>
        <span class="kn">listen</span>       <span class="s">[::]:80</span><span class="p">;</span>
        <span class="kn">server_name</span>  <span class="s">&lt;YOUR_HOST_NAME&gt;</span><span class="p">;</span>

        <span class="c1"># Load configuration files for the default server block.</span>
        <span class="kn">include</span> <span class="n">/etc/nginx/default.d/*.conf</span><span class="p">;</span>

        <span class="kn">location</span> <span class="n">/</span> <span class="p">{</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:8000</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="kn">location</span> <span class="n">/test</span> <span class="p">{</span>
            <span class="kn">rewrite</span> <span class="s">^/test(/.*)</span>$ <span class="nv">$1</span> <span class="s">break</span><span class="p">;</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:9000</span><span class="p">;</span>
            <span class="kn">proxy_redirect</span> <span class="n">/</span> <span class="n">/test/</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="kn">error_page</span> <span class="mi">404</span> <span class="n">/404.html</span><span class="p">;</span>
        <span class="kn">location</span> <span class="p">=</span> <span class="n">/404.html</span> <span class="p">{</span>
        <span class="p">}</span>

        <span class="kn">error_page</span> <span class="mi">500</span> <span class="mi">502</span> <span class="mi">503</span> <span class="mi">504</span> <span class="n">/50x.html</span><span class="p">;</span>
        <span class="kn">location</span> <span class="p">=</span> <span class="n">/50x.html</span> <span class="p">{</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>在上面的例子裡面，我們新增了底下的設定</p>

<div class="language-nginx highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="k">location</span> <span class="n">/</span> <span class="p">{</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:8000</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="k">location</span> <span class="n">/test</span> <span class="p">{</span>
            <span class="kn">rewrite</span> <span class="s">^/test(/.*)</span>$ <span class="nv">$1</span> <span class="s">break</span><span class="p">;</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:9000</span><span class="p">;</span>
            <span class="kn">proxy_redirect</span> <span class="n">/</span> <span class="n">/test/</span><span class="p">;</span>
        <span class="p">}</span>
</code></pre></div></div>

<p>我們使用<code class="language-plaintext highlighter-rouge">proxy_pass</code>來將不同path的request傳到對應的服務上，假如使用者連到<code class="language-plaintext highlighter-rouge">HOST/</code>，就會導到<code class="language-plaintext highlighter-rouge">localhost:8000</code>，如果連到<code class="language-plaintext highlighter-rouge">HOST/test/</code>就會導到<code class="language-plaintext highlighter-rouge">localhost:9000</code>。</p>

<p>不過如果只有單純的<code class="language-plaintext highlighter-rouge">proxy_pass</code>，被重新導向的路徑會也帶上使用者加上的<code class="language-plaintext highlighter-rouge">/test/</code>，倘若希望在導向的時候將這個path給去除，讓服務收到的request是<code class="language-plaintext highlighter-rouge">/</code>的話，可以使用<code class="language-plaintext highlighter-rouge">rewrite</code>來對request做修改。</p>

<p>同樣地，如果服務收到<code class="language-plaintext highlighter-rouge">/</code>的request以後，想重新導向到服務的<code class="language-plaintext highlighter-rouge">/redirect</code>路徑，這時使用者實際上要request的就會需要是<code class="language-plaintext highlighter-rouge">HOST/test/redirect</code>，我們可以使用<code class="language-plaintext highlighter-rouge">proxy_redirect</code>來幫服務的重新導向加上<code class="language-plaintext highlighter-rouge">/test/</code>的前綴。</p>

<h2 id="啟動nginx">啟動nginx</h2>

<p>在寫好configuration以後，我們可以透過<code class="language-plaintext highlighter-rouge">nginx -t</code>來檢驗設定檔有沒有寫錯的地方，如果順利通過就能將nginx的服務起起來了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo</span> /usr/sbin/nginx <span class="nt">-t</span>
<span class="nb">sudo </span>service nginx start
<span class="nb">sudo </span>service nginx reload
chkconfig nginx on
</code></pre></div></div>

<p>而nginx本身的log會寫到底下的路徑，每當有使用者連線進來，就會寫到<code class="language-plaintext highlighter-rouge">access.log</code>，如果發生了錯誤會寫到<code class="language-plaintext highlighter-rouge">error.log</code>。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/var/log/nginx/access.log
/var/log/nginx/error.log
</code></pre></div></div>

<p>如果之後設定檔有做其他的修改，只需要執行<code class="language-plaintext highlighter-rouge">nginx reload</code>就可以讓新的設定生效。</p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li><a href="https://blog.containerize.com/zh-hant/how-to-setup-and-configure-nginx-as-reverse-proxy/">如何設置和配置為反向代理</a></li>
</ol>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[最近想要把在同一台機器上面的不同服務都使用同一個port來去做serving，這邊記錄一下嘗試使用nginx來做reverse proxy的過程。]]></summary></entry><entry><title type="html">如何使用CPU跑LLM</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/09/11/llama-cpp-introduction/" rel="alternate" type="text/html" title="如何使用CPU跑LLM" /><published>2023-09-11T00:00:00+00:00</published><updated>2023-09-11T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/09/11/llama-cpp-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/09/11/llama-cpp-introduction/"><![CDATA[<p>Large Language Model（LLM）的風潮席捲全球，大家都在努力嘗試使用LLM來建造各式各樣的應用，但LLM本身所需要的計算量很大，沒有足夠的資源是跑不起來的，好在網路上有很多大神們在嘗試只使用少量的把LLM給跑起來，這篇文章介紹一下如何使用CPU的資源就將Llama2跑起來。</p>

<!--more-->

<h2 id="ggml">GGML</h2>

<p>現在把LLM跑在資源相較匱乏的電腦上的方法主要都是透過quantization來減少模型的計算量，在訓練模型的時候，模型通常都是使用32 bits的浮點數來去儲存參數，倘若我們把浮點數下調一些，用16 bits或是4bits來儲存的話，雖說計算的精準度會下降，但模型在inference的計算量就可以減少很多。</p>

<p>其中quantization最常使用的是<a href="https://github.com/ggerganov/ggml">ggml</a>這個工具，ggml是個用C寫成的套件，它可以幫助你把手上的模型做quantization，而且支援目前大多數的開源LLM模型，支援的模型們可以去它的github上面看。</p>

<h2 id="llamacpp">llama.cpp</h2>

<p><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>是一個基於ggml的工具，讓你可以很輕易地把你手上建構在llama上的模型做quantization，像是Llama、Alpaca、Vicuna、Llama2等都可以透過llama.cpp來把模型變得更小、計算得更快，底下會講一下如何使用llama.cpp來讓Llama2跑在CPU上。</p>

<h3 id="llama2">Llama2</h3>

<p><a href="https://ai.meta.com/llama/">Llama2</a>是Meta基於Llama訓練出來的有條件可商用模型，如果想要取得Llama2的模型，可以直接去Meta的官網上面填寫資料，之後根據寄來的email上的指示就能將模型的參數們下載回來了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % <span class="nb">ls </span>llama-2-13b-chat
checklist.chk  consolidated.00.pth  consolidated.01.pth  params.json  tokenizer.model
</code></pre></div></div>

<h3 id="compile-llamacpp">Compile llama.cpp</h3>

<p>在quantize模型之前，我們需要先編譯一下我們的工具llama.cpp，編譯的方法可以參考github上的<a href="https://github.com/ggerganov/llama.cpp#readme">README.md</a>，如果是Linux的話應該只需要將repository clone下來以後執行make就可以了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/ggerganov/llama.cpp.git
<span class="nb">cd </span>llama.cpp
pip3 <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
make
</code></pre></div></div>

<h3 id="quantization">Quantization</h3>

<p>接下來就可以著手來做quantization了，詳細的步驟也可以參考<a href="https://github.com/ggerganov/llama.cpp#prepare-data--run">官方的README.md</a>，首先我們需要將模型的參數做成16 bits的gguf檔，在過去被稱為ggml，也就是套件的名稱，但後來ggml的格式又做了一些修改，變成了gguf，獲得了更好的可擴充性。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 ./convert.py ~/llama-2-13b-chat/
</code></pre></div></div>

<p>這時在原本模型儲存的路徑下應該會多出一個<strong>ggml-model-f16.gguf</strong>檔，這時其實就可以使用這個比較小的模型檔來在CPU上面做inference了，不過我們還可以進一步的做quantization，來讓執行時間變得更短。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./quantize ~/llama-2-13b-chat/ggml-model-f16.gguf ~/llama-2-13b-chat/ggml-model-f16.gguf.q4_0.bin q4_0
</code></pre></div></div>

<p>在上面的指令裡面，我們給了3個參數，分別是剛剛做好的gguf檔，再來是做完quantization後想輸出的路徑，最後是quantization的方法，quantization的方法在<a href="https://github.com/ggerganov/llama.cpp#quantization">README.md</a>上面有列表來告訴我們有哪些選項，以及其效果如何。</p>

<p>在<a href="https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF">Hugging Face上</a>也已經有別人quantized好的模型了，如果想直接拿現成的也可以從上面下載下來。</p>

<h3 id="inference">Inference</h3>

<p>在quantize好自己想要的大小的模型以後，接下來就是使用這個模型來執行看看prompt了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./main <span class="nt">-m</span> ~/llama-2-13b-chat/ggml-model-f16.gguf.q4_0.bin <span class="nt">-n</span> <span class="nt">-1</span> <span class="nt">-e</span> <span class="nt">-t</span> 8 <span class="nt">-p</span> <span class="s2">"YOUR PROMPT HERE"</span>
</code></pre></div></div>

<p>關於<code class="language-plaintext highlighter-rouge">main</code>更多的參數可以透過<code class="language-plaintext highlighter-rouge">./main -h</code>來查看，這邊列一下上面指令option所代表的意思。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nt">-m</span> FNAME, <span class="nt">--model</span> FNAME
                        model path <span class="o">(</span>default: models/7B/ggml-model-f16.gguf<span class="o">)</span>
  <span class="nt">-n</span> N, <span class="nt">--n-predict</span> N   number of tokens to predict <span class="o">(</span>default: <span class="nt">-1</span>, <span class="nt">-1</span> <span class="o">=</span> infinity, <span class="nt">-2</span> <span class="o">=</span> <span class="k">until </span>context filled<span class="o">)</span>
  <span class="nt">-t</span> N, <span class="nt">--threads</span> N     number of threads to use during computation <span class="o">(</span>default: 4<span class="o">)</span>
  <span class="nt">-p</span> PROMPT, <span class="nt">--prompt</span> PROMPT
                        prompt to start generation with <span class="o">(</span>default: empty<span class="o">)</span>
  <span class="nt">-e</span>, <span class="nt">--escape</span>          process prompt escapes sequences <span class="o">(</span><span class="se">\n</span>, <span class="se">\r</span>, <span class="se">\t</span>, <span class="se">\'</span>, <span class="se">\"</span>, <span class="se">\\</span><span class="o">)</span>
</code></pre></div></div>

<p>如果我們想要透過python使用這個quantized好的模型，我們可以使用<a href="https://github.com/abetlen/llama-cpp-python">llama-cpp-python</a>，能過直接透過pip來安裝。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>llama-cpp-python
</code></pre></div></div>

<p>接著就能使用類似下面的程式碼來使用了，更多的使用方法可以參考其github repository。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">llama_cpp</span> <span class="kn">import</span> <span class="n">Llama</span>
<span class="n">llm</span> <span class="o">=</span> <span class="nc">Llama</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="sh">"</span><span class="s">./llama-2-13b-chat/ggml-model-f16.gguf.q4_0.bin</span><span class="sh">"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nf">llm</span><span class="p">(</span><span class="sh">"</span><span class="s">YOUR PROMPT HERE</span><span class="sh">"</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">echo</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>值得一提的是，它所回傳的會是一個類似底下的dict object，需要自己再parse一下。</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"cmpl-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"object"</span><span class="p">:</span><span class="w"> </span><span class="s2">"text_completion"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"created"</span><span class="p">:</span><span class="w"> </span><span class="mi">1679561337</span><span class="p">,</span><span class="w">
  </span><span class="nl">"model"</span><span class="p">:</span><span class="w"> </span><span class="s2">"./models/7B/ggml-model.bin"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"choices"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Q: Name the planets in the solar system? A: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto."</span><span class="p">,</span><span class="w">
      </span><span class="nl">"index"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
      </span><span class="nl">"logprobs"</span><span class="p">:</span><span class="w"> </span><span class="err">None</span><span class="p">,</span><span class="w">
      </span><span class="nl">"finish_reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"stop"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"usage"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"prompt_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">14</span><span class="p">,</span><span class="w">
    </span><span class="nl">"completion_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">28</span><span class="p">,</span><span class="w">
    </span><span class="nl">"total_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">42</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="gpu-acceleration">GPU Acceleration</h2>

<p>如果你希望能把已經quantized好的模型，加速跑得更快的話，可以考慮在<code class="language-plaintext highlighter-rouge">pip install llama-cpp-python</code>的時候，多加一些參數，讓它可以使用各種<a href="https://zh.wikipedia.org/zh-tw/BLAS">BLAS</a> backend來加速，如果你安裝的是cuBLAS，還可以使用GPU的資源來加速，詳細的介紹可以參考<a href="https://github.com/abetlen/llama-cpp-python#installation-with-hardware-acceleration">README.md</a>，下面放上使用cuBLAS的安裝指令。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">LLAMA_CUBLAS</span><span class="o">=</span>1
<span class="nv">CMAKE_ARGS</span><span class="o">=</span><span class="s2">"-DLLAMA_CUBLAS=on"</span> <span class="nv">FORCE_CMAKE</span><span class="o">=</span>1 pip <span class="nb">install</span> <span class="nt">--upgrade</span> <span class="nt">--force-reinstall</span> llama-cpp-python <span class="nt">--no-cache-dir</span>
</code></pre></div></div>

<p>這時我們在使用llama-cpp-python的時候，就能於讀取模型的地方多加<code class="language-plaintext highlighter-rouge">n_gpu_layers</code>的參數把部分的模型放到GPU上面執行。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">llama_cpp</span> <span class="kn">import</span> <span class="n">Llama</span>
<span class="n">llm</span> <span class="o">=</span> <span class="nc">Llama</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="sh">"</span><span class="s">./llama-2-13b-chat/ggml-model-f16.gguf</span><span class="sh">"</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">n_gpu_layers</span><span class="o">=</span><span class="mi">43</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nf">llm</span><span class="p">(</span><span class="sh">"</span><span class="s">YOUR PROMPT HERE</span><span class="sh">"</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">echo</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>不同的模型、不同quantized的參數產生的模型所需要的GPU記憶體都不同，需要試著跑看看才知道GPU能不能吃的下來，而模型總共有多少layer可以在llama-cpp-python寫出來的log裡面看到，像是llama2總共有43層，<code class="language-plaintext highlighter-rouge">n_gpu_layers</code>設定超過43跟設43是一樣的效果。</p>

<h3 id="gptq">GPTQ</h3>

<p>上面所使用的quantization方法主要是調整模型參數的bit數，來達到減少運算量的目標，但這樣直接減少bit的數目會對精準度有一些影響，所以就有人在研究怎麼在quantize某一個特定的參數時，適時地調整還沒有被quantize的其他參數，讓整體的loss與quantize前的不要差異太大，其中衍生出了很多方法及其演進（OBD→OBS→OBQ→GPTQ），詳細的介紹和背後的原理推薦看<a href="https://zhuanlan.zhihu.com/p/646210009">QLoRA、GPTQ：模型量化概述</a>這篇文章的介紹。</p>

<p>在<a href="https://huggingface.co/TheBloke/Llama-2-7b-Chat-GPTQ">HuggingFace上</a>，有人使用了GPTQ的技術對Llama2做quantization，並將算出來的模型參數放上去了，如果對上面使用llama.cpp做出來的模型不滿意，且有個不錯的GPU，可以試試看用GPTQ quantize的Llama2。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li><a href="https://zhuanlan.zhihu.com/p/616969812">GPTQ: 模型量化，穷鬼救星</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/646210009">QLoRA、GPTQ：模型量化概述</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="Tool" /><category term="Machine-Learning" /><category term="Natural-Language-Processing" /><summary type="html"><![CDATA[Large Language Model（LLM）的風潮席捲全球，大家都在努力嘗試使用LLM來建造各式各樣的應用，但LLM本身所需要的計算量很大，沒有足夠的資源是跑不起來的，好在網路上有很多大神們在嘗試只使用少量的把LLM給跑起來，這篇文章介紹一下如何使用CPU的資源就將Llama2跑起來。]]></summary></entry><entry><title type="html">Parameter-Efficient Fine-Tuning</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/15/parameter-efficient-fine-tuning/" rel="alternate" type="text/html" title="Parameter-Efficient Fine-Tuning" /><published>2023-07-15T00:00:00+00:00</published><updated>2023-07-15T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/15/parameter-efficient-fine-tuning</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/15/parameter-efficient-fine-tuning/"><![CDATA[<p>隨著大型語言模型（LLM）的蓬勃發展，各式各樣的應用也隨之而來，但如果想要為自己的應用而fine-tune LLM的話，除了更新整個LLM的參數外，還有很多只訓練少量參數的方法，這篇文章簡單介紹一些有效率調整參數的方法。</p>

<!--more-->

<p>PEFT又或是Parameter-Efficient Fine-Tuning指得便是使用少少的參數來有效率地調整模型，省去調整整個模型的參數來達到fine-tune模型的效果，底下會介紹一些常見的PEFT方法。</p>

<h2 id="adapter-tuning">Adapter Tuning</h2>

<p><img src="adapter_tuning.png" alt="Adapter Tuning" /></p>

<p><a href="https://arxiv.org/pdf/1902.00751.pdf">Adapter Tuning</a>的概念是在原本Transformer的架構當中，插入Adapter，並在接下來的訓練裡面只訓練Adapter。</p>

<p>在上圖的左邊是Transformer的架構，主要由Attention layer和Feed-forward layer組成，而在paper裡面，作者們把Adapter插在Feed-foward layer後面、skip connection之前。Adapter的架構展示在上圖右邊，是一個會先降維再升維的Feed-forward layer們，其中也包含了一個skip connection，讓Adapter最差的效果等同於Identity matrix，維持原本LLM的水準。</p>

<h2 id="prefix-tuning">Prefix Tuning</h2>

<p><img src="prefix_tuning.png" alt="Prefix Tuning" /></p>

<p><a href="https://arxiv.org/pdf/2101.00190.pdf">Prefix Tuning</a>的概念是仿照人類在Prompt Engineering裡面，嘗試使用指示性的文字、給一些範例給LLM的方法，以embedding的方式放進模型裡面，作法上是在Transformer的每一層，多加一些可以被訓練的prefix embedding，當Transformer在做attention的時候，就可以參考訓練出來的prefix們來獲得更好的結果。</p>

<p>在paper裡面有提到，如果直接放進prefix讓模型自己去訓練的話，模型的效果會下降而且訓練的時候會不穩定，所以在原始的paper裡面會另外使用一個MLP來產生prefix embeddings，使用比較低維度的向量經過MLP對應到Transformer token的維度大小，等訓練完成以後就只需要留下prefix embeddings，MLP相關的參數就可以拋棄掉了。</p>

<h2 id="prompt-tuning">Prompt Tuning</h2>

<p><img src="prompt_tuning.png" alt="Prompt Tuning" /></p>

<p><a href="https://aclanthology.org/2021.emnlp-main.243.pdf">Prompt Tuning</a>跟Prefix Tuning的想法類似，不過Prompt Tuning只有在輸入的地方加入task specific的prefix，不像Prefix Tuning會在Transformer的每一層都加入embedding。</p>

<p>在做訓練的時候，Prompt Tuning會把各個Task混在一起訓練來增加訓練的穩定度，避免訓練時特別偏重某個Task而偏掉。</p>

<h2 id="p-tuning">P-Tuning</h2>

<h3 id="v1">v1</h3>

<p><img src="p_tuning_v1.png" alt="P-Tuning" /></p>

<p><a href="https://arxiv.org/pdf/2103.10385.pdf">P-Tuning</a>的作法跟前面的各種tuning不同的地方在於，P-Tuning會重新調整預訓練的文字embedding，在上圖左方表示的是原本人類或是機器搜尋最佳prompt的方式，會由Prompt Generator調整prompt裡面的文字，而這些文字進到模型裡面以後會被對應到word embedding，再往後面的Transformer傳，而右方是P-Tuning提出的方法。</p>

<p>在這邊P-Tuning使用了Bidirectional LSTM加上MLP來去替換掉原本word embedding，不過並不是替換掉所有的embedding，只替換了prompt template裡面的embedding而已，prompt template指的是制式化的問題模板，舉例來說我們想問各個地方的首都是哪裡，所以我們準備了各個地方的名字（e.g. Britain、United States等），這些輸入在paper裡面被定義為context，而問題裡面希望LLM產生、但在訓練時會被遮起來的<code class="language-plaintext highlighter-rouge">MASK</code>是target，剩下的<code class="language-plaintext highlighter-rouge">The capital of ___ is ___</code>便是prompt template。</p>

<h3 id="v2">v2</h3>

<p><img src="p_tuning_v2.png" alt="P-Tuning" /></p>

<p><a href="https://aclanthology.org/2022.acl-short.8.pdf">P-Tuning後來出了改良版</a>，在前一個版本裡面雖然方法有效，但在參數量比較少的模型上面表現並不理想，這邊提出的改良方式是搭配Prefix Tuning的想法，把產生出來的embedding當作是prefix放進Transformer的各個layer裡面。</p>

<h2 id="lora-low-rank-adaptation">LoRA: Low-Rank Adaptation</h2>

<p><img class="image image--xl" src="lora.png" /></p>

<p>在前面的各種Tuning裡面雖然可以達到Fine-tune的效果，但是各自有一些些缺點，像是Adapter Tuning因為增加了模型的深度，所以在inference的時候會需要更多的時間，而Prefix Tuning、Prompt Tuning和P-Tuning因為在Transformer裡面增加了token的數量，使得使用者想要輸入進模型的prompt token數量會被排擠到，而<a href="https://arxiv.org/pdf/2106.09685.pdf">LoRA</a>解決了上述的兩個問題。</p>

<p>在Neural Network裡面，主要的構成是把輸入一個向量，經過矩陣運算以後轉換成另外一個向量，而LoRA做的事情就是在原本預訓練好的Neural Network旁邊多加一個中間維度比較少的另一個Neural Network，把相同的input $x$丟進去，把產生出來的結果加回原本Neural Network的輸出當中</p>

\[h=Wx+BAx\]

<p>在初始化的時候，$A$是從Gaussian隨機生成，而$B$則是零矩陣，好讓Fine-tune的時候不會一下就偏掉了。</p>

<p>如果想在Transformer中使用的話，Transformer裡面有很多Multi-head attention，其中包含了很多矩陣像是$W_q,W_k,W_v,W_o$，以及很多MLP，這些矩陣們都可以使用LoRA的方式來Fine-tune，而作者們在paper裡面固定MLP的部分，只把LoRA套用在attention weights上面。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li><a href="https://zhuanlan.zhihu.com/p/618894319">让天下没有难Tuning的大模型-PEFT技术简介</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="Machine-Learning" /><summary type="html"><![CDATA[隨著大型語言模型（LLM）的蓬勃發展，各式各樣的應用也隨之而來，但如果想要為自己的應用而fine-tune LLM的話，除了更新整個LLM的參數外，還有很多只訓練少量參數的方法，這篇文章簡單介紹一些有效率調整參數的方法。]]></summary></entry><entry><title type="html">在本機使用Stable Diffusion產生圖片</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/02/stable-diffusion/" rel="alternate" type="text/html" title="在本機使用Stable Diffusion產生圖片" /><published>2023-07-02T00:00:00+00:00</published><updated>2023-07-02T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/02/stable-diffusion</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/02/stable-diffusion/"><![CDATA[<p>在ChatGPT出來以前有一波使用機器學習產生圖片的熱潮，這篇文章記錄一下如何在本機上面使用Stable Diffusion來產生圖片。</p>

<!--more-->

<h2 id="stable-diffusion介紹">Stable Diffusion介紹</h2>

<p>Stable Diffusion是一種擴散模型（Diffusion model）的衍生，關於擴散模型的介紹可以參考<a href="https://www.youtube.com/watch?v=ifCDXFdeaaM">李宏毅老師的影片</a>，簡單來說就是使用一個類神經網路去不斷地對照片做去除雜訊的動作，於此同時，我們可以在這整個過程裡面加入其他latent variable，來指示圖片生的的樣子，隨著開源的社群把相關的程式碼整理得很好、有簡潔的UI來讓大家使用，造就了一波AI算圖的風潮。</p>

<h2 id="安裝stable-diffusion">安裝Stable Diffusion</h2>

<p>這邊就來介紹一下如何在本機上面安裝Stable Diffusion及其UI，更詳細的說明可以參考<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">官方文件</a>，根據文件裡面的說明，要在Linux上面安裝Stable Diffusion的UI只需要執行底下的指令就可以了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash &lt;<span class="o">(</span>wget <span class="nt">-qO-</span> https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh<span class="o">)</span>
<span class="nb">cd</span> ./stable-diffusion-webui
bash ./webui.sh
</code></pre></div></div>

<h3 id="疑難排解">疑難排解</h3>

<p>如果在安裝的過程當中碰到了一些錯誤，可以參考<a href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/installation/errors/">網路上整理的疑難排解</a>，這邊放上我在安裝時碰到的問題及解法。</p>

<h4 id="執行webuish時碰上repository-clone不下來">執行webui.sh時碰上repository clone不下來</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RuntimeError: Couldn<span class="s1">'t checkout {name}'</span>s <span class="nb">hash</span>: <span class="o">{</span>commithash<span class="o">}</span><span class="nb">.</span>
Command: <span class="s2">"git"</span> <span class="nt">-C</span> <span class="s2">"/home/wjohn1483/stable-diffusion-webui/repositories/k-diffusion"</span> checkout c9fe758757e022f05ca5a53fa8fac28889e4f1cf
Error code: 129
stderr: Unknown option: <span class="nt">-C</span>
</code></pre></div></div>

<p>會碰到這個問題是因為git的版本太舊了，還沒有支援<code class="language-plaintext highlighter-rouge">-C</code>的選項，只需要更新git的版本就可以了，在CentOS裡面更新的指令如下。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nt">-y</span> <span class="nb">install </span>https://packages.endpointdev.com/rhel/7/os/x86_64/endpoint-repo.x86_64.rpm
<span class="nb">sudo </span>yum <span class="nb">install </span>git
</code></pre></div></div>

<h4 id="執行webuish時碰上libgl找不到">執行webui.sh時碰上libGL找不到</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ImportError: libGL.so.1: cannot open shared object file: No such file or directory
</code></pre></div></div>

<p>網路上是建議將<code class="language-plaintext highlighter-rouge">opencv-python</code>移除掉，改安裝<code class="language-plaintext highlighter-rouge">opencv-python-headless</code>就能解決。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 uninstall opencv-python
pip3 <span class="nb">install </span>opencv-python-headless
</code></pre></div></div>

<p>不過有些套件的requirements裡面會要求安裝<code class="language-plaintext highlighter-rouge">opencv-python</code>，所以建議的解法會是安裝好相關的套件，如果是CentOS的話可以使用下面的指令。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> mesa-libGL
</code></pre></div></div>

<h4 id="啟動server時出現not-implemented-for-half">啟動server時，出現not implemented for ‘Half’</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RuntimeError: <span class="s2">"addmm_impl_cpu_"</span> not implemented <span class="k">for</span> <span class="s1">'Half'</span>
RuntimeError: <span class="s2">"LayerNormKernelImpl"</span> not implemented <span class="k">for</span> <span class="s1">'Half'</span>
</code></pre></div></div>

<p>這個查起來是浮點數精度的問題，可以在<strong>webui-user.sh</strong>裡面的<code class="language-plaintext highlighter-rouge">COMMANDLINE_ARGS</code>多加底下的參數來解決。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">COMMANDLINE_ARGS</span><span class="o">=</span><span class="s2">"--precision full --no-half"</span>
</code></pre></div></div>

<h4 id="成功啟動server了但是想讓遠端連進來">成功啟動server了，但是想讓遠端連進來</h4>

<p>預設server會起在<code class="language-plaintext highlighter-rouge">127.0.0.1</code>，如果想改成<code class="language-plaintext highlighter-rouge">0.0.0.0</code>讓其他人可以連線的話，可以在<strong>webui-user.sh</strong>中新增<code class="language-plaintext highlighter-rouge">--listen</code>到<code class="language-plaintext highlighter-rouge">COMMANDLINE_ARGS</code>中。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">COMMANDLINE_ARGS</span><span class="o">=</span><span class="s2">"--precision full --no-half --listen"</span>
</code></pre></div></div>

<p>如果想讓遠端連進來的人可以隨意安裝擴充套件的話，需要額外再加<code class="language-plaintext highlighter-rouge">--enable-insecure-extension-access</code>到其中。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">COMMANDLINE_ARGS</span><span class="o">=</span><span class="s2">"--precision full --no-half --listen --enable-insecure-extension-access"</span>
</code></pre></div></div>

<h2 id="使用各種模型擴充套件">使用各種模型、擴充套件</h2>

<p>在安裝好UI以後，它會預設幫你下載好一個模型，我們就可以直接在上面打字讓模型幫我們產生圖片了，但如果你想要使用其他特化的模型，或是使用擴充套件的話，可以直接在UI上面擴充。</p>

<h3 id="civitai">Civitai</h3>

<p>如果想要擴充模型的話，除了在HuggingFace上面搜尋以外，還可以在<a href="https://civitai.com/">Civitai</a>上面下載，另外在<a href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/installation/download-models/">這邊</a>也有人整理了一些有趣的模型們。</p>

<p>安裝的方式很簡單，只需要把下載下來的<code class="language-plaintext highlighter-rouge">.ckpt</code>或者是<code class="language-plaintext highlighter-rouge">.safetensors</code>的檔案放進<strong>stable-diffusion-webui/models/Stable-diffusion</strong>的資料夾下就行了，也可以使用wget來下載。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># https://civitai.com/models/56383/pirsus-epic-realism</span>
wget https://civitai.com/api/download/models/96535
<span class="nb">mv </span>96535 ./models/Stable-diffusion/pirsusEpicRealism_v21.safetensors
</code></pre></div></div>

<p>這邊的模型編號跟網址列上面的不同，需要使用網頁開發工具來看Download按鈕的URL。</p>

<p>下載完以後應該就能在UI最上方checkpoint的地方看到新的模型了。</p>

<p><img src="checkpoint.png" alt="New Checkpoint" /></p>

<h3 id="controlnet">ControlNet</h3>

<p>除了嘗試用各式各樣的模型和prompt來產生想像中的圖片以外，還可以使用<a href="https://github.com/lllyasviel/ControlNet">ControlNet</a>這個擴充套件來給予模型更精細的指示，像是希望產生的圖片動作要跟範例圖片中的相同。</p>

<p>安裝的方式蠻簡單的，在<code class="language-plaintext highlighter-rouge">Extensions</code>的頁面、選擇<code class="language-plaintext highlighter-rouge">Install from URL</code>、貼上下面的網址、按下Install、到<code class="language-plaintext highlighter-rouge">Installed</code>的tab按下重啟就行了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>https://github.com/Mikubill/sd-webui-controlnet
</code></pre></div></div>

<p><img src="install_extension.png" alt="Install Extension" /></p>

<p>接著我們還需要去<a href="https://huggingface.co/webui/ControlNet-modules-safetensors/tree/main">HuggingFace</a>上面下載ControlNet的模型下來到<strong>extensions/sd-webui-controlnet-main/models</strong>的目錄底下。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors <span class="nt">-P</span> ./extensions/sd-webui-controlnet/models
wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_normal-fp16.safetensors <span class="nt">-P</span> ./extensions/sd-webui-controlnet/models
wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors <span class="nt">-P</span> ./extensions/sd-webui-controlnet/models
</code></pre></div></div>

<p>這邊先下載了三個模型下來，可以根據自己的需求下載不同的模型，這些模型的效果可以參考<a href="https://home.gamer.com.tw/artwork.php?sn=5662905">這篇文章</a>。</p>

<p>安裝擴充套件回到<code class="language-plaintext highlighter-rouge">txt2img</code>的頁面後，應該就能在底下看到ControlNet的區塊了，在這邊我們可以把<code class="language-plaintext highlighter-rouge">Enable</code>打勾、丟上參考圖片、並在Preprocessor的地方選擇你想要的preprocessor，就能使用prompt跟參考圖片來產生更細緻的的圖片了。</p>

<p><img src="controlnet.png" alt="ControlNet Settings" /></p>

<p>這邊我胡亂使用prompt <code class="language-plaintext highlighter-rouge">A strong male</code>和上面的參考圖片，就能產生如底下的圖片了。</p>

<p><img src="generated_image.png" alt="Generated Image" /></p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li>
    <p><a href="https://home.gamer.com.tw/artwork.php?sn=5662905">Stable diffusion ControlNet使用心得 - tark455365的創作 - 巴哈姆特</a></p>
  </li>
  <li>
    <p><a href="https://ivonblog.com/posts/windows-stable-diffusion-webui/">AI繪圖：Windows安裝Stable Diffusion WebUI教學 | Ivon的部落格</a></p>
  </li>
</ol>]]></content><author><name>Your Name</name></author><category term="Machine-Learning" /><category term="Computer-Vision" /><category term="Tool" /><summary type="html"><![CDATA[在ChatGPT出來以前有一波使用機器學習產生圖片的熱潮，這篇文章記錄一下如何在本機上面使用Stable Diffusion來產生圖片。]]></summary></entry></feed>
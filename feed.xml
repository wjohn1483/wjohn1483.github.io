<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/" rel="alternate" type="text/html" /><updated>2024-02-18T09:36:56+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/feed.xml</id><title type="html">wjohn1483.github.io</title><subtitle></subtitle><author><name>Your Name</name></author><entry><title type="html">nginx Reverse Proxy</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/01/20/nginx-reverse-proxy/" rel="alternate" type="text/html" title="nginx Reverse Proxy" /><published>2024-01-20T00:00:00+00:00</published><updated>2024-01-20T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/01/20/nginx-reverse-proxy</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2024/01/20/nginx-reverse-proxy/"><![CDATA[<p>最近想要把在同一台機器上面的不同服務都使用同一個port來去做serving，這邊記錄一下嘗試使用nginx來做reverse proxy的過程。</p>

<!--more-->

<p>在機器上因為不同的需求開了兩個不同的服務在不同的port，但想要讓這兩個服務都透過相同的port 80來給使用者來做使用，這時候我們可以使用nginx的反向代理功能來讓使用者使用相同的port 80，搭配不同的path來連到不同的服務。</p>

<h2 id="安裝nginx">安裝nginx</h2>

<p>底下是在CentOS上面安裝時使用的指令，不同的作業系統的安裝方法可以參考<a href="https://www.nginx.com/resources/wiki/start/topics/tutorials/install/">官網</a>上的介紹。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> nginx
</code></pre></div></div>

<h2 id="設定nginx">設定nginx</h2>

<p>關於nginx的設定都放在<code class="language-plaintext highlighter-rouge">/etc/nginx/nginx.conf</code>裡面，我們可以在http$\rightarrow$server的區塊裡面，新增不同的path來讓nginx來做反向代理。</p>

<div class="language-nginx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># For more information on configuration, see:</span>
<span class="c1">#   * Official English Documentation: http://nginx.org/en/docs/</span>
<span class="c1">#   * Official Russian Documentation: http://nginx.org/ru/docs/</span>

<span class="k">user</span> <span class="s">nginx</span><span class="p">;</span>
<span class="k">worker_processes</span> <span class="s">auto</span><span class="p">;</span>
<span class="k">error_log</span> <span class="n">/var/log/nginx/error.log</span><span class="p">;</span>
<span class="k">pid</span> <span class="n">/run/nginx.pid</span><span class="p">;</span>

<span class="c1"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span>
<span class="k">include</span> <span class="n">/usr/share/nginx/modules/*.conf</span>;

<span class="k">events</span> <span class="p">{</span>
    <span class="kn">worker_connections</span> <span class="mi">1024</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">http</span> <span class="p">{</span>
    <span class="kn">log_format</span>  <span class="s">main</span>  <span class="s">'</span><span class="nv">$remote_addr</span> <span class="s">-</span> <span class="nv">$remote_user</span> <span class="s">[</span><span class="nv">$time_local</span><span class="s">]</span> <span class="s">"</span><span class="nv">$request</span><span class="s">"</span> <span class="s">'</span>
                      <span class="s">'</span><span class="nv">$status</span> <span class="nv">$body_bytes_sent</span> <span class="s">"</span><span class="nv">$http_referer</span><span class="s">"</span> <span class="s">'</span>
                      <span class="s">'"</span><span class="nv">$http_user_agent</span><span class="s">"</span> <span class="s">"</span><span class="nv">$http_x_forwarded_for</span><span class="s">"'</span><span class="p">;</span>

    <span class="kn">access_log</span>  <span class="n">/var/log/nginx/access.log</span>  <span class="s">main</span><span class="p">;</span>

    <span class="kn">sendfile</span>            <span class="no">on</span><span class="p">;</span>
    <span class="kn">tcp_nopush</span>          <span class="no">on</span><span class="p">;</span>
    <span class="kn">tcp_nodelay</span>         <span class="no">on</span><span class="p">;</span>
    <span class="kn">keepalive_timeout</span>   <span class="mi">65</span><span class="p">;</span>
    <span class="kn">types_hash_max_size</span> <span class="mi">4096</span><span class="p">;</span>

    <span class="kn">gzip_static</span> <span class="no">off</span><span class="p">;</span>

    <span class="kn">include</span>             <span class="n">/etc/nginx/mime.types</span><span class="p">;</span>
    <span class="kn">default_type</span>        <span class="nc">application/octet-stream</span><span class="p">;</span>

    <span class="c1"># Load modular configuration files from the /etc/nginx/conf.d directory.</span>
    <span class="c1"># See http://nginx.org/en/docs/ngx_core_module.html#include</span>
    <span class="c1"># for more information.</span>
    <span class="kn">include</span> <span class="n">/etc/nginx/conf.d/*.conf</span><span class="p">;</span>

    <span class="kn">server</span> <span class="p">{</span>
        <span class="kn">listen</span>       <span class="mi">80</span><span class="p">;</span>
        <span class="kn">listen</span>       <span class="s">[::]:80</span><span class="p">;</span>
        <span class="kn">server_name</span>  <span class="s">&lt;YOUR_HOST_NAME&gt;</span><span class="p">;</span>

        <span class="c1"># Load configuration files for the default server block.</span>
        <span class="kn">include</span> <span class="n">/etc/nginx/default.d/*.conf</span><span class="p">;</span>

        <span class="kn">location</span> <span class="n">/</span> <span class="p">{</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:8000</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="kn">location</span> <span class="n">/test</span> <span class="p">{</span>
            <span class="kn">rewrite</span> <span class="s">^/test(/.*)</span>$ <span class="nv">$1</span> <span class="s">break</span><span class="p">;</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:9000</span><span class="p">;</span>
            <span class="kn">proxy_redirect</span> <span class="n">/</span> <span class="n">/test/</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="kn">error_page</span> <span class="mi">404</span> <span class="n">/404.html</span><span class="p">;</span>
        <span class="kn">location</span> <span class="p">=</span> <span class="n">/404.html</span> <span class="p">{</span>
        <span class="p">}</span>

        <span class="kn">error_page</span> <span class="mi">500</span> <span class="mi">502</span> <span class="mi">503</span> <span class="mi">504</span> <span class="n">/50x.html</span><span class="p">;</span>
        <span class="kn">location</span> <span class="p">=</span> <span class="n">/50x.html</span> <span class="p">{</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>在上面的例子裡面，我們新增了底下的設定</p>

<div class="language-nginx highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="k">location</span> <span class="n">/</span> <span class="p">{</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:8000</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="k">location</span> <span class="n">/test</span> <span class="p">{</span>
            <span class="kn">rewrite</span> <span class="s">^/test(/.*)</span>$ <span class="nv">$1</span> <span class="s">break</span><span class="p">;</span>
            <span class="kn">proxy_pass</span> <span class="s">http://localhost:9000</span><span class="p">;</span>
            <span class="kn">proxy_redirect</span> <span class="n">/</span> <span class="n">/test/</span><span class="p">;</span>
        <span class="p">}</span>
</code></pre></div></div>

<p>我們使用<code class="language-plaintext highlighter-rouge">proxy_pass</code>來將不同path的request傳到對應的服務上，假如使用者連到<code class="language-plaintext highlighter-rouge">HOST/</code>，就會導到<code class="language-plaintext highlighter-rouge">localhost:8000</code>，如果連到<code class="language-plaintext highlighter-rouge">HOST/test/</code>就會導到<code class="language-plaintext highlighter-rouge">localhost:9000</code>。</p>

<p>不過如果只有單純的<code class="language-plaintext highlighter-rouge">proxy_pass</code>，被重新導向的路徑會也帶上使用者加上的<code class="language-plaintext highlighter-rouge">/test/</code>，倘若希望在導向的時候將這個path給去除，讓服務收到的request是<code class="language-plaintext highlighter-rouge">/</code>的話，可以使用<code class="language-plaintext highlighter-rouge">rewrite</code>來對request做修改。</p>

<p>同樣地，如果服務收到<code class="language-plaintext highlighter-rouge">/</code>的request以後，想重新導向到服務的<code class="language-plaintext highlighter-rouge">/redirect</code>路徑，這時使用者實際上要request的就會需要是<code class="language-plaintext highlighter-rouge">HOST/test/redirect</code>，我們可以使用<code class="language-plaintext highlighter-rouge">proxy_redirect</code>來幫服務的重新導向加上<code class="language-plaintext highlighter-rouge">/test/</code>的前綴。</p>

<h2 id="啟動nginx">啟動nginx</h2>

<p>在寫好configuration以後，我們可以透過<code class="language-plaintext highlighter-rouge">nginx -t</code>來檢驗設定檔有沒有寫錯的地方，如果順利通過就能將nginx的服務起起來了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo</span> /usr/sbin/nginx <span class="nt">-t</span>
<span class="nb">sudo </span>service nginx start
<span class="nb">sudo </span>service nginx reload
chkconfig nginx on
</code></pre></div></div>

<p>而nginx本身的log會寫到底下的路徑，每當有使用者連線進來，就會寫到<code class="language-plaintext highlighter-rouge">access.log</code>，如果發生了錯誤會寫到<code class="language-plaintext highlighter-rouge">error.log</code>。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/var/log/nginx/access.log
/var/log/nginx/error.log
</code></pre></div></div>

<p>如果之後設定檔有做其他的修改，只需要執行<code class="language-plaintext highlighter-rouge">nginx reload</code>就可以讓新的設定生效。</p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li><a href="https://blog.containerize.com/zh-hant/how-to-setup-and-configure-nginx-as-reverse-proxy/">如何設置和配置為反向代理</a></li>
</ol>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[最近想要把在同一台機器上面的不同服務都使用同一個port來去做serving，這邊記錄一下嘗試使用nginx來做reverse proxy的過程。]]></summary></entry><entry><title type="html">如何使用CPU跑LLM</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/09/11/llama-cpp-introduction/" rel="alternate" type="text/html" title="如何使用CPU跑LLM" /><published>2023-09-11T00:00:00+00:00</published><updated>2023-09-11T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/09/11/llama-cpp-introduction</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/09/11/llama-cpp-introduction/"><![CDATA[<p>Large Language Model（LLM）的風潮席捲全球，大家都在努力嘗試使用LLM來建造各式各樣的應用，但LLM本身所需要的計算量很大，沒有足夠的資源是跑不起來的，好在網路上有很多大神們在嘗試只使用少量的把LLM給跑起來，這篇文章介紹一下如何使用CPU的資源就將Llama2跑起來。</p>

<!--more-->

<h2 id="ggml">GGML</h2>

<p>現在把LLM跑在資源相較匱乏的電腦上的方法主要都是透過quantization來減少模型的計算量，在訓練模型的時候，模型通常都是使用32 bits的浮點數來去儲存參數，倘若我們把浮點數下調一些，用16 bits或是4bits來儲存的話，雖說計算的精準度會下降，但模型在inference的計算量就可以減少很多。</p>

<p>其中quantization最常使用的是<a href="https://github.com/ggerganov/ggml">ggml</a>這個工具，ggml是個用C寫成的套件，它可以幫助你把手上的模型做quantization，而且支援目前大多數的開源LLM模型，支援的模型們可以去它的github上面看。</p>

<h2 id="llamacpp">llama.cpp</h2>

<p><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>是一個基於ggml的工具，讓你可以很輕易地把你手上建構在llama上的模型做quantization，像是Llama、Alpaca、Vicuna、Llama2等都可以透過llama.cpp來把模型變得更小、計算得更快，底下會講一下如何使用llama.cpp來讓Llama2跑在CPU上。</p>

<h3 id="llama2">Llama2</h3>

<p><a href="https://ai.meta.com/llama/">Llama2</a>是Meta基於Llama訓練出來的有條件可商用模型，如果想要取得Llama2的模型，可以直接去Meta的官網上面填寫資料，之後根據寄來的email上的指示就能將模型的參數們下載回來了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % <span class="nb">ls </span>llama-2-13b-chat
checklist.chk  consolidated.00.pth  consolidated.01.pth  params.json  tokenizer.model
</code></pre></div></div>

<h3 id="compile-llamacpp">Compile llama.cpp</h3>

<p>在quantize模型之前，我們需要先編譯一下我們的工具llama.cpp，編譯的方法可以參考github上的<a href="https://github.com/ggerganov/llama.cpp#readme">README.md</a>，如果是Linux的話應該只需要將repository clone下來以後執行make就可以了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/ggerganov/llama.cpp.git
<span class="nb">cd </span>llama.cpp
pip3 <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
make
</code></pre></div></div>

<h3 id="quantization">Quantization</h3>

<p>接下來就可以著手來做quantization了，詳細的步驟也可以參考<a href="https://github.com/ggerganov/llama.cpp#prepare-data--run">官方的README.md</a>，首先我們需要將模型的參數做成16 bits的gguf檔，在過去被稱為ggml，也就是套件的名稱，但後來ggml的格式又做了一些修改，變成了gguf，獲得了更好的可擴充性。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 ./convert.py ~/llama-2-13b-chat/
</code></pre></div></div>

<p>這時在原本模型儲存的路徑下應該會多出一個<strong>ggml-model-f16.gguf</strong>檔，這時其實就可以使用這個比較小的模型檔來在CPU上面做inference了，不過我們還可以進一步的做quantization，來讓執行時間變得更短。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./quantize ~/llama-2-13b-chat/ggml-model-f16.gguf ~/llama-2-13b-chat/ggml-model-f16.gguf.q4_0.bin q4_0
</code></pre></div></div>

<p>在上面的指令裡面，我們給了3個參數，分別是剛剛做好的gguf檔，再來是做完quantization後想輸出的路徑，最後是quantization的方法，quantization的方法在<a href="https://github.com/ggerganov/llama.cpp#quantization">README.md</a>上面有列表來告訴我們有哪些選項，以及其效果如何。</p>

<p>在<a href="https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF">Hugging Face上</a>也已經有別人quantized好的模型了，如果想直接拿現成的也可以從上面下載下來。</p>

<h3 id="inference">Inference</h3>

<p>在quantize好自己想要的大小的模型以後，接下來就是使用這個模型來執行看看prompt了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./main <span class="nt">-m</span> ~/llama-2-13b-chat/ggml-model-f16.gguf.q4_0.bin <span class="nt">-n</span> <span class="nt">-1</span> <span class="nt">-e</span> <span class="nt">-t</span> 8 <span class="nt">-p</span> <span class="s2">"YOUR PROMPT HERE"</span>
</code></pre></div></div>

<p>關於<code class="language-plaintext highlighter-rouge">main</code>更多的參數可以透過<code class="language-plaintext highlighter-rouge">./main -h</code>來查看，這邊列一下上面指令option所代表的意思。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nt">-m</span> FNAME, <span class="nt">--model</span> FNAME
                        model path <span class="o">(</span>default: models/7B/ggml-model-f16.gguf<span class="o">)</span>
  <span class="nt">-n</span> N, <span class="nt">--n-predict</span> N   number of tokens to predict <span class="o">(</span>default: <span class="nt">-1</span>, <span class="nt">-1</span> <span class="o">=</span> infinity, <span class="nt">-2</span> <span class="o">=</span> <span class="k">until </span>context filled<span class="o">)</span>
  <span class="nt">-t</span> N, <span class="nt">--threads</span> N     number of threads to use during computation <span class="o">(</span>default: 4<span class="o">)</span>
  <span class="nt">-p</span> PROMPT, <span class="nt">--prompt</span> PROMPT
                        prompt to start generation with <span class="o">(</span>default: empty<span class="o">)</span>
  <span class="nt">-e</span>, <span class="nt">--escape</span>          process prompt escapes sequences <span class="o">(</span><span class="se">\n</span>, <span class="se">\r</span>, <span class="se">\t</span>, <span class="se">\'</span>, <span class="se">\"</span>, <span class="se">\\</span><span class="o">)</span>
</code></pre></div></div>

<p>如果我們想要透過python使用這個quantized好的模型，我們可以使用<a href="https://github.com/abetlen/llama-cpp-python">llama-cpp-python</a>，能過直接透過pip來安裝。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>llama-cpp-python
</code></pre></div></div>

<p>接著就能使用類似下面的程式碼來使用了，更多的使用方法可以參考其github repository。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">llama_cpp</span> <span class="kn">import</span> <span class="n">Llama</span>
<span class="n">llm</span> <span class="o">=</span> <span class="nc">Llama</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="sh">"</span><span class="s">./llama-2-13b-chat/ggml-model-f16.gguf.q4_0.bin</span><span class="sh">"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nf">llm</span><span class="p">(</span><span class="sh">"</span><span class="s">YOUR PROMPT HERE</span><span class="sh">"</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">echo</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>值得一提的是，它所回傳的會是一個類似底下的dict object，需要自己再parse一下。</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"cmpl-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"object"</span><span class="p">:</span><span class="w"> </span><span class="s2">"text_completion"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"created"</span><span class="p">:</span><span class="w"> </span><span class="mi">1679561337</span><span class="p">,</span><span class="w">
  </span><span class="nl">"model"</span><span class="p">:</span><span class="w"> </span><span class="s2">"./models/7B/ggml-model.bin"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"choices"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Q: Name the planets in the solar system? A: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto."</span><span class="p">,</span><span class="w">
      </span><span class="nl">"index"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
      </span><span class="nl">"logprobs"</span><span class="p">:</span><span class="w"> </span><span class="err">None</span><span class="p">,</span><span class="w">
      </span><span class="nl">"finish_reason"</span><span class="p">:</span><span class="w"> </span><span class="s2">"stop"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"usage"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"prompt_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">14</span><span class="p">,</span><span class="w">
    </span><span class="nl">"completion_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">28</span><span class="p">,</span><span class="w">
    </span><span class="nl">"total_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">42</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="gpu-acceleration">GPU Acceleration</h2>

<p>如果你希望能把已經quantized好的模型，加速跑得更快的話，可以考慮在<code class="language-plaintext highlighter-rouge">pip install llama-cpp-python</code>的時候，多加一些參數，讓它可以使用各種<a href="https://zh.wikipedia.org/zh-tw/BLAS">BLAS</a> backend來加速，如果你安裝的是cuBLAS，還可以使用GPU的資源來加速，詳細的介紹可以參考<a href="https://github.com/abetlen/llama-cpp-python#installation-with-hardware-acceleration">README.md</a>，下面放上使用cuBLAS的安裝指令。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">LLAMA_CUBLAS</span><span class="o">=</span>1
<span class="nv">CMAKE_ARGS</span><span class="o">=</span><span class="s2">"-DLLAMA_CUBLAS=on"</span> <span class="nv">FORCE_CMAKE</span><span class="o">=</span>1 pip <span class="nb">install</span> <span class="nt">--upgrade</span> <span class="nt">--force-reinstall</span> llama-cpp-python <span class="nt">--no-cache-dir</span>
</code></pre></div></div>

<p>這時我們在使用llama-cpp-python的時候，就能於讀取模型的地方多加<code class="language-plaintext highlighter-rouge">n_gpu_layers</code>的參數把部分的模型放到GPU上面執行。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">llama_cpp</span> <span class="kn">import</span> <span class="n">Llama</span>
<span class="n">llm</span> <span class="o">=</span> <span class="nc">Llama</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="sh">"</span><span class="s">./llama-2-13b-chat/ggml-model-f16.gguf</span><span class="sh">"</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">n_gpu_layers</span><span class="o">=</span><span class="mi">43</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nf">llm</span><span class="p">(</span><span class="sh">"</span><span class="s">YOUR PROMPT HERE</span><span class="sh">"</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">echo</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p>不同的模型、不同quantized的參數產生的模型所需要的GPU記憶體都不同，需要試著跑看看才知道GPU能不能吃的下來，而模型總共有多少layer可以在llama-cpp-python寫出來的log裡面看到，像是llama2總共有43層，<code class="language-plaintext highlighter-rouge">n_gpu_layers</code>設定超過43跟設43是一樣的效果。</p>

<h3 id="gptq">GPTQ</h3>

<p>上面所使用的quantization方法主要是調整模型參數的bit數，來達到減少運算量的目標，但這樣直接減少bit的數目會對精準度有一些影響，所以就有人在研究怎麼在quantize某一個特定的參數時，適時地調整還沒有被quantize的其他參數，讓整體的loss與quantize前的不要差異太大，其中衍生出了很多方法及其演進（OBD→OBS→OBQ→GPTQ），詳細的介紹和背後的原理推薦看<a href="https://zhuanlan.zhihu.com/p/646210009">QLoRA、GPTQ：模型量化概述</a>這篇文章的介紹。</p>

<p>在<a href="https://huggingface.co/TheBloke/Llama-2-7b-Chat-GPTQ">HuggingFace上</a>，有人使用了GPTQ的技術對Llama2做quantization，並將算出來的模型參數放上去了，如果對上面使用llama.cpp做出來的模型不滿意，且有個不錯的GPU，可以試試看用GPTQ quantize的Llama2。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li><a href="https://zhuanlan.zhihu.com/p/616969812">GPTQ: 模型量化，穷鬼救星</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/646210009">QLoRA、GPTQ：模型量化概述</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="Tool" /><category term="Machine-Learning" /><category term="Natural-Language-Processing" /><summary type="html"><![CDATA[Large Language Model（LLM）的風潮席捲全球，大家都在努力嘗試使用LLM來建造各式各樣的應用，但LLM本身所需要的計算量很大，沒有足夠的資源是跑不起來的，好在網路上有很多大神們在嘗試只使用少量的把LLM給跑起來，這篇文章介紹一下如何使用CPU的資源就將Llama2跑起來。]]></summary></entry><entry><title type="html">Parameter-Efficient Fine-Tuning</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/15/parameter-efficient-fine-tuning/" rel="alternate" type="text/html" title="Parameter-Efficient Fine-Tuning" /><published>2023-07-15T00:00:00+00:00</published><updated>2023-07-15T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/15/parameter-efficient-fine-tuning</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/15/parameter-efficient-fine-tuning/"><![CDATA[<p>隨著大型語言模型（LLM）的蓬勃發展，各式各樣的應用也隨之而來，但如果想要為自己的應用而fine-tune LLM的話，除了更新整個LLM的參數外，還有很多只訓練少量參數的方法，這篇文章簡單介紹一些有效率調整參數的方法。</p>

<!--more-->

<p>PEFT又或是Parameter-Efficient Fine-Tuning指得便是使用少少的參數來有效率地調整模型，省去調整整個模型的參數來達到fine-tune模型的效果，底下會介紹一些常見的PEFT方法。</p>

<h2 id="adapter-tuning">Adapter Tuning</h2>

<p><img src="adapter_tuning.png" alt="Adapter Tuning" /></p>

<p><a href="https://arxiv.org/pdf/1902.00751.pdf">Adapter Tuning</a>的概念是在原本Transformer的架構當中，插入Adapter，並在接下來的訓練裡面只訓練Adapter。</p>

<p>在上圖的左邊是Transformer的架構，主要由Attention layer和Feed-forward layer組成，而在paper裡面，作者們把Adapter插在Feed-foward layer後面、skip connection之前。Adapter的架構展示在上圖右邊，是一個會先降維再升維的Feed-forward layer們，其中也包含了一個skip connection，讓Adapter最差的效果等同於Identity matrix，維持原本LLM的水準。</p>

<h2 id="prefix-tuning">Prefix Tuning</h2>

<p><img src="prefix_tuning.png" alt="Prefix Tuning" /></p>

<p><a href="https://arxiv.org/pdf/2101.00190.pdf">Prefix Tuning</a>的概念是仿照人類在Prompt Engineering裡面，嘗試使用指示性的文字、給一些範例給LLM的方法，以embedding的方式放進模型裡面，作法上是在Transformer的每一層，多加一些可以被訓練的prefix embedding，當Transformer在做attention的時候，就可以參考訓練出來的prefix們來獲得更好的結果。</p>

<p>在paper裡面有提到，如果直接放進prefix讓模型自己去訓練的話，模型的效果會下降而且訓練的時候會不穩定，所以在原始的paper裡面會另外使用一個MLP來產生prefix embeddings，使用比較低維度的向量經過MLP對應到Transformer token的維度大小，等訓練完成以後就只需要留下prefix embeddings，MLP相關的參數就可以拋棄掉了。</p>

<h2 id="prompt-tuning">Prompt Tuning</h2>

<p><img src="prompt_tuning.png" alt="Prompt Tuning" /></p>

<p><a href="https://aclanthology.org/2021.emnlp-main.243.pdf">Prompt Tuning</a>跟Prefix Tuning的想法類似，不過Prompt Tuning只有在輸入的地方加入task specific的prefix，不像Prefix Tuning會在Transformer的每一層都加入embedding。</p>

<p>在做訓練的時候，Prompt Tuning會把各個Task混在一起訓練來增加訓練的穩定度，避免訓練時特別偏重某個Task而偏掉。</p>

<h2 id="p-tuning">P-Tuning</h2>

<h3 id="v1">v1</h3>

<p><img src="p_tuning_v1.png" alt="P-Tuning" /></p>

<p><a href="https://arxiv.org/pdf/2103.10385.pdf">P-Tuning</a>的作法跟前面的各種tuning不同的地方在於，P-Tuning會重新調整預訓練的文字embedding，在上圖左方表示的是原本人類或是機器搜尋最佳prompt的方式，會由Prompt Generator調整prompt裡面的文字，而這些文字進到模型裡面以後會被對應到word embedding，再往後面的Transformer傳，而右方是P-Tuning提出的方法。</p>

<p>在這邊P-Tuning使用了Bidirectional LSTM加上MLP來去替換掉原本word embedding，不過並不是替換掉所有的embedding，只替換了prompt template裡面的embedding而已，prompt template指的是制式化的問題模板，舉例來說我們想問各個地方的首都是哪裡，所以我們準備了各個地方的名字（e.g. Britain、United States等），這些輸入在paper裡面被定義為context，而問題裡面希望LLM產生、但在訓練時會被遮起來的<code class="language-plaintext highlighter-rouge">MASK</code>是target，剩下的<code class="language-plaintext highlighter-rouge">The capital of ___ is ___</code>便是prompt template。</p>

<h3 id="v2">v2</h3>

<p><img src="p_tuning_v2.png" alt="P-Tuning" /></p>

<p><a href="https://aclanthology.org/2022.acl-short.8.pdf">P-Tuning後來出了改良版</a>，在前一個版本裡面雖然方法有效，但在參數量比較少的模型上面表現並不理想，這邊提出的改良方式是搭配Prefix Tuning的想法，把產生出來的embedding當作是prefix放進Transformer的各個layer裡面。</p>

<h2 id="lora-low-rank-adaptation">LoRA: Low-Rank Adaptation</h2>

<p><img class="image image--xl" src="lora.png" /></p>

<p>在前面的各種Tuning裡面雖然可以達到Fine-tune的效果，但是各自有一些些缺點，像是Adapter Tuning因為增加了模型的深度，所以在inference的時候會需要更多的時間，而Prefix Tuning、Prompt Tuning和P-Tuning因為在Transformer裡面增加了token的數量，使得使用者想要輸入進模型的prompt token數量會被排擠到，而<a href="https://arxiv.org/pdf/2106.09685.pdf">LoRA</a>解決了上述的兩個問題。</p>

<p>在Neural Network裡面，主要的構成是把輸入一個向量，經過矩陣運算以後轉換成另外一個向量，而LoRA做的事情就是在原本預訓練好的Neural Network旁邊多加一個中間維度比較少的另一個Neural Network，把相同的input $x$丟進去，把產生出來的結果加回原本Neural Network的輸出當中</p>

\[h=Wx+BAx\]

<p>在初始化的時候，$A$是從Gaussian隨機生成，而$B$則是零矩陣，好讓Fine-tune的時候不會一下就偏掉了。</p>

<p>如果想在Transformer中使用的話，Transformer裡面有很多Multi-head attention，其中包含了很多矩陣像是$W_q,W_k,W_v,W_o$，以及很多MLP，這些矩陣們都可以使用LoRA的方式來Fine-tune，而作者們在paper裡面固定MLP的部分，只把LoRA套用在attention weights上面。</p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li><a href="https://zhuanlan.zhihu.com/p/618894319">让天下没有难Tuning的大模型-PEFT技术简介</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="Machine-Learning" /><summary type="html"><![CDATA[隨著大型語言模型（LLM）的蓬勃發展，各式各樣的應用也隨之而來，但如果想要為自己的應用而fine-tune LLM的話，除了更新整個LLM的參數外，還有很多只訓練少量參數的方法，這篇文章簡單介紹一些有效率調整參數的方法。]]></summary></entry><entry><title type="html">在本機使用Stable Diffusion產生圖片</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/02/stable-diffusion/" rel="alternate" type="text/html" title="在本機使用Stable Diffusion產生圖片" /><published>2023-07-02T00:00:00+00:00</published><updated>2023-07-02T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/02/stable-diffusion</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/07/02/stable-diffusion/"><![CDATA[<p>在ChatGPT出來以前有一波使用機器學習產生圖片的熱潮，這篇文章記錄一下如何在本機上面使用Stable Diffusion來產生圖片。</p>

<!--more-->

<h2 id="stable-diffusion介紹">Stable Diffusion介紹</h2>

<p>Stable Diffusion是一種擴散模型（Diffusion model）的衍生，關於擴散模型的介紹可以參考<a href="https://www.youtube.com/watch?v=ifCDXFdeaaM">李宏毅老師的影片</a>，簡單來說就是使用一個類神經網路去不斷地對照片做去除雜訊的動作，於此同時，我們可以在這整個過程裡面加入其他latent variable，來指示圖片生的的樣子，隨著開源的社群把相關的程式碼整理得很好、有簡潔的UI來讓大家使用，造就了一波AI算圖的風潮。</p>

<h2 id="安裝stable-diffusion">安裝Stable Diffusion</h2>

<p>這邊就來介紹一下如何在本機上面安裝Stable Diffusion及其UI，更詳細的說明可以參考<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">官方文件</a>，根據文件裡面的說明，要在Linux上面安裝Stable Diffusion的UI只需要執行底下的指令就可以了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash &lt;<span class="o">(</span>wget <span class="nt">-qO-</span> https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh<span class="o">)</span>
<span class="nb">cd</span> ./stable-diffusion-webui
bash ./webui.sh
</code></pre></div></div>

<h3 id="疑難排解">疑難排解</h3>

<p>如果在安裝的過程當中碰到了一些錯誤，可以參考<a href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/installation/errors/">網路上整理的疑難排解</a>，這邊放上我在安裝時碰到的問題及解法。</p>

<h4 id="執行webuish時碰上repository-clone不下來">執行webui.sh時碰上repository clone不下來</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RuntimeError: Couldn<span class="s1">'t checkout {name}'</span>s <span class="nb">hash</span>: <span class="o">{</span>commithash<span class="o">}</span><span class="nb">.</span>
Command: <span class="s2">"git"</span> <span class="nt">-C</span> <span class="s2">"/home/wjohn1483/stable-diffusion-webui/repositories/k-diffusion"</span> checkout c9fe758757e022f05ca5a53fa8fac28889e4f1cf
Error code: 129
stderr: Unknown option: <span class="nt">-C</span>
</code></pre></div></div>

<p>會碰到這個問題是因為git的版本太舊了，還沒有支援<code class="language-plaintext highlighter-rouge">-C</code>的選項，只需要更新git的版本就可以了，在CentOS裡面更新的指令如下。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nt">-y</span> <span class="nb">install </span>https://packages.endpointdev.com/rhel/7/os/x86_64/endpoint-repo.x86_64.rpm
<span class="nb">sudo </span>yum <span class="nb">install </span>git
</code></pre></div></div>

<h4 id="執行webuish時碰上libgl找不到">執行webui.sh時碰上libGL找不到</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ImportError: libGL.so.1: cannot open shared object file: No such file or directory
</code></pre></div></div>

<p>網路上是建議將<code class="language-plaintext highlighter-rouge">opencv-python</code>移除掉，改安裝<code class="language-plaintext highlighter-rouge">opencv-python-headless</code>就能解決。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 uninstall opencv-python
pip3 <span class="nb">install </span>opencv-python-headless
</code></pre></div></div>

<p>不過有些套件的requirements裡面會要求安裝<code class="language-plaintext highlighter-rouge">opencv-python</code>，所以建議的解法會是安裝好相關的套件，如果是CentOS的話可以使用下面的指令。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> mesa-libGL
</code></pre></div></div>

<h4 id="啟動server時出現not-implemented-for-half">啟動server時，出現not implemented for ‘Half’</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RuntimeError: <span class="s2">"addmm_impl_cpu_"</span> not implemented <span class="k">for</span> <span class="s1">'Half'</span>
RuntimeError: <span class="s2">"LayerNormKernelImpl"</span> not implemented <span class="k">for</span> <span class="s1">'Half'</span>
</code></pre></div></div>

<p>這個查起來是浮點數精度的問題，可以在<strong>webui-user.sh</strong>裡面的<code class="language-plaintext highlighter-rouge">COMMANDLINE_ARGS</code>多加底下的參數來解決。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">COMMANDLINE_ARGS</span><span class="o">=</span><span class="s2">"--precision full --no-half"</span>
</code></pre></div></div>

<h4 id="成功啟動server了但是想讓遠端連進來">成功啟動server了，但是想讓遠端連進來</h4>

<p>預設server會起在<code class="language-plaintext highlighter-rouge">127.0.0.1</code>，如果想改成<code class="language-plaintext highlighter-rouge">0.0.0.0</code>讓其他人可以連線的話，可以在<strong>webui-user.sh</strong>中新增<code class="language-plaintext highlighter-rouge">--listen</code>到<code class="language-plaintext highlighter-rouge">COMMANDLINE_ARGS</code>中。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">COMMANDLINE_ARGS</span><span class="o">=</span><span class="s2">"--precision full --no-half --listen"</span>
</code></pre></div></div>

<p>如果想讓遠端連進來的人可以隨意安裝擴充套件的話，需要額外再加<code class="language-plaintext highlighter-rouge">--enable-insecure-extension-access</code>到其中。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">COMMANDLINE_ARGS</span><span class="o">=</span><span class="s2">"--precision full --no-half --listen --enable-insecure-extension-access"</span>
</code></pre></div></div>

<h2 id="使用各種模型擴充套件">使用各種模型、擴充套件</h2>

<p>在安裝好UI以後，它會預設幫你下載好一個模型，我們就可以直接在上面打字讓模型幫我們產生圖片了，但如果你想要使用其他特化的模型，或是使用擴充套件的話，可以直接在UI上面擴充。</p>

<h3 id="civitai">Civitai</h3>

<p>如果想要擴充模型的話，除了在HuggingFace上面搜尋以外，還可以在<a href="https://civitai.com/">Civitai</a>上面下載，另外在<a href="https://ivonblog.com/posts/stable-diffusion-webui-manuals/installation/download-models/">這邊</a>也有人整理了一些有趣的模型們。</p>

<p>安裝的方式很簡單，只需要把下載下來的<code class="language-plaintext highlighter-rouge">.ckpt</code>或者是<code class="language-plaintext highlighter-rouge">.safetensors</code>的檔案放進<strong>stable-diffusion-webui/models/Stable-diffusion</strong>的資料夾下就行了，也可以使用wget來下載。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># https://civitai.com/models/56383/pirsus-epic-realism</span>
wget https://civitai.com/api/download/models/96535
<span class="nb">mv </span>96535 ./models/Stable-diffusion/pirsusEpicRealism_v21.safetensors
</code></pre></div></div>

<p>這邊的模型編號跟網址列上面的不同，需要使用網頁開發工具來看Download按鈕的URL。</p>

<p>下載完以後應該就能在UI最上方checkpoint的地方看到新的模型了。</p>

<p><img src="checkpoint.png" alt="New Checkpoint" /></p>

<h3 id="controlnet">ControlNet</h3>

<p>除了嘗試用各式各樣的模型和prompt來產生想像中的圖片以外，還可以使用<a href="https://github.com/lllyasviel/ControlNet">ControlNet</a>這個擴充套件來給予模型更精細的指示，像是希望產生的圖片動作要跟範例圖片中的相同。</p>

<p>安裝的方式蠻簡單的，在<code class="language-plaintext highlighter-rouge">Extensions</code>的頁面、選擇<code class="language-plaintext highlighter-rouge">Install from URL</code>、貼上下面的網址、按下Install、到<code class="language-plaintext highlighter-rouge">Installed</code>的tab按下重啟就行了。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>https://github.com/Mikubill/sd-webui-controlnet
</code></pre></div></div>

<p><img src="install_extension.png" alt="Install Extension" /></p>

<p>接著我們還需要去<a href="https://huggingface.co/webui/ControlNet-modules-safetensors/tree/main">HuggingFace</a>上面下載ControlNet的模型下來到<strong>extensions/sd-webui-controlnet-main/models</strong>的目錄底下。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors <span class="nt">-P</span> ./extensions/sd-webui-controlnet/models
wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_normal-fp16.safetensors <span class="nt">-P</span> ./extensions/sd-webui-controlnet/models
wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors <span class="nt">-P</span> ./extensions/sd-webui-controlnet/models
</code></pre></div></div>

<p>這邊先下載了三個模型下來，可以根據自己的需求下載不同的模型，這些模型的效果可以參考<a href="https://home.gamer.com.tw/artwork.php?sn=5662905">這篇文章</a>。</p>

<p>安裝擴充套件回到<code class="language-plaintext highlighter-rouge">txt2img</code>的頁面後，應該就能在底下看到ControlNet的區塊了，在這邊我們可以把<code class="language-plaintext highlighter-rouge">Enable</code>打勾、丟上參考圖片、並在Preprocessor的地方選擇你想要的preprocessor，就能使用prompt跟參考圖片來產生更細緻的的圖片了。</p>

<p><img src="controlnet.png" alt="ControlNet Settings" /></p>

<p>這邊我胡亂使用prompt <code class="language-plaintext highlighter-rouge">A strong male</code>和上面的參考圖片，就能產生如底下的圖片了。</p>

<p><img src="generated_image.png" alt="Generated Image" /></p>

<h2 id="參考資料">參考資料</h2>

<ol>
  <li>
    <p><a href="https://home.gamer.com.tw/artwork.php?sn=5662905">Stable diffusion ControlNet使用心得 - tark455365的創作 - 巴哈姆特</a></p>
  </li>
  <li>
    <p><a href="https://ivonblog.com/posts/windows-stable-diffusion-webui/">AI繪圖：Windows安裝Stable Diffusion WebUI教學 | Ivon的部落格</a></p>
  </li>
</ol>]]></content><author><name>Your Name</name></author><category term="Machine-Learning" /><category term="Computer-Vision" /><category term="Tool" /><summary type="html"><![CDATA[在ChatGPT出來以前有一波使用機器學習產生圖片的熱潮，這篇文章記錄一下如何在本機上面使用Stable Diffusion來產生圖片。]]></summary></entry><entry><title type="html">如何在本機上跑Vicuna模型</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/04/30/vicuna/" rel="alternate" type="text/html" title="如何在本機上跑Vicuna模型" /><published>2023-04-30T00:00:00+00:00</published><updated>2023-04-30T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/04/30/vicuna</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/04/30/vicuna/"><![CDATA[<p>隨著LLaMA的推出，有越來越多人基於該模型做了各式各樣的調校，而Vicuna是其中的一種，這篇文章記錄一下如何在自己的機器上面將Vicuna跑起來。</p>

<!--more-->

<h2 id="vicuna">Vicuna</h2>

<p><a href="https://vicuna.lmsys.org/">Vicuna</a>是一個基於<a href="https://github.com/facebookresearch/llama">LLaMA</a>的大型語言模型（LLM），開發團隊使用GPT-4來當作評審去評論Vicuna和ChatGPT的回答哪個比較好，而Vicuna在測試裡面達到了90%的水準，是個表現相當不錯的模型，個人覺得回答的效果比起<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a>和單純的LLaMA還要好上不少。</p>

<p>底下會講一下如何在本機上面執行Vicuna，在ChatGPT跑不出你想要的結果時，不妨嘗試將問題問看看Vicuna。</p>

<h2 id="下載llama">下載LLaMA</h2>

<p>由於Vicuna是基於LLaMA的模型，首先我們會需要先拿到LLaMA的參數，正規的方式是去這份<a href="https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform">google表單</a>上面填寫資料，跟Meta申請使用許可，不過網路社群上也提供了很多其他的方式來讓大家下載，像是<a href="https://github.com/juncongmoo/pyllama">pyllama</a>。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>pyllama <span class="nt">-U</span>
python <span class="nt">-m</span> llama.download <span class="nt">--model_size</span> 13B <span class="nt">--folder</span> /tmp/pyllama_data
</code></pre></div></div>

<p>只要下上面的指令就能簡單下載到LLaMA 13B的參數了，詳細的說明可以參考pyllama的文件。</p>

<p>在執行的過程中有可能連線會卡住，可以使用<code class="language-plaintext highlighter-rouge">Ctrl+C</code>將連線斷開以後執行第二行的指令，它會從斷掉的地方繼續下載，不用怕會需要從頭下載，下載下來的參數僅限於研究的用途，不應該再被拿去做其他使用。</p>

<h2 id="轉成huggingface的格式">轉成huggingface的格式</h2>

<p>在下載好LLaMA的參數以後，我們需要將下載下來的參數轉成hugging face的格式，為此我們需要安裝<code class="language-plaintext highlighter-rouge">transformers</code>在機器上，而Vicuna要求transformers的版本要在<strong>4.28.0</strong>以上，如果直接用pip安裝的版本不夠高的話，可以直接下下面的指令來安裝最新版。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>https://github.com/huggingface/transformers/archive/refs/heads/main.zip
</code></pre></div></div>

<p>接著就能將LLaMA轉成hugging face的格式了</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 ./convert_llama_weights_to_hf.py <span class="se">\</span>
    <span class="nt">--input_dir</span> ./pyllama_data <span class="se">\</span>
    <span class="nt">--model_size</span> 13B <span class="se">\</span>
    <span class="nt">--output_dir</span> ./llama_hf
</code></pre></div></div>

<p>上面指令裡面的<code class="language-plaintext highlighter-rouge">convert_llama_weights_to_hf.py</code>是使用<a href="https://huggingface.co/docs/transformers/main/model_doc/llama">LLaMA在hugging face頁面上</a>所提供的<a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py">這份</a>，而<code class="language-plaintext highlighter-rouge">./pyllama_data</code>是上面使用pyllama下載下來的資料夾、<code class="language-plaintext highlighter-rouge">./llama_hf</code>是輸出的資料夾。</p>

<h2 id="下載vicuna-delta">下載Vicuna delta</h2>

<p>Vicuna的參數放在他們的<a href="https://huggingface.co/lmsys">hugging face帳戶上</a>，但因為裡面有包含了非常大檔案的參數檔，所以在使用git clone下來之前會需要先安裝<a href="https://git-lfs.com/">Git Large File Storage（LFS）</a>才能將大檔案下載下來，底下是在Cent OS上安裝並下載的指令。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-s</span> https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | <span class="nb">sudo </span>bash
<span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> git-lfs
git lfs <span class="nb">install
</span>git clone https://huggingface.co/lmsys/vicuna-13b-delta-v1.1
</code></pre></div></div>

<h2 id="apply-vicuna-delta">Apply Vicuna delta</h2>

<p>有了LLaMA的參數和Vicuna的delta後，我們需要將delta套用在LLaMA的參數上來獲得實際的Vicuna，套用的方法是使用pip <code class="language-plaintext highlighter-rouge">fschat</code>的套件。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install </span>fschat
python3 <span class="nt">-m</span> fastchat.model.apply_delta <span class="se">\</span>
    <span class="nt">--base</span> ./llama_hf <span class="se">\</span>
    <span class="nt">--target</span> ./vicuna-13b <span class="se">\</span>
    <span class="nt">--delta</span> ./vicuna-13b-delta-v1.1
</code></pre></div></div>

<p>使用套件裡面的<code class="language-plaintext highlighter-rouge">apply_delta</code>搭配先前準備好的hugging face格式的LLaMA和Vicuna delta就能獲得實際的Vicuna了，值得一提的是套用7B的模型需要30GB的RAM，而13B的模型需要60GB，如果RAM沒有那麼足夠的話，可以參考<a href="https://github.com/lm-sys/FastChat#low-cpu-memory-conversion">文件當中的方式</a>來降低記憶體的使用。</p>

<h2 id="使用vicuna">使用Vicuna</h2>

<p>準備好Vicuna得參數後，便能使用fastchat提供的function來在terminal上面跟Vicuna對話了，詳細的參數可以參考<a href="https://github.com/lm-sys/FastChat#inference-with-command-line-interface">文件</a>。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> fastchat.serve.cli <span class="nt">--model-path</span> ./vicuna-13b-delta-v1.1
</code></pre></div></div>

<p>如果想用網頁版的方式來互動，fastchat也有使用<a href="https://gradio.app/">Gradio</a>來包成網頁，詳細的說明請參考<a href="https://github.com/lm-sys/FastChat#serving-with-web-gui">文件</a>。</p>

<p>Vicuna有另外推出了<a href="https://github.com/lm-sys/FastChat#fastchat-t5">FastChat-T5</a>供大家在商業上使用，指令跟上面文章的相同，只需要將模型的路徑指到FastChat-T5就行了。</p>]]></content><author><name>Your Name</name></author><category term="Tool" /><category term="Natural-Language-Processing" /><summary type="html"><![CDATA[隨著LLaMA的推出，有越來越多人基於該模型做了各式各樣的調校，而Vicuna是其中的一種，這篇文章記錄一下如何在自己的機器上面將Vicuna跑起來。]]></summary></entry><entry><title type="html">將PySpark Executor的Log蒐集到Driver</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/03/23/pyspark-executor-log/" rel="alternate" type="text/html" title="將PySpark Executor的Log蒐集到Driver" /><published>2023-03-23T00:00:00+00:00</published><updated>2023-03-23T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/03/23/pyspark-executor-log</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/03/23/pyspark-executor-log/"><![CDATA[<p>這篇文章記錄一下如何用spark內建的accumulator把在executor的資訊帶回driver上。</p>

<!--more-->

<p>在寫PySpark的程式時，我們很常會寫一些user-defined function（UDF），在executor上面執行這些UDF來處理資料，如果在UDF裡面有<code class="language-plaintext highlighter-rouge">print</code>之類的指令來印出處理的過程，雖說可以在spark UI上面能找到executor印出來的結果，但是當處理的步驟很多、UDF也很多的時候，就需要花一些時間去定位這個UDF是在哪個stage執行，才可以找到對應的log。</p>

<p>如果想要省去在spark UI上面尋找特定UDF log的麻煩，我們可以透過<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.Accumulator.html">spark內建的accumulator</a>來把各個executor上的log蒐集起來到driver上，最後在driver上一次把所有的log都印出來，如此便能在同一個地方看到各個UDF執行的log了。</p>

<h2 id="pyspark-accumulator">Pyspark Accumulator</h2>

<p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.Accumulator.html">Accumulator</a>是一個累加器，executor們可以對accumulator進行<code class="language-plaintext highlighter-rouge">add</code>的動作，來更新accumulator的數值，常用的是int和float的累加，一個簡單的範例可以從<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.Accumulator.html">spark的官方文件</a>裡面看到。</p>

<h2 id="custom-accumulatorparam">Custom AccumulatorParam</h2>

<p>目前原生支援的accumulator只有支援數值型的資料型態，為了要把我們UDF執行的log放進accumulator裡面，我們需要自己寫一個<code class="language-plaintext highlighter-rouge">AccumulatorParam</code>的class，讓Accumulator可以接受數值以外的資料，底下是一個讓accumulator吃<code class="language-plaintext highlighter-rouge">dict</code>的範例，可以按照每次不同的需求而修改</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.accumulators</span> <span class="kn">import</span> <span class="n">AccumulatorParam</span>


<span class="k">class</span> <span class="nc">DictParam</span><span class="p">(</span><span class="n">AccumulatorParam</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">zero</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">init_value</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">init_value</span>

    <span class="k">def</span> <span class="nf">addInPlace</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">v1</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">v2</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
            <span class="n">v1</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">v2</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">v1</span>
</code></pre></div></div>

<p>在上面的class裡面有兩個method，<code class="language-plaintext highlighter-rouge">zero()</code>是在初始化accumulator的時候會被呼叫的method，可以在這邊設定一開始的預設值，而<code class="language-plaintext highlighter-rouge">addInPlace()</code>是決定每個executor的資料要如何被整合在一起的method，在上面的例子裡面，我們可以想像每個executor會回傳一個<code class="language-plaintext highlighter-rouge">dict</code>的資料，這些<code class="language-plaintext highlighter-rouge">dict</code>會逐個丟入<code class="language-plaintext highlighter-rouge">addInPlace()</code>來收斂成一個<code class="language-plaintext highlighter-rouge">dict</code>。</p>

<p>在UDF裡面寫入log的方式就跟一般accumulator使用的方法一樣，只不過這邊就會變成你所定義的資料型態了，一個簡單的測試可以參考底下的例子</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="n">pyspark.accumulators</span> <span class="kn">import</span> <span class="n">AccumulatorParam</span>


<span class="k">class</span> <span class="nc">DictParam</span><span class="p">(</span><span class="n">AccumulatorParam</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">zero</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">init_value</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">init_value</span>

    <span class="k">def</span> <span class="nf">addInPlace</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">v1</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">v2</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
            <span class="n">v1</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">v2</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">v1</span>


<span class="k">def</span> <span class="nf">manipulate_dict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">accumulator</span><span class="p">):</span>
    <span class="n">accumulator</span><span class="p">.</span><span class="nf">add</span><span class="p">({</span><span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="s">This is the executor processing </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="sh">"</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nf">enableHiveSupport</span><span class="p">().</span><span class="nf">getOrCreate</span><span class="p">()</span>
    <span class="n">rdd</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span><span class="p">.</span><span class="nf">parallelize</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="n">accumulator</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span><span class="p">.</span><span class="nf">accumulator</span><span class="p">({},</span> <span class="nc">DictParam</span><span class="p">())</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">rdd</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">manipulate_list</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">accumulator</span><span class="p">)).</span><span class="nf">collect</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">accumulator</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">()</span>
</code></pre></div></div>

<p>在上面的程式碼裡面，我們寫了一個<code class="language-plaintext highlighter-rouge">manipulate_dict()</code>的UDF，在function裡面會去把收到的參數放進accumulator裡面並回傳參數的平方出去，這個程式執行後在driver印出來的結果如下</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">81</span><span class="p">]</span>
<span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 0</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 1</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 2</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 3</span><span class="sh">'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 4</span><span class="sh">'</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 5</span><span class="sh">'</span><span class="p">,</span> <span class="mi">6</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 6</span><span class="sh">'</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 7</span><span class="sh">'</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 8</span><span class="sh">'</span><span class="p">,</span> <span class="mi">9</span><span class="p">:</span> <span class="sh">'</span><span class="s">This is the executor processing 9</span><span class="sh">'</span><span class="p">}</span>
</code></pre></div></div>

<p>如果說只是想要寫入單純的字串到accumulator裡面，可以改用<code class="language-plaintext highlighter-rouge">list</code>的param來達成搜集executor log的目的</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="n">pyspark.accumulators</span> <span class="kn">import</span> <span class="n">AccumulatorParam</span>


<span class="k">class</span> <span class="nc">ListParam</span><span class="p">(</span><span class="n">AccumulatorParam</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">zero</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">init_value</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">init_value</span>

    <span class="k">def</span> <span class="nf">addInPlace</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">v1</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">v1</span> <span class="o">+=</span> <span class="n">v2</span>
        <span class="k">return</span> <span class="n">v1</span>


<span class="k">def</span> <span class="nf">manipulate_list</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">accumulator</span><span class="p">):</span>
    <span class="n">accumulator</span><span class="p">.</span><span class="nf">add</span><span class="p">([</span><span class="sa">f</span><span class="sh">"</span><span class="s">This is the executor processing </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="sh">"</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nf">enableHiveSupport</span><span class="p">().</span><span class="nf">getOrCreate</span><span class="p">()</span>
    <span class="n">rdd</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span><span class="p">.</span><span class="nf">parallelize</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="n">accumulator</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span><span class="p">.</span><span class="nf">accumulator</span><span class="p">([],</span> <span class="nc">ListParam</span><span class="p">())</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">rdd</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">manipulate_list</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">accumulator</span><span class="p">)).</span><span class="nf">collect</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">accumulator</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">()</span>
</code></pre></div></div>

<p>在driver上印出的結果如下</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">81</span><span class="p">]</span>
<span class="p">[</span><span class="sh">'</span><span class="s">This is the executor processing 0</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 3</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 4</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 5</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 6</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 7</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 8</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">This is the executor processing 9</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<p>透過自定義<code class="language-plaintext highlighter-rouge">AccumulatorParam</code>，我們可以很彈性地在UDF回傳想要印在driver上的資料，讓debug spark的程式變得輕鬆一些。</p>

<h2 id="references">References</h2>

<ul>
  <li>
    <p><a href="https://towardsdatascience.com/custom-pyspark-accumulators-310f63ca3c8c">Custom PySpark Accumulators</a></p>
  </li>
  <li>
    <p><a href="https://stackoverflow.com/questions/44640184/accumulator-in-pyspark-with-dict-as-global-variable">dictionary - accumulator in pyspark with dict as global variable - Stack Overflow</a></p>
  </li>
</ul>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[這篇文章記錄一下如何用spark內建的accumulator把在executor的資訊帶回driver上。]]></summary></entry><entry><title type="html">Temporal Collaborative Ranking Via Personalized Transformer</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/03/18/temporal-collaborative-ranking-via-personalized-transformer/" rel="alternate" type="text/html" title="Temporal Collaborative Ranking Via Personalized Transformer" /><published>2023-03-18T00:00:00+00:00</published><updated>2023-03-18T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/03/18/temporal-collaborative-ranking-via-personalized-transformer</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/03/18/temporal-collaborative-ranking-via-personalized-transformer/"><![CDATA[<p>這篇文章記錄一下看完<a href="https://arxiv.org/pdf/1908.05435.pdf">這篇paper</a>的筆記。</p>

<!--more-->

<h2 id="推薦系統">推薦系統</h2>

<p>推薦系統裡面常用的做法可以粗略分成三種：</p>

<ul>
  <li>
    <p>item-to-item：目標是找到與使用者互動的商品接近的其他商品</p>
  </li>
  <li>
    <p>user-to-user：找到與使用者類似的其他使用者，推薦其他使用者有互動的商品</p>
  </li>
  <li>
    <p>user-to-item：綜觀的看待使用者和商品的互動，嘗試預測使用者和未互動的商品的關係，collaborative filtering就是這樣的方法，如果有把互動的順序也納入考量的話就會變成sequential recommendation</p>
  </li>
</ul>

<h2 id="模型介紹">模型介紹</h2>

<p>在這篇paper裡面的模型便是sequential recommendation的方法，以transformer的模型為主要的架構來做推薦系統。</p>

<h3 id="任務定義">任務定義</h3>

<p>在paper當中，假設我們有$n$個使用者、$m$個商品，模型想要做的就是根據使用者過去的行為，預測出下個時間點會跟這$m$個商品的哪個做互動，以分數最高的前$K$個商品作為推薦，亦即是把商品當作文字，使用language model的方式來預測下一個商品會是什麼，在這邊以$s_i$來代表使用者互動的商品序列</p>

\[s_i=(j_{i1},j_{i2},...,j_{iT}),for\ 1\le i\le n\]

<p>$s_i$表示的是使用者$i$從舊到新，在過去$T$個時間點有互動的商品們。</p>

<p>在切train/valid/test set的時候，作者是以最後一個商品作為test set、倒數第二個做為validation set，其他都是training set。</p>

<h3 id="personalized-transformer">Personalized Transformer</h3>

<p>底下是這篇paper的模型架構，作者將這個模型取名為Stochastic Shared Embedding - Personalized Transformer（SSE-PT）。</p>

<p><img src="ssept_architecture.png" alt="SSE-PT Architecture" /></p>

<h4 id="embedding-layer">Embedding Layer</h4>

<p>在這邊作者將使用者的embedding和商品的embedding用兩個lookup table來做紀錄，分別是$U\in R^{n\times d_u}$、$V\in R^{m\times d_i}$，其中$n$是使用者的數量、$m$是商品的數量，而$d_u$和$d_i$分別是兩者embedding的長度。</p>

\[E=
\begin{bmatrix}
[v_{j_{i1}};u_i]+p_1 \\
[v_{j_{i2}};u_i]+p_2 \\
.\\
.\\
.\\
[v_{j_{iT}};u_i]+p_T \\
\end{bmatrix}
\in R^{T \times d}\]

<p>在輸入到Self-Attention layer之前，會把商品的embedding和使用者的embedding接在一起後加上positional encoding才輸入到下一層，這邊的$d=d_u+d_i$、$P\in R^{T\times d}$。</p>

<h4 id="self-attention-layer">Self-Attention Layer</h4>

<p>這邊的Self-Attention layer跟<a href="https://wjohn1483.github.io/2020/03/21/attention-is-all-you-need/#scaled-dot-product-attention">其他地方</a>見到的是一樣的。</p>

\[S=SA(E)=\mathrm{Attention}\left (  EW^{(Q)}, EW^{(H)}, EW^{(V)} \right ), where\ W^{(Q)}, W^{(H)}, W^{(V)}\in R^{d\times d}\]

\[\mathrm{Attention}(Q,H,V)=\mathrm{softmax}\left ( \frac{QH^T}{\sqrt{d}} \right ) \cdot V\]

<h4 id="pointwise-feed-forward-layer">Pointwise Feed-Forward Layer</h4>

<p>在經過Self-Attention layer以後，作者為了要在結果$S\in R^{n\times d}$多加一些non-linearity，所以在之後接了兩層feed-forward layer。</p>

\[F=FC(S)=\mathrm{Relu}(SW+b)\cdot \tilde{W}+\tilde{b}\]

<p>其中$W,\tilde{W}\in R^{d\times d}$是weight、$b,\tilde{b}\in R^d$是bias。</p>

<h4 id="self-attention-blocks">Self-Attention Blocks</h4>

<p>Self-Attention block其實就是self-attention layer和feed-forward layer兩者組合在一起做成一個block，每一個block的輸入便是上一個block的輸出。</p>

\[S^{(2)}=SA(F^{(1)})\]

<p>在這邊使用$B$來表示總共使用了多少block。</p>

<h4 id="prediction-layer">Prediction Layer</h4>

<p>在經過了多層的Self-Attention block以後，這邊paper使用了最後一個block的輸出中最後一個時間點的向量$F^B_{t-1}$跟商品$l$和使用者embedding的concatenation做內積再過sigmoid來當作是模型對使用者$i$在時間點$t$推薦商品$l$的分數$p_{itl}$。</p>

\[p_{itl}=\sigma(r_{itl})\]

\[r_{itl}=F^B_{t-1}\cdot [v_l;u_i]\]

<p>式(7)中的$\sigma$是sigmoid function。</p>

<h4 id="loss-function">Loss Function</h4>

<p>這邊所使用的loss function如下</p>

\[\sum_i\sum_{t=1}^{T-1}\sum_{k\in\Omega}-\left [ \log(p_{itl})+\log(1-p_{itk}) \right ]\]

<p>目標是希望positive的商品所得到的分數$p_{itl}$能越接近1越好，而negative商品所得到的分數$p_{itk}$能越小越好。</p>

<p>最終產生的$K$個推薦商品便是把所有商品$l$都去算出$r_{itl}$，取前$K$大的商品推薦出去。</p>

<h4 id="stochastic-shared-embeddingssse">Stochastic Shared Embeddings（SSE）</h4>

<p>在這篇paper裡面嘗試了多個regularization的方式像是layer normalization、residual connections、dropout等，模型的表現都沒有很好，最終使用了作者在<a href="https://arxiv.org/pdf/1905.10630.pdf">另一篇paper</a>發表的stochastic shared embeddings來做regularization才獲得了不錯的結果。</p>

<p>SSE的想法是，在一個knowledge graph裡面，兩個有相連的節點$j$、$k$，兩者所代表的意思應該會是相近的，所以如果在做stocahstic gradient descent的時候，我們把模型裡面embedding $j$的部分以某個特定的機率換成embedding $k$應該是不會影響到模型的成效，卻能帶來regularization的好處，SSE詳細的algorithm如下</p>

<p><img src="./sse_algorithm.png" alt="SSE Algorithm" /></p>

<p>如果今天碰到的問題並不是以graph為基礎，作者認為所有的東西還是是在一個很大的graph包含著，任一embedding $j$還是可以有微小的機率用embedding $k$來替換，而機率的定義如下</p>

\[p(j,k\vert \Phi)=\frac{p_0}{N-1},\forall\ 1\le k \ne j \le N\]

<p>$N$為整個embedding table的大小，而$p_0$是一個自定義數字，在paper裡面定義成$p_0=0.01$。</p>

<h4 id="sse-pt">SSE-PT++</h4>

<p>由於SSE-PT這個模型在架構上最多只能輸入長度最大為$T$的$s$，如果有人的互動紀錄長度大過$T$的話會塞不進模型中，為了解決這個問題，paper使用了sample的方式來把$s$輸入進模型中。</p>

<p>給定一個機率$p_s$，模型會從$[1,t-T]$的範圍中抽樣出一個index $v$，並把$v$以後$T$個商品當作是這個使用者$i$的$s_i$，亦即</p>

\[s_i=(j_{iv},j_{i(v+1)},...,j_{i(v+T-1)})\]

<p>而另外$1-p_s$的機率會直接使用最後$T$個商品作為$s_i$</p>

\[s_i=(j_{i(t-T+1)},...,j_{it})\]

<h2 id="實驗結果">實驗結果</h2>

<h3 id="evaluation-metrics">Evaluation Metrics</h3>

<p>這邊介紹一下實驗中使用的metrics和其他推薦系統常用到的metrics。</p>

<h4 id="recallk">Recall@K</h4>

<p>$Recall@K$指的是所有使用者喜歡的商品裡面，有多少個出現在推薦系統推薦的前$K$個商品裡面。</p>

\[Recall=\frac{\vert Relevant \cap Retrieved\vert}{\vert Relevant \vert}\]

<p>假如使用者喜歡100個商品，而在推薦系統推薦的商品裡面有出現10個使用者喜歡的商品，那$Recall@K$便是$\frac{10}{100}=0.1$。</p>

<h4 id="precisionk">Precision@K</h4>

<p>$Precision@K$指的是推薦系統推薦的前$K$個商品裡面，有多少個包含到使用者實際喜歡的商品。</p>

\[Precision=\frac{\vert Relevant \cap Retrieved\vert}{\vert Retrieved\vert}\]

<p>假如推薦系統推薦了100個商品，其中有3個有被使用者實際喜歡，那$Precision@K$便是$\frac{3}{100}=0.03$。</p>

<h4 id="mrrk">MRR@K</h4>

<p>$MRR@K$是Mean Reciprocal Rank@K的縮寫，這個metric用在衡量有多會找到一個使用者有興趣的商品，假設$K=3$，推薦系統推薦出的結果如下，其中v表示的是推薦出的商品是使用者有興趣的。</p>

<table>
  <thead>
    <tr>
      <th>User</th>
      <th>Rank 1</th>
      <th>Rank 2</th>
      <th>Rank 3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>u1</td>
      <td> </td>
      <td>v</td>
      <td> </td>
    </tr>
    <tr>
      <td>u2</td>
      <td>v</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>u3</td>
      <td> </td>
      <td> </td>
      <td>v</td>
    </tr>
  </tbody>
</table>

<p>$MRR@K$的計算方式便是算出每一個使用者的Reciprocal Rank後平均，也就是第一個有興趣商品的排名倒數平均，在上面例子中u1的reciprocal rank是$\frac{1}{2}$、u2的reciprocal rank是$\frac{1}{1}$，整個推薦系統的$MRR@K$就是$\frac{\left ( \frac{1}{2}+\frac{1}{1}+\frac{1}{3} \right )}{3}$。</p>

<h4 id="mapk">MAP@K</h4>

<p>MAP的全稱是Mean Average Precision，指的是每一個使用者的Average Precision再平均起來，假如說推薦結果推薦出的結果如下，其中v表示推薦出的商品是使用者有興趣的。</p>

<table>
  <thead>
    <tr>
      <th>User</th>
      <th>Rank 1</th>
      <th>Rank 2</th>
      <th>Rank 3</th>
      <th>Rank 4</th>
      <th>Rank 5</th>
      <th>Rank 6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>u1</td>
      <td> </td>
      <td>v</td>
      <td> </td>
      <td>v</td>
      <td> </td>
      <td>v</td>
    </tr>
    <tr>
      <td>u2</td>
      <td>v</td>
      <td> </td>
      <td>v</td>
      <td> </td>
      <td>v</td>
      <td> </td>
    </tr>
    <tr>
      <td>u3</td>
      <td> </td>
      <td>v</td>
      <td>v</td>
      <td>v</td>
      <td>v</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>使用者的average precision的計算方式是看截止目前推薦順序為止，算出目前的$Precision@K$，最後再平均起來</p>

\[Average\ Precision@6(u1)=\frac{\frac{0}{1}+\frac{1}{2}+\frac{1}{3}+\frac{2}{4}+\frac{2}{5}+\frac{3}{6}}{6}\]

\[Average\ Precision@6(u2)=\frac{\frac{1}{1}+\frac{1}{2}+\frac{2}{3}+\frac{2}{4}+\frac{3}{5}+\frac{3}{6}}{6}\]

<p>而整個推薦系統的$MAP@K$便是上面算出來的每個使用者的Average Precision的平均。</p>

<h4 id="ndcgk">NDCG@K</h4>

<p>NDCG是Normalized Discounted Cumulative Gain的縮寫，在上面的例子裡面，使用者只會有有興趣和沒興趣兩種標示，如果我們擁有每個使用者對商品的評分的話，就可以算出更精確的方式算出推薦系統的好壞。</p>

<p>假如使用者對每個商品的評分如下，這邊使用者對商品的評分稱之為$Gain$</p>

<table>
  <thead>
    <tr>
      <th>User</th>
      <th>Item 1</th>
      <th>Item 2</th>
      <th>Item 3</th>
      <th>Item 4</th>
      <th>Item 5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>u1</td>
      <td>1</td>
      <td>3</td>
      <td>5</td>
      <td>7</td>
      <td>9</td>
    </tr>
    <tr>
      <td>u2</td>
      <td>8</td>
      <td>4</td>
      <td>7</td>
      <td>9</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>假如推薦系統推薦出的商品如下</p>

<table>
  <thead>
    <tr>
      <th>User</th>
      <th>Rank 1</th>
      <th>Rank 2</th>
      <th>Rank 3</th>
      <th>Rank 4</th>
      <th>Rank 5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>u1</td>
      <td>Item 4</td>
      <td>Item 3</td>
      <td>Item 5</td>
      <td>Item 2</td>
      <td>Item 1</td>
    </tr>
    <tr>
      <td>u2</td>
      <td>Item 1</td>
      <td>Item 2</td>
      <td>Item 5</td>
      <td>Item 3</td>
      <td>Item 4</td>
    </tr>
  </tbody>
</table>

<p>我們先看u1的推薦結果，把裡面的商品替換成使用者的評分</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Rank 1</th>
      <th>Rank 2</th>
      <th>Rank 3</th>
      <th>Rank 4</th>
      <th>Rank 5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$Gain(u1)$</td>
      <td>7</td>
      <td>5</td>
      <td>9</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <td>$Cumulative\ Gain(u1)$</td>
      <td>7</td>
      <td>12</td>
      <td>21</td>
      <td>24</td>
      <td>25</td>
    </tr>
  </tbody>
</table>

<p>表格內的$Cumulative\ Gain$表示的是$Gain$隨著推薦順序的累加，由於我們希望推薦系統要能優先推薦使用者評分比較高的商品出來，所以越後面商品的分數需要有一個折扣，乘上折扣算出來的結果稱之為$Discounted\ Cumulative\ Gain\ (DCG)$</p>

\[DCG@K=\sum_{r=1}^{K}\frac{2^{Gain@r}-1}{\log_2(r+1)}\]

<p>可以想成是我們把使用者原本的$Gain$都根據它們的分數和排名重新計算，之後再累積起來，而上面例子u1的$DCG@5$便是</p>

\[DCG@5(u_1)=\frac{2^7-1}{\log_2(1+1)}+\frac{2^5-1}{\log_2(1+2)}+\frac{2^9-1}{\log_2(1+3)}+\frac{2^3-1}{\log_2(1+4)}+\frac{2^1-1}{\log_2(1+5)}\]

<p>雖說這樣可以從$DCG$裡面判斷出哪個推薦系統可以把使用者評分高的商品放在前面，但不同資料使用者的評分量級都不一樣，有可能評分從1到100或是只有1到5，這會造成$DCG$算出來的數字無法在不同資料集做比較，因此我們會需要做一個normalization，作法是去對$DCG$除上$Idealized\ DCG\ (IDCG)$，也就是除上最理想情況上的$DCG$，亦即推薦結果是按照分數由大到小排序的$DCG$</p>

<table>
  <thead>
    <tr>
      <th>對u1的推薦</th>
      <th>Rank 1</th>
      <th>Rank 2</th>
      <th>Rank 3</th>
      <th>Rank 4</th>
      <th>Rank 5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>實際排序</td>
      <td>Item 4</td>
      <td>Item 3</td>
      <td>Item 5</td>
      <td>Item 2</td>
      <td>Item 1</td>
    </tr>
    <tr>
      <td>理想排序</td>
      <td>Item 5</td>
      <td>Item 4</td>
      <td>Item 3</td>
      <td>Item 2</td>
      <td>Item 1</td>
    </tr>
  </tbody>
</table>

<p>根據上表的理想排序可以依照先前的方式算出$DCG$，而整個推薦系統的$NDCG$便是每一個使用者實際排序的$DCG$去除上理想排序的$DCG$算出來的數字再平均</p>

\[NDCG@K=\frac{1}{n}\sum_{i=1}^{n}\frac{DCG@K(u_i)}{IDCG@K(u_i)}\]

<h3 id="results">Results</h3>

<p>底下是SSE-PT和其他模型的比較，可以看到SSE-PT的表現不俗。</p>

<p><img src="./results.png" alt="Results" /></p>

<h2 id="參考資料">參考資料</h2>

<ul>
  <li><a href="https://zhuanlan.zhihu.com/p/293082914">推荐系统炼丹笔记：RecSys2020-SSE-PT解锁序列数据挖掘新姿势</a></li>
  <li><a href="https://ithelp.ithome.com.tw/articles/10192869">文件檢索的評價 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天</a></li>
  <li><a href="https://blog.csdn.net/anshuai_aw1/article/details/83117012">IR的评价指标-MAP，MRR和NDCG的形象理解_ndcg和mrr_anshuai_aw1的博客-CSDN博客</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="Recommendation-System" /><category term="Paper" /><summary type="html"><![CDATA[這篇文章記錄一下看完這篇paper的筆記。]]></summary></entry><entry><title type="html">Google Apps Script介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/23/google-apps-script/" rel="alternate" type="text/html" title="Google Apps Script介紹" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/23/google-apps-script</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/23/google-apps-script/"><![CDATA[<p>在<a href="https://wjohn1483.github.io/2021/06/05/display-html-in-google-sheet/">先前的文章</a>裡面，使用了Google apps script來在Google sheet裡面顯示html，而Google apps script還可以做到更多的事情，這篇文章簡單介紹一下Google apps script是什麼，並如何使用它操作Google calendar。</p>

<!--more-->

<h2 id="google-apps-script">Google Apps Script</h2>

<p><a href="https://www.google.com/script/start/">Google Apps Script（GAS）</a>是一個基於javascript的開發平台，可以在其中方便地跟Google Workspace的服務像是Gmail、Google Calendar、Google Maps等做整合，讓你可以對這些服務做更細緻的操作或是讓多個服務做連動。舉例來說，可以透過Google Sheet整理要一併寄出的收件者和內容，透過GAS來串連Gmail做寄出，又或者可以用GAS來設定今天這個Google Form收到多少回覆後就自動停止等。</p>

<p>除了寫給讓自己的生活更便利以外，GAS還可以部署成web api或者是extension來讓其他人打、使用，是個簡單卻又強大的功能，以下會帶一個<a href="https://developers.google.com/apps-script/samples/automations/vacation-calendar">同步group mail底下個人行事曆到共享行事曆的例子</a>來看看GAS要怎麼寫，如果想看其他更多的應用除了可以看<a href="https://developers.google.com/apps-script/samples">官方文件的範例</a>以外，強烈建議可以看<a href="https://ithelp.ithome.com.tw/articles/10275214">這篇文章</a>，裡面詳述地記載了一些常用到的scenario，並有實際的程式碼來一步一步帶領你建立屬於你的GAS。</p>

<h2 id="同步行事曆">同步行事曆</h2>

<p>在一個團隊裡面有時會有不定人數的人請假，為了能更方便地一眼看到誰請假，避免打擾到休假的人，我們時常會建立一個共享的團隊行事曆，讓大家去填上哪天休假，但這時請假的人就會需要在個人的行事曆上建立請假的事件，並額外在共享的行事曆上也建立相同的事件。</p>

<p>這種類型的事情，就很適合透過GAS來達成，我們可以寫一個GAS去週期性地掃團隊裡面的每個人的行事曆，把有特殊關鍵字的事件引入到共享的行事曆中，就可以節省團隊成員手動建立事件到共享行事曆的時間了。</p>

<p>詳細的程式碼和說明可以參考<a href="https://developers.google.com/apps-script/samples/automations/vacation-calendar">官方文件</a>，底下會稍微解釋一下這件事情是如何被達成的。</p>

<h3 id="程式概覽">程式概覽</h3>

<p>在跟著<a href="https://developers.google.com/apps-script/samples/automations/vacation-calendar">官方文件</a>建立新的行事曆以後，有個按鈕可以打開範例的專案，建立副本以後就能做修改了，理論上照著說明把變數換成你想要的並執行就能達到上述的功能了。</p>

<p>在專案裡面分成兩大塊，在Services裡面可以看到有個<code class="language-plaintext highlighter-rouge">Calendar</code>的service，表示我們在<code class="language-plaintext highlighter-rouge">Code.gs</code>裡面會需要用到calendar的API，而<code class="language-plaintext highlighter-rouge">Code.gs</code>是我們主要實現邏輯的地方。</p>

<p>在<code class="language-plaintext highlighter-rouge">Code.gs</code>裡面有底下幾個function：</p>

<ul>
  <li>
    <p>setup：設定trigger來去定期地執行sync</p>
  </li>
  <li>
    <p>sync：程式的進入點，去逐一掃描團隊個人行事曆裡面的事件是不是有包含到定義的關鍵字，如果有，就引入到共享行事曆中</p>
  </li>
  <li>
    <p>importEvent：引入event到共享行事曆中</p>
  </li>
  <li>
    <p>findEvents：尋找哪些event該被引入到共享行事曆中</p>
  </li>
  <li>
    <p>shoudImportEvent：判斷該不該引入event</p>
  </li>
  <li>
    <p>formatDateAsRFC3339：把日期轉成特定格式</p>
  </li>
</ul>

<p>其實裡面的邏輯並不複雜，註解也寫得很詳細，可以很快速地看懂每個function想要做的事情，而裡面所使用的物件method可以在<a href="https://developers.google.com/apps-script/reference/calendar">Apps Script的文件</a>當中找到每個method的定義、傳入值和回傳值。</p>

<h3 id="測試程式">測試程式</h3>

<p><img src="./debug.png" alt="Debug" /></p>

<p>在寫好了想要的邏輯以後，可以在畫面上方的menu bar裡面選擇想要測試的function並點擊<code class="language-plaintext highlighter-rouge">Debug</code>的按鈕來測試想要的功能有沒有被實現，如果在上面找不到寫好的function，可能是因為還沒有儲存專案的關係。</p>

<p>如果想要印出debug訊息，除了使用<code class="language-plaintext highlighter-rouge">Debug</code>按鈕提供的sidebar以外，可以使用<code class="language-plaintext highlighter-rouge">console.log()</code>來把訊息寫在console中。</p>

<h3 id="定期執行程式">定期執行程式</h3>

<p>在<code class="language-plaintext highlighter-rouge">setup()</code>裡面會透過API建立一個每30分鐘執行一次的排程作業，我們也可以透過左邊的Triggers手動建立一個trigger來定期執行GAS，而GAS會在GCP的default專案裡面被執行，也就是使用你個人的資源來運行，不過Google有提供<a href="https://developers.google.com/apps-script/guides/services/quotas">免費的quota</a>來做使用，而每次執行的log都可以在左邊Executions的tab裡面找到。</p>

<p>如果想要把專案部署成API、使用Service API的次數超過免費額度，就會需要把這份GAS改放到其他專案裡面，根據用量來付費。</p>

<h2 id="結論">結論</h2>

<p>GAS是個方便統整Google服務的平台，除了<a href="https://ithelp.ithome.com.tw/articles/10275214">上述文章</a>提供的使用情境外，還可以根據自身碰到的情況來做擴充，藉由研讀Google服務們所提供的API來達到你的需求。</p>

<p>像是在上面同步行事曆的GAS裡面，如果有人後來決定不請假的話，在程式碼裡面是不會判斷這件事並把共享行事曆裡面的事件刪除掉的，這時就可以參考Calendar的API來自行撰寫刪除事件的function。</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/**
 * Delete all events in the calendar with id TEAM_CALENDAR_ID
 */</span>
<span class="kd">function</span> <span class="nf">deleteAllEvents</span><span class="p">(</span><span class="nx">start</span><span class="p">,</span> <span class="nx">end</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">let</span> <span class="nx">calendar</span> <span class="o">=</span> <span class="nx">CalendarApp</span><span class="p">.</span><span class="nf">getCalendarById</span><span class="p">(</span><span class="nx">TEAM_CALENDAR_ID</span><span class="p">);</span>
  <span class="kd">let</span> <span class="nx">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">'</span><span class="s1">Delete all events in calendar "</span><span class="dl">'</span> <span class="o">+</span> <span class="nx">calendar</span><span class="p">.</span><span class="nf">getName</span><span class="p">()</span> <span class="o">+</span> <span class="dl">'</span><span class="s1">"</span><span class="se">\n</span><span class="s1">from "</span><span class="dl">'</span> <span class="o">+</span> <span class="nx">start</span> <span class="o">+</span> <span class="dl">'</span><span class="s1">"</span><span class="se">\n</span><span class="s1">to "</span><span class="dl">'</span> <span class="o">+</span> <span class="nx">end</span> <span class="o">+</span> <span class="dl">'</span><span class="s1">"</span><span class="dl">'</span><span class="p">);</span>
  <span class="nx">events</span> <span class="o">=</span> <span class="nx">calendar</span><span class="p">.</span><span class="nf">getEvents</span><span class="p">(</span><span class="nx">start</span><span class="p">,</span> <span class="nx">end</span><span class="p">);</span>
  <span class="nx">events</span><span class="p">.</span><span class="nf">forEach</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">event</span><span class="p">){</span>
    <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">'</span><span class="s1">Deleting: </span><span class="dl">'</span> <span class="o">+</span> <span class="nx">event</span><span class="p">.</span><span class="nf">getTitle</span><span class="p">()</span> <span class="o">+</span> <span class="dl">'</span><span class="se">\n</span><span class="s1">starting from </span><span class="dl">'</span> <span class="o">+</span> <span class="nx">event</span><span class="p">.</span><span class="nf">getStartTime</span><span class="p">()</span> <span class="o">+</span> <span class="dl">'</span><span class="se">\n</span><span class="s1">end at </span><span class="dl">'</span> <span class="o">+</span> <span class="nx">event</span><span class="p">.</span><span class="nf">getEndTime</span><span class="p">());</span>
    <span class="nx">event</span><span class="p">.</span><span class="nf">deleteEvent</span><span class="p">();</span>
    <span class="nx">count</span><span class="o">++</span><span class="p">;</span>
  <span class="p">});</span>
  <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">Deleted </span><span class="dl">"</span> <span class="o">+</span> <span class="nx">count</span> <span class="o">+</span> <span class="dl">"</span><span class="s2"> events</span><span class="dl">"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>上面的function會把共享行事曆裡面特定日期內的所有事件都刪除，我們就能用這個簡單的方式在import事件之前把事件都清空，再把event引入到行事曆中來達到event同步刪除的功能。</p>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[在先前的文章裡面，使用了Google apps script來在Google sheet裡面顯示html，而Google apps script還可以做到更多的事情，這篇文章簡單介紹一下Google apps script是什麼，並如何使用它操作Google calendar。]]></summary></entry><entry><title type="html">xsv使用介紹</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/15/xsv/" rel="alternate" type="text/html" title="xsv使用介紹" /><published>2023-02-15T00:00:00+00:00</published><updated>2023-02-15T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/15/xsv</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/15/xsv/"><![CDATA[<p>這篇文章簡單紀錄xsv，一個處理csv檔案的command line工具的使用範例。</p>

<!--more-->

<p><a href="https://github.com/BurntSushi/xsv">xsv</a>是一個command line工具，專門用來處理csv檔案，方便使用者在處理資料或是觀察資料的時候可以迅速地得到想要的結果。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Usage:
    xsv &lt;command&gt; [&lt;args&gt;...]
    xsv [options]

Options:
    --list        List all commands available.
    -h, --help    Display this message
    &lt;command&gt; -h  Display the command help message
    --version     Print version info and exit

Commands:
    cat         Concatenate by row or column
    count       Count records
    fixlengths  Makes all records have same length
    flatten     Show one field per line
    fmt         Format CSV output (change field delimiter)
    frequency   Show frequency tables
    headers     Show header names
    help        Show this usage message.
    index       Create CSV index for faster access
    input       Read CSV data with special quoting rules
    join        Join CSV files
    sample      Randomly sample CSV data
    search      Search CSV data with regexes
    select      Select columns from CSV
    slice       Slice records from CSV
    sort        Sort CSV data
    split       Split CSV data into many files
    stats       Compute basic statistics
    table       Align CSV data into columns
</code></pre></div></div>

<p>上面是xsv的usage，底下會走過一遍在<a href="https://github.com/BurntSushi/xsv/blob/master/README.md">xsv的README.md</a>裡面的範例，會更清楚各個指令的使用情況。</p>

<h2 id="取得範例資料">取得範例資料</h2>

<p>在開始執行範例之前，會需要先準備一個csv檔案來作為指令的作用對象，在README.md裡面提供了一個範例資料，記載了世界上每個城市的人口。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LO</span> https://burntsushi.net/stuff/worldcitiespop.csv
</code></pre></div></div>

<h2 id="安裝xsv">安裝xsv</h2>

<p>安裝xsv的方法可以參照<a href="https://github.com/BurntSushi/xsv#installation">官方文件裡面的說明</a>，如果是mac的話可以直接使用底下的指令。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>xsv
</code></pre></div></div>

<p>如果是Windows或是Linux，xsv也有提供<a href="https://github.com/BurntSushi/xsv/releases/">binary檔在GitHub上可以下載</a>，下面的指令是以Linux為範例。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://github.com/BurntSushi/xsv/releases/download/0.13.0/xsv-0.13.0-x86_64-unknown-linux-musl.tar.gz
<span class="nb">tar </span>zxvf xsv-0.13.0-x86_64-unknown-linux-musl.tar.gz
<span class="nb">sudo mv </span>xsv /usr/local/bin
</code></pre></div></div>

<h2 id="查看csv的基本資料">查看csv的基本資料</h2>

<h3 id="csv裡面有哪些欄位">csv裡面有哪些欄位</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv headers worldcitiespop.csv
1   Country
2   City
3   AccentCity
4   Region
5   Population
6   Latitude
7   Longitude
</code></pre></div></div>

<h3 id="各個欄位的統計數據">各個欄位的統計數據</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv stats <span class="nt">--everything</span> worldcitiespop.csv | xsv table
field       <span class="nb">type     sum                 </span>min            max            min_length  max_length  mean                stddev              median      mode         cardinality
Country     Unicode                      ad             zw             2           2                                                               cn           234
City        Unicode                       bab el ahmar  Þykkvibaer     1           91                                                              san jose     2351892
AccentCity  Unicode                       Bâb el Ahmar  ïn Bou Chella  1           91                                                              San Antonio  2375760
Region      Unicode                      00             Z9             0           2                                                   13          04           397
Population  Integer  2289584999          7              31480498       0           8           47719.570633597126  302885.5592040396   10779                    28754
Latitude    Float    86294096.37312101   <span class="nt">-54</span>.933333     82.483333      1           12          27.188165808468785  21.95261384912504   32.4972221  51.15        1038349
Longitude   Float    117718483.57958724  <span class="nt">-179</span>.9833333   180            1           14          37.08885989656418   63.223010459241635  35.28       23.8         1167162
</code></pre></div></div>

<p>在指令裡面的<code class="language-plaintext highlighter-rouge">--everything</code>是把所有可以得到的統計數字都列出來，在這個例子裡面如果不下<code class="language-plaintext highlighter-rouge">--everything</code>的話，欄位就會少了median、mode和cardinality，<code class="language-plaintext highlighter-rouge">xsv stats</code>最後產生出來的會是csv的格式，為了在terminal上面比較好觀察，所以把結果pipe到<code class="language-plaintext highlighter-rouge">xsv table</code>裡面讓它把結果排整齊。</p>

<h3 id="csv有多少筆資料">csv有多少筆資料</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv count worldcitiespop.csv
3173958
</code></pre></div></div>

<h2 id="查看csv的內容">查看csv的內容</h2>

<h3 id="查看csv的特定列數">查看csv的特定列數</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv slice worldcitiespop.csv <span class="nt">-s</span> 0 <span class="nt">-e</span> 5 | xsv table
Country  City        AccentCity  Region  Population  Latitude    Longitude
ad       aixas       Aixàs       06                  42.4833333  1.4666667
ad       aixirivali  Aixirivali  06                  42.4666667  1.5
ad       aixirivall  Aixirivall  06                  42.4666667  1.5
ad       aixirvall   Aixirvall   06                  42.4666667  1.5
ad       aixovall    Aixovall    06                  42.4666667  1.4833333
</code></pre></div></div>

<p>在指令裡面的<code class="language-plaintext highlighter-rouge">-s/--start</code>是開始的列數，這邊index是0-based的，所以第一筆資料的index是0，而<code class="language-plaintext highlighter-rouge">-e/--end</code>是結束的列數，所給予的index<strong>不會</strong>包含在輸出裡面，可以想成會輸出的資料列數是<code class="language-plaintext highlighter-rouge">[start, end)</code>。</p>

<p>在<code class="language-plaintext highlighter-rouge">xsv slice</code>裡面還有提供<code class="language-plaintext highlighter-rouge">-l/--len</code>的argument來讓使用者決定要輸出多少列。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv slice worldcitiespop.csv <span class="nt">-s</span> 0 <span class="nt">-l</span> 6 | xsv table
Country  City        AccentCity  Region  Population  Latitude    Longitude
ad       aixas       Aixàs       06                  42.4833333  1.4666667
ad       aixirivali  Aixirivali  06                  42.4666667  1.5
ad       aixirivall  Aixirivall  06                  42.4666667  1.5
ad       aixirvall   Aixirvall   06                  42.4666667  1.5
ad       aixovall    Aixovall    06                  42.4666667  1.4833333
ad       andorra     Andorra     07                  42.5        1.5166667
</code></pre></div></div>

<p>如果只是想看特定某一列的話，可以用<code class="language-plaintext highlighter-rouge">-i/--index</code>來看。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv slice worldcitiespop.csv <span class="nt">-i</span> 1 | xsv table
Country  City        AccentCity  Region  Population  Latitude    Longitude
ad       aixirivali  Aixirivali  06                  42.4666667  1.5
</code></pre></div></div>

<p>如果csv裡面有很多column的話，可以把指令後面的table換成flatten，改用直的方式印出來。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv slice worldcitiespop.csv <span class="nt">-s</span> 0 <span class="nt">-l</span> 2 | xsv flatten
Country     ad
City        aixas
AccentCity  Aixàs
Region      06
Population
Latitude    42.4833333
Longitude   1.4666667
<span class="c">#</span>
Country     ad
City        aixirivali
AccentCity  Aixirivali
Region      06
Population
Latitude    42.4666667
Longitude   1.5
</code></pre></div></div>

<h3 id="查看特定column">查看特定column</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv <span class="k">select </span>Country,AccentCity,Population worldcitiespop.csv | xsv sample 10 | xsv table
Country  AccentCity            Population
us       Thomas Crossing
lk       Egodagoda
ir       Sarbandan
rs       Malo Lukare
lv       Polumyza Mazindritsa
ru       Sovkhoznyy            3916
ne       Balidey
mk       <span class="o">((</span> Kisela Voda <span class="o">))</span>
br       Japuim
ir       Qal<span class="sb">`</span>ehgah-e Khalifeh
</code></pre></div></div>

<p>上面指令的<code class="language-plaintext highlighter-rouge">xsv select</code>後面接的是column的名稱，這邊也可以用index來替代，不過這邊就是1-based的計數方式，所以在上面我們需要把<code class="language-plaintext highlighter-rouge">Country,AccentCity,Population</code>替換成<code class="language-plaintext highlighter-rouge">1,3,5</code>來得到一樣的column。</p>

<p>如果多個column有相同的名稱可以在後面用中括號來表示這個第幾個重複的column，像是<code class="language-plaintext highlighter-rouge">xsv select 'Foo[2]'</code>就是拿第三個叫<code class="language-plaintext highlighter-rouge">Foo</code>的column，而如果要抓取某個範圍內的column，可以用<code class="language-plaintext highlighter-rouge">-</code>來選取中間所有的column，像是<code class="language-plaintext highlighter-rouge">Country-Population</code>或<code class="language-plaintext highlighter-rouge">1-5</code>，更多的操作方法可以看<code class="language-plaintext highlighter-rouge">xsv select -h</code>裡面的說明。</p>

<h3 id="每個value的出現次數">每個value的出現次數</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv frequency worldcitiespop.csv <span class="nt">--limit</span> 3 | xsv table
field       value        count
Country     cn           238985
Country     ru           215938
Country     <span class="nb">id           </span>176546
City        san jose     328
City        san antonio  320
City        santa rosa   296
AccentCity  San Antonio  317
AccentCity  Santa Rosa   296
AccentCity  Santa Cruz   281
Region      04           159916
Region      02           142158
Region      07           126867
Population  <span class="o">(</span>NULL<span class="o">)</span>       3125978
Population  2310         12
Population  2230         11
Latitude    51.15        777
Latitude    51.083333    772
Latitude    51.116667    769
Longitude   23.8         484
Longitude   23.2         477
Longitude   23.05        476
</code></pre></div></div>

<p>這邊<code class="language-plaintext highlighter-rouge">xsv frequency</code>會去計算每個column裡面的每一個value在這個csv裡面出現了幾次，而<code class="language-plaintext highlighter-rouge">--limit</code>會限制取出現次數最多的前N名，如果想看頻率由小到大的排序，可以用<code class="language-plaintext highlighter-rouge">-a/--asc</code>的option。</p>

<h3 id="搜尋欄位的值">搜尋欄位的值</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv search <span class="nt">-s</span> Population <span class="s1">'[0-9]'</span> worldcitiespop.csv | xsv <span class="k">select </span>Country,AccentCity,Population | xsv sample 10 | xsv table
Country  AccentCity  Population
cz       Sumperk     29604
co       Vianí       1586
ph       La Curva    3359
fr       Eaubonne    23739
<span class="k">in       </span>Kamareddi   71049
ru       Ust-Kulom   5205
us       Brent       22735
ph       Lupao       11000
ro       Caraula     2628
ph       Bacnar      4606
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">-s/--select</code>可以指定要搜尋的是哪一個column，而後面搜尋的pattern是regular expression，如果想要排除有比對到的結果，可以用<code class="language-plaintext highlighter-rouge">-v/--invert-match</code>，<code class="language-plaintext highlighter-rouge">xsv search</code>會把所有有比對到的列都印出來變成csv檔，所以如果要只顯示部分的欄位就需要再使用<code class="language-plaintext highlighter-rouge">xsv select</code>或是<code class="language-plaintext highlighter-rouge">xsv slice</code>做處理。</p>

<h2 id="join兩個csv">join兩個csv</h2>

<p>在上面的例子裡面，如果我們想要知道每個Country的縮寫實際代表的國家是哪個的話，可以透過查表的方式來得到，底下的指令會下載一個csv檔，裡面記載著國家縮寫的全稱是什麼。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LO</span> https://gist.githubusercontent.com/anonymous/063cb470e56e64e98cf1/raw/98e2589b801f6ca3ff900b01a87fbb7452eb35c7/countrynames.csv
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv headers countrynames.csv
1   Abbrev
2   Country
</code></pre></div></div>

<p>我們也可以使用join的方式來直接把所有的縮寫都轉成全稱。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv <span class="nb">join</span> <span class="nt">--no-case</span> Abbrev countrynames.csv Country worldcitiespop.csv | xsv sample 10 | xsv table
Abbrev  Country     Country  City             AccentCity       Region  Population  Latitude     Longitude
CO      Colombia    co       santa marta      Santa Marta      28                  3.883889     <span class="nt">-75</span>.102222
LV      Latvia      lv       kozes            Kozes            10                  56.2         25.7
TN      Tunisia     tn       bir bou rekba    Bir Bou Rekba    19                  36.434824    10.565897
LA      Laos        la       ban poung        Ban Poung        22                  19.928056    100.608611
GE      Georgia     ge       zakvi            Zakvi            06                  41.5063889   43.4997222
MZ      Mozambique  mz       gube             Gubé             04                  <span class="nt">-26</span>.2833333  32.5666667
PE      Peru        pe       cruz de callana  Cruz de Callana  11                  <span class="nt">-13</span>.75       <span class="nt">-75</span>.9333333
MZ      Mozambique  mz       maguezane        Maguezane        03                  <span class="nt">-21</span>.5166667  34.6375
TH      Thailand    th       ban tang pra     Ban Tang Pra     35                  14.678472    100.351278
LA      Laos        la       ban xiangkheng   Ban Xiangkheng   16                  21.333333    100.883333
</code></pre></div></div>

<p>在<code class="language-plaintext highlighter-rouge">xsv join</code>裡面，需要先把想要join的key擺在前面，後面再接csv檔。除了上面的inner join以外，xsv還有支援left join、right join等，可以看<code class="language-plaintext highlighter-rouge">xsv join -h</code>裡面的說明。</p>

<p>在上面的結果裡面，如果我們只想要保留國家的全稱就好，想把join的key都拿掉的話，可以再過一個<code class="language-plaintext highlighter-rouge">xsv select '!Abbrev,Country[1]'</code>，把除了Abbrev和第二個Country以外的全部欄位都選出來。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv <span class="nb">join</span> <span class="nt">--no-case</span> Abbrev countrynames.csv Country worldcitiespop.csv | xsv <span class="k">select</span> <span class="s1">'!Abbrev,Country[1]'</span> | xsv sample 10 | xsv table
Country                          City           AccentCity     Region  Population  Latitude     Longitude
Peru                             cachisama      Cachisama      05                  <span class="nt">-13</span>.1166667  <span class="nt">-74</span>.3
Bosnia and Herzegovina | Bosnia  gecet          Gecet          01                  44.5666667   16.1005556
China                            caihuaqiao     Caihuaqiao     07                  27.035278    119.777222
Pakistan                         kothung        Kothung        07                  35.384052    75.74772
Pakistan                         dhok waraich   Dhok Waraich   04                  33.727099    72.242949
Russian Federation | Russia      yasenok        Yasenok        10                  53.218388    32.851209
Philippines                      padaraonan     Padaraonan     J3                  10.4919      122.4906
Indonesia                        gunungaseupan  Gunungaseupan  30                  <span class="nt">-7</span>.039722    107.505278
Colombia                         dificil        Dificil        38                  9.849747     <span class="nt">-74</span>.236267
Ukraine                          lesnichevka    Lesnichëvka    23                  48.613614    28.180124
</code></pre></div></div>

<h2 id="加速xsv的計算">加速xsv的計算</h2>

<p>xsv支援先對csv檔做index，來讓xsv的其他操作像是<code class="language-plaintext highlighter-rouge">stats</code>、<code class="language-plaintext highlighter-rouge">slice</code>等可以變得更快。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; % xsv index worldcitiespop.csv
</code></pre></div></div>

<p>執行完上面的指令以後會產生一個<strong>wordcitiespop.csv.idx</strong>的檔案，接下來在執行其他操作的時候就會自動加速了，不過如果原本的檔案內容有被更動過的話，會需要再重新製作一個index檔。</p>]]></content><author><name>Your Name</name></author><category term="Tool" /><summary type="html"><![CDATA[這篇文章簡單紀錄xsv，一個處理csv檔案的command line工具的使用範例。]]></summary></entry><entry><title type="html">KGAT: Knowledge Graph Attention Network for Recommendation</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/02/kgat/" rel="alternate" type="text/html" title="KGAT: Knowledge Graph Attention Network for Recommendation" /><published>2023-02-02T00:00:00+00:00</published><updated>2023-02-02T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/02/kgat</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2023/02/02/kgat/"><![CDATA[<p>這篇文章紀錄一下看了<a href="https://arxiv.org/pdf/1905.07854.pdf">KGAT: Knowledge Graph Attention Network for Recommendation</a>的筆記。</p>

<!--more-->

<p>在過去的推薦系統當中，蠻常使用collaborative filtering（CF）來產生推薦，藉由觀察使用者和商品的互動行為，來找出目標使用者跟哪些現有的使用者相似，用現有使用者有互動過的商品來推薦給目標使用者。</p>

<p>然而，在collaborative filtering當中，比較少著墨於使用者本身的特性以及商品之間的關聯，主要只使用使用者對商品的行為來當作輸入，而這篇paper嘗試引入了knowledge graph進來，藉此補足collaborative filtering不足的部分。</p>

<h2 id="task-formulation">Task Formulation</h2>

<p>這邊先介紹一下在這篇paper裡面所使用到的graph，主要是由兩個bipartite組成。</p>

<p><img src="./collaborative_knowledge_graph.png" alt="Collaborative knowledge graph" /></p>

<p>上半部的Users、Items是collaborative filtering的部分，由user和item組成，其中兩者的關係$r_1$是指user看過item的意思，舉例來說user $u_1$看過item $i_1$，就會在上圖有個$u_1$的node，並有一個箭頭$r_1$指向item $i_1$的node。</p>

<p>下半部的Items、Entities是knowledge graph的部分，每一個$e_n$表示的是item的特性，而item和entity之間可能有很多的關係像是電影種類、導演、演員等。</p>

<p>作者將這個由兩個bipartite組成的graph稱之為<strong>Collaborative Knowledge Graph</strong>，可以簡單想成是我們把$u_1$看過$i_1$做成$(u_1, r_1, i_1)$這樣的triplet也放進knowledge graph裡面。</p>

<h2 id="method">Method</h2>

<p>上面的部分主要是模型輸入的部分，而下圖是整個模型的架構圖。</p>

<p><img src="./model_overview.png" alt="Model overview" /></p>

<h3 id="embedding-layer">Embedding Layer</h3>

<p>在這邊我們會給每一個user、item、entity和relation一個embedding，不過因為我們已經轉換成了knowledge graph的形式，成為了$(head, relation, tail)$的triplet們，所以在底下便會用$\mathbf{e}_h, \mathbf{e}_t \in \mathbb{R}^d$來代表head和tail的embedding，用$\mathbf{e}_r\in\mathbb{R}^k$來代表relation的embedding。</p>

<p>在knowledge graph裡面我們會需要一個來衡量這個triplet目前學得怎麼樣的分數，而這篇paper的定義如下</p>

\[g(h, r, t)=\left \| \mathbf{W}_r\mathbf{e}_h+\mathbf{e}_r-\mathbf{W}_r\mathbf{e}_t\right \|_2^2\]

<p>在上面的$\mathbf{W}_r\in\mathbb{R}^{k\times d}$是一個transformation matrix，幫忙把head和tail的embedding轉換到relation的空間，並直接用head和relation向量相加的位置跟tail的位置差異來為triplet打分數，一個越小的$g(h, r, t)$是越好的。</p>

<p>而要訓練的loss function便是希望有存在在graph裡面的triplet的$g(h, r, t)$要比隨機抽樣的tail $t’$的$g(h, r, t’)$還要來得小。</p>

\[\mathcal{L}_{KG}=\sum\limits_{(h, r, t, t') \in \tau}-\ln\sigma\left( g(h, r, t')-g(h, r, t) \right)\\ \tau=\{ (h, r, t, t')|(h, r, t)\in\mathcal{G}, (h, r, t')\notin\mathcal{G}\}\]

<p>上面算式中的$\sigma$是sigmoid function。</p>

<h3 id="attentive-embedding-propagation-layers">Attentive Embedding Propagation Layers</h3>

<h4 id="information-propagation">Information Propagation</h4>

<p>在這篇paper裡面，embedding除了被上面knowledge graph的gradient更新以外，這裡還會根據鄰居的embedding來影響本身的embedding。</p>

<p>假如現在有一個entity $h$，它的鄰居就是與$h$相鄰的所有node，而我們把這些鄰居按照重要性weighted sum成一個單一的embedding $\mathbf{e}_{\mathcal{N}_h}$。</p>

\[\mathbf{e}_{\mathcal{N}_h}=\sum\limits_{(h, r, t)\in\mathcal{N}_h}\pi(h,r,t)\mathbf{e}_t\\ \mathcal{N}_h = \{(h, r, t) \vert (h, r, t) \in \mathcal{G} \}\]

<h4 id="knowledge-aware-attention">Knowledge-aware Attention</h4>

<p>在式$(3)$裡面的$\pi(h,r,t)$所定義每個鄰居的重要程度是由底下的式子定義出來的</p>

\[\pi(h,r,t)=(\mathbf{W}_r\mathbf{e}_t)^\top\tanh\left((\mathbf{W}_r\mathbf{e}_h+\mathbf{e}_r)\right)\]

<p>在這邊我們把entity和它的鄰居透過transformation matrix轉換到relation的空間以後，透過dot product來算出跟entity $h$的相關性來表示鄰居的重要程度，接著再做normalize。</p>

\[\pi(h, r, t)=\frac{\exp(\pi(h,r,t))}{\sum_{(h,r',t')\in\mathcal{N}_h}\exp(\pi(h,r',t'))}\]

<h4 id="information-aggregation">Information Aggregation</h4>

<p>在有了鄰居的embedding $\mathbf{e}_{\mathcal{N}_h}$以後，這篇paper提出了三種function來更新原本的entity embedding $\mathbf{e}_h$。</p>

<ul>
  <li>GCN Aggregator</li>
</ul>

\[f_{GCN}=\mathrm{LeakyReLU}\left( \mathbf{W}(\mathbf{e}_h+\mathbf{e}_{\mathcal{N}_h}) \right)\]

<ul>
  <li>GraphSage Aggregator</li>
</ul>

\[f_{GraphSage}=\mathrm{LeakyReLU}\left( \mathbf{W}(\mathbf{e}_h\|\mathbf{e}_{\mathcal{N}_h})\right)\]

<ul>
  <li>Bi-Interaction Aggregator</li>
</ul>

\[f_{Bi-Interaction}=\mathrm{LeakyReLU}\left(\mathbf{W}_1(\mathbf{e}_h+\mathbf{e}_{\mathcal{N}_h})\right)+\mathrm{LeakyReLU}\left(\mathbf{W}_2(\mathbf{e}_h\odot\mathbf{e}_{\mathcal{N}_h})\right)\]

<p>上面的$\mathbf{W}_1,\mathbf{W}_2\in\mathbb{R}^{d’\times d}$是可被訓練的參數，而$\odot$是element-wise product。</p>

<h4 id="high-order-propagation">High-order Propagation</h4>

<p>在上面我們定義了如何把entity $h$的鄰居的資訊整合起來變成一個embedding，也定義了一些function來更新entity $h$的embedding，而這樣的步驟可以重複很多次來得到多個embedding表示距離從近到遠的資訊總和，這邊假設我們重複$l$次，每次entity $h$的embedding為</p>

\[\mathbf{e}^{(l)}_h=f\left(\mathbf{e}^{(l-1)}_h,\mathbf{e}^{(l-1)}_{\mathcal{N}_h}\right)\]

<p>而鄰居的embedding為</p>

\[\mathbf{e}^{(l-1)}_{\mathcal{N}_h}=\sum\limits_{(h,r,t)\in\mathcal{N}_h}\pi(h,r,t)\mathbf{e}^{(l-1)}_t\]

<h3 id="model-prediction">Model Prediction</h3>

<p>在經過了$l$次的擴散，也就是$L$層layer（每個step在information aggregation都可以有不同的weights）以後，每個user $u$會有$L$個embedding ${\mathbf{e}^{(1)}_u,…,\mathbf{e}^{(L)}_u}$，每個item $i$也會有$L$個embedding ${\mathbf{e}^{(1)}_i,…,\mathbf{e}^{(L)}_i}$，我們把這些embedding都concatenate起來當做是最終user和item的embedding。</p>

\[\mathbf{e}^*_u=\mathbf{e}^{(0)}_u\|...\|\mathbf{e}^{(L)}_u,\mathbf{e}^*_i=\mathbf{e}^{(0)}_i\|...\|\mathbf{e}^{(L)}_i\]

<p>而整個推薦系統的推薦便是以user和item embedding內積的結果大小來排序</p>

\[\hat y(u,i)=\mathbf{e}^{*\top}_u\mathbf{e}^*_i\]

<h3 id="optimization">Optimization</h3>

<p>在loss function的部分除了式$(2)$ knowledge graph的loss $\mathcal{L}_{KG}$以外，我們還需要把使用者跟商品互動的部分，也就是collaborative filter的loss放進去</p>

\[\mathcal{L}_{CF}=\sum\limits_{(u,i,j)\in\mathcal{O}}-\ln\sigma\left(\hat y(u,i)-\hat y(u,j)\right)\\ \mathcal{O}=\{(u,i,j)\vert(u,i)\in\mathcal{R}^+,(u,j)\in\mathcal{R}^- \}\]

<p>式$(13)$裡面的$\mathcal{O}$指的是training data，整個式子的意思是有實際互動過的使用者和商品的組合的分數要比沒有實際互動過的組合要來得高。</p>

<p>整個模型的loss function合起來的樣子如下</p>

\[\mathcal{L}_{KGAT}=\mathcal{L}_{KG}+\mathcal{L}_{CF}+\lambda\|\Theta\|^2_2\\ \Theta=\{\mathbf{E},\mathbf{W}_r,\forall l\in\mathcal{R},\mathbf{W}^{(l)}_1,\mathbf{W}^{(l)}_2,\forall l\in\{1,...,L\}\}\]

<p>其中$\Theta$是整個模型的參數，最後一項是一個$L_2$的regularization。</p>

<h2 id="experiments">Experiments</h2>

<p>作者將這個模型套用在三個dataset上，其相關的統計數值如下。</p>

<p><img src="./dataset.png" alt="Dataset statistics" /></p>

<p>模型跑出來的結果如下</p>

<p><img src="./performance.png" alt="Performance" /></p>

<p>可以看到KGAT在各個dataset上面都有不錯的表現。</p>

<h2 id="conclusion">Conclusion</h2>

<p>這篇paper在collaborative filter上又多加了knowledge graph的資訊在裡面，在各個dataset上看獲得了不錯的結果，在paper上面也有附上實作的<a href="https://github.com/xiangwang1223/knowledge_graph_attention_network">程式碼</a>讓大家試試看。</p>]]></content><author><name>Your Name</name></author><category term="Graph-Model" /><category term="Recommendation-System" /><category term="Machine-Learning" /><category term="Paper" /><summary type="html"><![CDATA[這篇文章紀錄一下看了KGAT: Knowledge Graph Attention Network for Recommendation的筆記。]]></summary></entry></feed>